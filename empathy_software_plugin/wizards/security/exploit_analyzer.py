"""
Exploit Analyzer (Level 4)

Analyzes which vulnerabilities are actually exploitable.

This is Level 4 Anticipatory Empathy - predicting which security issues
will actually be exploited in the wild.

Copyright 2025 Smart AI Memory, LLC
Licensed under Fair Source 0.9
"""

from dataclasses import dataclass
from typing import Any


@dataclass
class ExploitabilityAssessment:
    """Assessment of how exploitable a vulnerability is"""

    vulnerability: dict[str, Any]
    exploitability: str  # "CRITICAL", "HIGH", "MEDIUM", "LOW"
    accessibility: str  # "public", "authenticated", "internal"
    attack_complexity: str  # "low", "medium", "high"
    exploit_likelihood: float  # 0.0 to 1.0
    reasoning: list[str]
    real_world_examples: list[str]
    mitigation_urgency: str


class ExploitAnalyzer:
    """
    Analyzes exploitability of security vulnerabilities.

    Level 4: Predicts which vulnerabilities will actually be exploited.
    """

    def __init__(self):
        # Known attack patterns from real-world incidents
        self.active_attack_patterns = {
            "SQL Injection": {
                "likelihood": 0.9,
                "reason": "Actively scanned by automated tools",
                "examples": ["SQLMap", "Havij", "automated bots"],
            },
            "Command Injection": {
                "likelihood": 0.95,
                "reason": "Direct remote code execution - high value target",
                "examples": ["Log4Shell", "Shellshock"],
            },
            "Hardcoded Credentials": {
                "likelihood": 0.85,
                "reason": "Credentials harvested from GitHub leaks",
                "examples": ["GitHub scanning bots", "credential stuffing"],
            },
            "Cross-Site Scripting": {
                "likelihood": 0.7,
                "reason": "Common in web apps, automated scanners detect",
                "examples": ["BeEF", "XSS Hunter"],
            },
            "Insecure Deserialization": {
                "likelihood": 0.8,
                "reason": "Remote code execution vector",
                "examples": ["Java deserialization attacks"],
            },
            "Path Traversal": {
                "likelihood": 0.75,
                "reason": "File system access, automated detection",
                "examples": ["Directory traversal attacks"],
            },
        }

    def assess_exploitability(
        self, vulnerability: dict[str, Any], context: dict[str, Any] = None
    ) -> ExploitabilityAssessment:
        """
        Assess how exploitable a vulnerability is.

        Args:
            vulnerability: Detected vulnerability
            context: Additional context (endpoint exposure, auth, etc.)

        Returns:
            ExploitabilityAssessment

        Example:
            >>> vuln = {"name": "SQL Injection", "severity": "CRITICAL", ...}
            >>> assessment = analyzer.assess_exploitability(vuln, {
            ...     "endpoint_public": True,
            ...     "has_auth": False
            ... })
            >>> print(f"Exploitability: {assessment.exploitability}")
        """
        context = context or {}

        vuln_name = vulnerability.get("name", "Unknown")

        # Get base attack pattern info
        attack_info = self.active_attack_patterns.get(
            vuln_name, {"likelihood": 0.5, "reason": "Unknown attack pattern", "examples": []}
        )

        # Determine accessibility
        accessibility = self._determine_accessibility(vulnerability, context)

        # Determine attack complexity
        attack_complexity = self._determine_attack_complexity(vulnerability, context)

        # Calculate exploit likelihood
        exploit_likelihood = self._calculate_exploit_likelihood(
            attack_info["likelihood"],
            accessibility,
            attack_complexity,
            vulnerability.get("severity", "MEDIUM"),
        )

        # Generate reasoning
        reasoning = self._generate_reasoning(
            vulnerability, accessibility, attack_complexity, attack_info
        )

        # Determine exploitability rating
        exploitability = self._determine_exploitability_rating(exploit_likelihood)

        # Determine mitigation urgency
        mitigation_urgency = self._determine_mitigation_urgency(
            exploitability, accessibility, vulnerability.get("severity", "MEDIUM")
        )

        return ExploitabilityAssessment(
            vulnerability=vulnerability,
            exploitability=exploitability,
            accessibility=accessibility,
            attack_complexity=attack_complexity,
            exploit_likelihood=exploit_likelihood,
            reasoning=reasoning,
            real_world_examples=attack_info.get("examples", []),
            mitigation_urgency=mitigation_urgency,
        )

    def _determine_accessibility(
        self, vulnerability: dict[str, Any], context: dict[str, Any]
    ) -> str:
        """Determine if vulnerability is publicly accessible"""

        # Check context clues
        if context.get("endpoint_public") is True:
            return "public"

        if context.get("endpoint_public") is False:
            return "internal"

        if context.get("requires_authentication"):
            return "authenticated"

        # Infer from file path
        file_path = vulnerability.get("file_path", "")

        if any(p in file_path.lower() for p in ["api", "public", "web", "routes"]):
            return "public"

        if any(p in file_path.lower() for p in ["admin", "internal"]):
            return "internal"

        # Default to public for web-related vulnerabilities
        if vulnerability.get("category") in ["injection", "cross_site_scripting"]:
            return "public"

        return "authenticated"

    def _determine_attack_complexity(
        self, vulnerability: dict[str, Any], context: dict[str, Any]
    ) -> str:
        """Determine attack complexity"""

        vuln_name = vulnerability.get("name", "")

        # Low complexity attacks
        if any(
            v in vuln_name for v in ["SQL Injection", "Command Injection", "Hardcoded Credentials"]
        ):
            return "low"

        # Medium complexity
        if any(v in vuln_name for v in ["XSS", "CSRF", "Path Traversal"]):
            return "medium"

        # High complexity
        if any(v in vuln_name for v in ["Deserialization", "Race Condition"]):
            return "high"

        return "medium"

    def _calculate_exploit_likelihood(
        self, base_likelihood: float, accessibility: str, attack_complexity: str, severity: str
    ) -> float:
        """Calculate overall exploit likelihood"""

        likelihood = base_likelihood

        # Adjust for accessibility
        if accessibility == "public":
            likelihood *= 1.2  # More likely if publicly accessible
        elif accessibility == "authenticated":
            likelihood *= 0.8
        elif accessibility == "internal":
            likelihood *= 0.5

        # Adjust for attack complexity
        complexity_multipliers = {"low": 1.2, "medium": 1.0, "high": 0.7}
        likelihood *= complexity_multipliers.get(attack_complexity, 1.0)

        # Adjust for severity
        if severity == "CRITICAL":
            likelihood *= 1.1

        # Cap at 1.0
        return min(likelihood, 1.0)

    def _generate_reasoning(
        self,
        vulnerability: dict[str, Any],
        accessibility: str,
        attack_complexity: str,
        attack_info: dict[str, Any],
    ) -> list[str]:
        """Generate reasoning for exploitability assessment"""

        reasoning = []

        # Accessibility reasoning
        if accessibility == "public":
            reasoning.append("Endpoint is publicly accessible")
        elif accessibility == "authenticated":
            reasoning.append("Requires authentication - reduces attack surface")
        else:
            reasoning.append("Internal access only - limited exposure")

        # Attack complexity reasoning
        if attack_complexity == "low":
            reasoning.append("Low attack complexity - easy to exploit")
        elif attack_complexity == "high":
            reasoning.append("High attack complexity - requires expertise")

        # Pattern-based reasoning
        if attack_info.get("reason"):
            reasoning.append(f"In our experience: {attack_info['reason']}")

        return reasoning

    def _determine_exploitability_rating(self, exploit_likelihood: float) -> str:
        """Determine exploitability rating"""

        if exploit_likelihood > 0.8:
            return "CRITICAL"
        elif exploit_likelihood > 0.6:
            return "HIGH"
        elif exploit_likelihood > 0.4:
            return "MEDIUM"
        else:
            return "LOW"

    def _determine_mitigation_urgency(
        self, exploitability: str, accessibility: str, severity: str
    ) -> str:
        """Determine how urgently to mitigate"""

        if exploitability == "CRITICAL" and accessibility == "public":
            return "IMMEDIATE - Fix before next deployment"

        if exploitability == "CRITICAL" or (exploitability == "HIGH" and accessibility == "public"):
            return "URGENT - Fix within 24 hours"

        if exploitability == "HIGH" or severity == "CRITICAL":
            return "HIGH - Fix within 1 week"

        if exploitability == "MEDIUM":
            return "MEDIUM - Fix in next sprint"

        return "LOW - Schedule for future sprint"
