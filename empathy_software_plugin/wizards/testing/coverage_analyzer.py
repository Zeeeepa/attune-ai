"""
Coverage Analyzer for Enhanced Testing Wizard

Parses coverage reports and provides intelligent analysis of test coverage gaps,
including branch coverage, critical path identification, and trend analysis.

Copyright 2025 Smart-AI-Memory
Licensed under Fair Source License 0.9
"""

import json
import xml.etree.ElementTree as ET
from dataclasses import dataclass
from enum import Enum
from pathlib import Path
from typing import Any


class CoverageFormat(Enum):
    """Supported coverage report formats"""

    XML = "xml"
    JSON = "json"
    HTML = "html"
    LCOV = "lcov"


@dataclass
class FileCoverage:
    """Coverage statistics for a single file"""

    file_path: str
    lines_total: int
    lines_covered: int
    lines_missing: list[int]
    branches_total: int
    branches_covered: int
    branches_missing: list[tuple[int, int]]  # (line_num, branch_id)
    percentage: float

    @property
    def lines_uncovered(self) -> int:
        """Number of uncovered lines"""
        return self.lines_total - self.lines_covered

    @property
    def branch_percentage(self) -> float:
        """Branch coverage percentage"""
        if self.branches_total == 0:
            return 100.0
        return (self.branches_covered / self.branches_total) * 100


@dataclass
class CoverageReport:
    """Complete coverage analysis report"""

    overall_percentage: float
    lines_total: int
    lines_covered: int
    branches_total: int
    branches_covered: int
    files: dict[str, FileCoverage]
    critical_gaps: list[str]  # Files with <50% coverage
    untested_files: list[str]  # Files with 0% coverage
    timestamp: str | None = None

    @property
    def files_total(self) -> int:
        """Total number of files analyzed"""
        return len(self.files)

    @property
    def files_well_covered(self) -> int:
        """Number of files with â‰¥80% coverage"""
        return sum(1 for f in self.files.values() if f.percentage >= 80.0)


class CoverageAnalyzer:
    """
    Analyzes test coverage reports to identify gaps and provide recommendations.

    Supports multiple formats:
    - Coverage.py XML (pytest --cov)
    - Coverage.py JSON
    - LCOV format
    - HTML reports
    """

    def __init__(self):
        self.critical_threshold = 50.0  # Files below this are critical
        self.target_threshold = 80.0  # Target coverage percentage

    def parse_coverage_xml(self, xml_path: Path) -> CoverageReport:
        """
        Parse coverage.xml format (Coverage.py / pytest-cov output)

        Args:
            xml_path: Path to coverage.xml file

        Returns:
            CoverageReport with full analysis

        Raises:
            FileNotFoundError: If XML file doesn't exist
            ValueError: If XML is malformed
        """
        if not xml_path.exists():
            raise FileNotFoundError(f"Coverage XML not found: {xml_path}")

        try:
            # Note: Parsing trusted coverage.xml generated by pytest-cov, not untrusted user input
            tree = ET.parse(xml_path)  # nosec B314
            root = tree.getroot()
        except ET.ParseError as e:
            raise ValueError(f"Malformed coverage XML: {e}") from e

        # Extract overall statistics
        overall = root.attrib
        lines_total = int(overall.get("lines-valid", 0))
        lines_covered = int(overall.get("lines-covered", 0))
        branches_total = int(overall.get("branches-valid", 0))
        branches_covered = int(overall.get("branches-covered", 0))

        # Calculate overall percentage
        if lines_total > 0:
            overall_pct = (lines_covered / lines_total) * 100
        else:
            overall_pct = 0.0

        # Parse individual files
        files: dict[str, FileCoverage] = {}
        critical_gaps: list[str] = []
        untested_files: list[str] = []

        for package in root.findall(".//package"):
            for cls in package.findall(".//class"):
                filename = cls.attrib.get("filename", "")
                if not filename:
                    continue

                # Get line statistics
                lines = cls.findall(".//line")
                lines_total_file = len(lines)
                lines_covered_file = sum(1 for line in lines if line.attrib.get("hits", "0") != "0")
                lines_missing = [
                    int(line.attrib.get("number", 0))
                    for line in lines
                    if line.attrib.get("hits", "0") == "0"
                ]

                # Get branch statistics
                branches_file = [line for line in lines if line.attrib.get("branch") == "true"]
                branches_total_file = len(branches_file) * 2  # Each branch point has 2 paths
                branches_covered_file = 0
                for line in branches_file:
                    if "condition-coverage" in line.attrib:
                        # Format: "50% (1/2)" or "0% (0/2)"
                        cov_str = line.attrib.get("condition-coverage", "0% (0/2)")
                        # Extract the fraction part: (1/2)
                        if "(" in cov_str:
                            fraction = cov_str.split("(")[1].split(")")[0]  # "1/2"
                            covered = int(fraction.split("/")[0])  # 1
                            branches_covered_file += covered
                branches_missing = [
                    (int(line.attrib.get("number", 0)), i)
                    for line in branches_file
                    for i in range(2)  # Each branch has 2 paths
                ]

                # Calculate file percentage
                if lines_total_file > 0:
                    file_pct = (lines_covered_file / lines_total_file) * 100
                else:
                    file_pct = 0.0

                file_cov = FileCoverage(
                    file_path=filename,
                    lines_total=lines_total_file,
                    lines_covered=lines_covered_file,
                    lines_missing=lines_missing,
                    branches_total=branches_total_file,
                    branches_covered=branches_covered_file,
                    branches_missing=branches_missing,
                    percentage=file_pct,
                )

                files[filename] = file_cov

                # Track critical gaps
                if file_pct < self.critical_threshold:
                    critical_gaps.append(filename)
                if file_pct == 0.0 and lines_total_file > 0:
                    untested_files.append(filename)

        return CoverageReport(
            overall_percentage=overall_pct,
            lines_total=lines_total,
            lines_covered=lines_covered,
            branches_total=branches_total,
            branches_covered=branches_covered,
            files=files,
            critical_gaps=critical_gaps,
            untested_files=untested_files,
            timestamp=overall.get("timestamp"),
        )

    def parse_coverage_json(self, json_path: Path) -> CoverageReport:
        """
        Parse coverage.json format (Coverage.py JSON output)

        Args:
            json_path: Path to coverage.json file

        Returns:
            CoverageReport with full analysis
        """
        if not json_path.exists():
            raise FileNotFoundError(f"Coverage JSON not found: {json_path}")

        with open(json_path) as f:
            data = json.load(f)

        # Extract overall totals
        totals = data.get("totals", {})
        lines_total = totals.get("num_statements", 0)
        lines_covered = totals.get("covered_lines", 0)
        branches_total = totals.get("num_branches", 0)
        branches_covered = totals.get("covered_branches", 0)

        if lines_total > 0:
            overall_pct = (lines_covered / lines_total) * 100
        else:
            overall_pct = 0.0

        # Parse individual files
        files: dict[str, FileCoverage] = {}
        critical_gaps: list[str] = []
        untested_files: list[str] = []

        for filename, file_data in data.get("files", {}).items():
            summary = file_data.get("summary", {})

            lines_total_file = summary.get("num_statements", 0)
            lines_covered_file = summary.get("covered_lines", 0)
            branches_total_file = summary.get("num_branches", 0)
            branches_covered_file = summary.get("covered_branches", 0)

            # Get missing lines
            missing_lines = file_data.get("missing_lines", [])

            # Get missing branches
            missing_branches = [
                (line, branch)
                for line, branches in file_data.get("missing_branches", {}).items()
                for branch in branches
            ]

            if lines_total_file > 0:
                file_pct = (lines_covered_file / lines_total_file) * 100
            else:
                file_pct = 0.0

            file_cov = FileCoverage(
                file_path=filename,
                lines_total=lines_total_file,
                lines_covered=lines_covered_file,
                lines_missing=missing_lines,
                branches_total=branches_total_file,
                branches_covered=branches_covered_file,
                branches_missing=missing_branches,
                percentage=file_pct,
            )

            files[filename] = file_cov

            if file_pct < self.critical_threshold:
                critical_gaps.append(filename)
            if file_pct == 0.0 and lines_total_file > 0:
                untested_files.append(filename)

        return CoverageReport(
            overall_percentage=overall_pct,
            lines_total=lines_total,
            lines_covered=lines_covered,
            branches_total=branches_total,
            branches_covered=branches_covered,
            files=files,
            critical_gaps=critical_gaps,
            untested_files=untested_files,
            timestamp=data.get("meta", {}).get("timestamp"),
        )

    def identify_critical_gaps(self, report: CoverageReport) -> list[str]:
        """
        Identify files that critically need testing (below threshold)

        Args:
            report: Coverage report to analyze

        Returns:
            List of file paths sorted by priority (worst coverage first)
        """
        critical = [
            (file_path, file_cov.percentage)
            for file_path, file_cov in report.files.items()
            if file_cov.percentage < self.critical_threshold
        ]

        # Sort by percentage (lowest first)
        critical.sort(key=lambda x: x[1])

        return [file_path for file_path, _ in critical]

    def suggest_priority_files(
        self, report: CoverageReport, top_n: int = 10
    ) -> list[dict[str, Any]]:
        """
        Suggest which files to test next for maximum impact

        Prioritizes based on:
        1. Current coverage (lower is higher priority)
        2. File size (larger files have more impact)
        3. Missing lines count (more gaps = more opportunity)

        Args:
            report: Coverage report to analyze
            top_n: Number of suggestions to return

        Returns:
            List of suggestions with reasoning
        """
        suggestions = []

        for file_path, file_cov in report.files.items():
            # Skip well-covered files
            if file_cov.percentage >= self.target_threshold:
                continue

            # Calculate impact score
            coverage_gap = self.target_threshold - file_cov.percentage
            size_factor = file_cov.lines_total / 100  # Normalize
            missing_factor = file_cov.lines_uncovered / 10  # Normalize

            impact_score = (coverage_gap * 0.5) + (size_factor * 0.3) + (missing_factor * 0.2)

            suggestions.append(
                {
                    "file": file_path,
                    "current_coverage": file_cov.percentage,
                    "lines_missing": file_cov.lines_uncovered,
                    "impact_score": impact_score,
                    "reason": self._generate_suggestion_reason(file_cov),
                }
            )

        # Sort by impact score (highest first)
        suggestions.sort(key=lambda x: x["impact_score"], reverse=True)

        return suggestions[:top_n]

    def _generate_suggestion_reason(self, file_cov: FileCoverage) -> str:
        """Generate human-readable reason for testing suggestion"""
        if file_cov.percentage == 0.0:
            return "No tests exist - critical gap"
        elif file_cov.percentage < 30:
            return "Very low coverage - high priority"
        elif file_cov.percentage < 50:
            return "Below critical threshold"
        elif file_cov.percentage < 70:
            return "Moderate gap - good opportunity for improvement"
        else:
            return "Close to target - finish with targeted tests"

    def calculate_coverage_trend(
        self, historical_reports: list[tuple[str, CoverageReport]]
    ) -> dict[str, float]:
        """
        Calculate coverage trends over time

        Args:
            historical_reports: List of (timestamp, report) tuples in chronological order

        Returns:
            Dict mapping file paths to trend percentage (positive = improving)
        """
        if len(historical_reports) < 2:
            return {}

        trends = {}

        # Get oldest and newest reports
        oldest_date, oldest_report = historical_reports[0]
        newest_date, newest_report = historical_reports[-1]

        # Calculate trend for each file
        all_files = set(oldest_report.files.keys()) | set(newest_report.files.keys())

        for file_path in all_files:
            old_cov = oldest_report.files.get(file_path)
            new_cov = newest_report.files.get(file_path)

            if old_cov and new_cov:
                trend = new_cov.percentage - old_cov.percentage
                trends[file_path] = trend
            elif new_cov and not old_cov:
                # New file added
                trends[file_path] = new_cov.percentage
            elif old_cov and not new_cov:
                # File removed
                trends[file_path] = -old_cov.percentage

        return trends

    def generate_summary(self, report: CoverageReport) -> str:
        """
        Generate human-readable coverage summary

        Args:
            report: Coverage report to summarize

        Returns:
            Formatted summary string
        """
        summary = []
        summary.append("=" * 60)
        summary.append("COVERAGE ANALYSIS SUMMARY")
        summary.append("=" * 60)
        summary.append(f"Overall Coverage: {report.overall_percentage:.2f}%")
        summary.append(f"Lines: {report.lines_covered}/{report.lines_total}")
        summary.append(f"Branches: {report.branches_covered}/{report.branches_total}")
        summary.append(f"Files: {report.files_total} total")
        summary.append(f"  - Well covered (â‰¥80%): {report.files_well_covered}")
        summary.append(f"  - Critical gaps (<50%): {len(report.critical_gaps)}")
        summary.append(f"  - Untested: {len(report.untested_files)}")
        summary.append("")

        if report.untested_files:
            summary.append("âš ï¸  UNTESTED FILES (0% coverage):")
            for file_path in report.untested_files[:5]:
                summary.append(f"  - {file_path}")
            if len(report.untested_files) > 5:
                summary.append(f"  ... and {len(report.untested_files) - 5} more")
            summary.append("")

        if report.critical_gaps:
            summary.append("ðŸ”´ CRITICAL GAPS (<50% coverage):")
            critical_sorted = sorted(
                [(f, report.files[f].percentage) for f in report.critical_gaps], key=lambda x: x[1]
            )
            for file_path, pct in critical_sorted[:5]:
                summary.append(f"  - {file_path}: {pct:.1f}%")
            if len(report.critical_gaps) > 5:
                summary.append(f"  ... and {len(report.critical_gaps) - 5} more")

        summary.append("=" * 60)

        return "\n".join(summary)
