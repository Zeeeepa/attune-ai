"""Behavioral tests for coordination.

Generated by LLM-enhanced test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import pytest
from datetime import datetime, timedelta
from unittest.mock import Mock, patch, MagicMock
from enum import Enum

from attune.coordination import (
    ResolutionStrategy,
    ResolutionResult,
    TeamPriorities,
    ConflictResolver,
    AgentTask,
    AgentCoordinator,
    TeamSession,
)
from attune.pattern_library import Pattern


# Fixtures
@pytest.fixture
def sample_pattern():
    """Create a sample pattern for testing."""
    return Pattern(
        id="test_pattern_1",
        agent_id="agent_1",
        pattern_type="best_practice",
        name="Test Pattern",
        description="A test pattern",
        confidence=0.85,
        context={"language": "python", "file_type": "module"},
        discovered_at=datetime.now(),
        usage_count=10,
    )


@pytest.fixture
def another_pattern():
    """Create another sample pattern for testing."""
    return Pattern(
        id="test_pattern_2",
        agent_id="agent_2",
        pattern_type="security",
        name="Security Pattern",
        description="A security pattern",
        confidence=0.75,
        context={"language": "python", "security_level": "high"},
        discovered_at=datetime.now() - timedelta(days=1),
        usage_count=5,
    )


@pytest.fixture
def high_confidence_pattern():
    """Create a high confidence pattern."""
    return Pattern(
        id="high_conf_pattern",
        agent_id="agent_3",
        pattern_type="performance",
        name="High Confidence Pattern",
        description="A high confidence pattern",
        confidence=0.95,
        context={"language": "python", "optimization": "true"},
        discovered_at=datetime.now() - timedelta(days=5),
        usage_count=50,
    )


@pytest.fixture
def team_priorities():
    """Create team priorities for testing."""
    return TeamPriorities(
        readability_weight=0.3,
        performance_weight=0.2,
        security_weight=0.3,
        maintainability_weight=0.2,
        type_preferences={
            "security": 1.0,
            "best_practice": 0.8,
            "performance": 0.7,
            "style": 0.5,
            "warning": 0.6,
        },
        preferred_tags=["security", "performance"],
    )


@pytest.fixture
def conflict_resolver(team_priorities):
    """Create a ConflictResolver instance."""
    return ConflictResolver(team_priorities=team_priorities)


@pytest.fixture
def agent_coordinator():
    """Create an AgentCoordinator instance."""
    return AgentCoordinator()


@pytest.fixture
def team_session():
    """Create a TeamSession instance."""
    return TeamSession(
        team_id="test_team",
        agent_ids=["agent_1", "agent_2", "agent_3"],
    )


# ResolutionStrategy Tests
class TestResolutionStrategy:
    """Test ResolutionStrategy enum."""

    def test_given_resolution_strategy_when_accessing_values_then_returns_correct_strings(self):
        """Verify ResolutionStrategy enum values are correct."""
        # Given/When/Then
        assert ResolutionStrategy.HIGHEST_CONFIDENCE.value == "highest_confidence"
        assert ResolutionStrategy.MOST_RECENT.value == "most_recent"
        assert ResolutionStrategy.BEST_CONTEXT_MATCH.value == "best_context_match"
        assert ResolutionStrategy.TEAM_PRIORITY.value == "team_priority"
        assert ResolutionStrategy.WEIGHTED_SCORE.value == "weighted_score"

    def test_given_resolution_strategy_when_comparing_then_enum_comparison_works(self):
        """Verify ResolutionStrategy enum comparison works correctly."""
        # Given
        strategy1 = ResolutionStrategy.HIGHEST_CONFIDENCE
        strategy2 = ResolutionStrategy.HIGHEST_CONFIDENCE
        strategy3 = ResolutionStrategy.MOST_RECENT

        # When/Then
        assert strategy1 == strategy2
        assert strategy1 != strategy3


# ResolutionResult Tests
class TestResolutionResult:
    """Test ResolutionResult dataclass."""

    def test_given_patterns_when_creating_resolution_result_then_initializes_correctly(
        self, sample_pattern, another_pattern
    ):
        """Verify ResolutionResult initialization with all fields."""
        # Given
        winning = sample_pattern
        losing = [another_pattern]
        strategy = ResolutionStrategy.HIGHEST_CONFIDENCE
        confidence = 0.9
        reasoning = "Higher confidence score"
        factors = {"confidence": 0.95, "recency": 0.85}

        # When
        result = ResolutionResult(
            winning_pattern=winning,
            losing_patterns=losing,
            strategy_used=strategy,
            confidence=confidence,
            reasoning=reasoning,
            factors=factors,
        )

        # Then
        assert result.winning_pattern == winning
        assert result.losing_patterns == losing
        assert result.strategy_used == strategy
        assert result.confidence == confidence
        assert result.reasoning == reasoning
        assert result.factors == factors

    def test_given_minimal_data_when_creating_resolution_result_then_uses_defaults(
        self, sample_pattern
    ):
        """Verify ResolutionResult with default factors."""
        # Given/When
        result = ResolutionResult(
            winning_pattern=sample_pattern,
            losing_patterns=[],
            strategy_used=ResolutionStrategy.MOST_RECENT,
            confidence=0.8,
            reasoning="Most recent",
        )

        # Then
        assert result.factors == {}


# TeamPriorities Tests
class TestTeamPriorities:
    """Test TeamPriorities dataclass."""

    def test_given_no_params_when_creating_team_priorities_then_uses_defaults(self):
        """Verify TeamPriorities default initialization."""
        # Given/When
        priorities = TeamPriorities()

        # Then
        assert priorities.readability_weight == 0.3
        assert priorities.performance_weight == 0.2
        assert priorities.security_weight == 0.3
        assert priorities.maintainability_weight == 0.2
        assert "security" in priorities.type_preferences
        assert priorities.type_preferences["security"] == 1.0
        assert priorities.preferred_tags == []

    def test_given_custom_weights_when_creating_team_priorities_then_uses_custom_values(
        self,
    ):
        """Verify TeamPriorities with custom weights."""
        # Given
        custom_types = {"security": 1.0, "custom": 0.9}
        custom_tags = ["important", "critical"]

        # When
        priorities = TeamPriorities(
            readability_weight=0.4,
            performance_weight=0.3,
            security_weight=0.2,
            maintainability_weight=0.1,
            type_preferences=custom_types,
            preferred_tags=custom_tags,
        )

        # Then
        assert priorities.readability_weight == 0.4
        assert priorities.performance_weight == 0.3
        assert priorities.type_preferences == custom_types
        assert priorities.preferred_tags == custom_tags


# ConflictResolver Tests
class TestConflictResolver:
    """Test ConflictResolver class."""

    def test_given_resolver_when_initialized_then_has_correct_attributes(
        self, team_priorities
    ):
        """Verify ConflictResolver initialization."""
        # Given/When
        resolver = ConflictResolver(team_priorities=team_priorities)

        # Then
        assert resolver.team_priorities == team_priorities
        assert hasattr(resolver, "resolution_history")

    def test_given_resolver_with_no_priorities_when_initialized_then_uses_defaults(self):
        """Verify ConflictResolver with default priorities."""
        # Given/When
        resolver = ConflictResolver()

        # Then
        assert resolver.team_priorities is not None
        assert isinstance(resolver.team_priorities, TeamPriorities)

    def test_given_two_patterns_when_resolving_with_highest_confidence_then_selects_correct_pattern(
        self, conflict_resolver, sample_pattern, high_confidence_pattern
    ):
        """Verify conflict resolution using highest confidence strategy."""
        # Given
        patterns = [sample_pattern, high_confidence_pattern]
        strategy = ResolutionStrategy.HIGHEST_CONFIDENCE

        # When
        result = conflict_resolver.resolve_patterns(patterns, strategy=strategy)

        # Then
        assert result.winning_pattern == high_confidence_pattern
        assert sample_pattern in result.losing_patterns
        assert result.strategy_used == strategy
        assert result.confidence > 0

    def test_given_two_patterns_when_resolving_with_most_recent_then_selects_newest(
        self, conflict_resolver, sample_pattern, another_pattern
    ):
        """Verify conflict resolution using most recent strategy."""
        # Given
        patterns = [sample_pattern, another_pattern]
        strategy = ResolutionStrategy.MOST_RECENT

        # When
        result = conflict_resolver.resolve_patterns(patterns, strategy=strategy)

        # Then
        assert result.winning_pattern == sample_pattern
        assert another_pattern in result.losing_patterns
        assert result.strategy_used == strategy

    def test_given_patterns_with_context_when_resolving_with_best_context_match_then_selects_best_match(
        self, conflict_resolver, sample_pattern, another_pattern
    ):
        """Verify conflict resolution using best context match strategy."""
        # Given
        patterns = [sample_pattern, another_pattern]
        context = {"language": "python", "file_type": "module"}
        strategy = ResolutionStrategy.BEST_CONTEXT_MATCH

        # When
        result = conflict_resolver.resolve_patterns(
            patterns, strategy=strategy, context=context
        )

        # Then
        assert result.winning_pattern in patterns
        assert result.strategy_used == strategy
        assert "context_match" in result.factors

    def test_given_patterns_when_resolving_with_team_priority_then_respects_priorities(
        self, conflict_resolver, sample_pattern, another_pattern
    ):
        """Verify conflict resolution using team priority strategy."""
        # Given
        patterns = [sample_pattern, another_pattern]
        strategy = ResolutionStrategy.TEAM_PRIORITY

        # When
        result = conflict_resolver.resolve_patterns(patterns, strategy=strategy)

        # Then
        # Security pattern should win due to type_preferences
        assert result.winning_pattern == another_pattern
        assert result.strategy_used == strategy

    def test_given_patterns_when_resolving_with_weighted_score_then_combines_factors(
        self, conflict_resolver, sample_pattern, another_pattern
    ):
        """Verify conflict resolution using weighted score strategy."""
        # Given
        patterns = [sample_pattern, another_pattern]
        strategy = ResolutionStrategy.WEIGHTED_SCORE

        # When
        result = conflict_resolver.resolve_patterns(patterns, strategy=strategy)

        # Then
        assert result.winning_pattern in patterns
        assert result.strategy_used == strategy
        assert len(result.factors) > 0

    def test_given_single_pattern_when_resolving_then_raises_error(
        self, conflict_resolver, sample_pattern
    ):
        """Verify resolution with single pattern raises error (needs at least 2)."""
        # Given
        patterns = [sample_pattern]

        # When/Then
        with pytest.raises(ValueError, match="at least 2 patterns"):
            conflict_resolver.resolve_patterns(patterns)

    def test_given_empty_patterns_when_resolving_then_raises_error(
        self, conflict_resolver
    ):
        """Verify resolution with empty patterns raises error."""
        # Given
        patterns = []

        # When/Then
        with pytest.raises((ValueError, IndexError)):
            conflict_resolver.resolve_patterns(patterns)

    def test_given_patterns_when_calculating_pattern_score_then_returns_valid_score(
        self, conflict_resolver, sample_pattern
    ):
        """Verify pattern score calculation."""
        # Given
        context = {"language": "python"}

        # When
        score = conflict_resolver._calculate_pattern_score(
            sample_pattern, context, ResolutionStrategy.WEIGHTED_SCORE
        )

        # Then
        assert isinstance(score, dict)
        assert "total" in score
        assert score["total"] >= 0

    def test_given_pattern_and_context_when_calculating_context_match_then_returns_score(
        self, conflict_resolver, sample_pattern
    ):
        """Verify context match calculation."""
        # Given
        context = {"language": "python", "file_type": "module"}

        # When
        match_score = conflict_resolver._calculate_context_match(
            sample_pattern, context
        )

        # Then
        assert isinstance(match_score, (float, int))
        assert 0 <= match_score <= 1

    def test_given_pattern_when_calculating_team_alignment_then_returns_score(
        self, conflict_resolver, sample_pattern
    ):
        """Verify team alignment calculation."""
        # Given
        context = {"language": "python"}

        # When
        alignment = conflict_resolver._calculate_team_alignment(sample_pattern, context)

        # Then
        assert isinstance(alignment, (float, int))
        assert alignment >= 0

    def test_given_resolution_result_when_generating_reasoning_then_returns_string(
        self, conflict_resolver, sample_pattern, another_pattern
    ):
        """Verify reasoning generation."""
        # Given
        result = ResolutionResult(
            winning_pattern=sample_pattern,
            losing_patterns=[another_pattern],
            strategy_used=ResolutionStrategy.HIGHEST_CONFIDENCE,
            confidence=0.9,
            reasoning="",
            factors={"confidence": 0.9},
        )

        # When
        reasoning = conflict_resolver._generate_reasoning(
            sample_pattern,
            [another_pattern],
            {"confidence": 0.9},
            {},
            ResolutionStrategy.HIGHEST_CONFIDENCE,
        )

        # Then
        assert isinstance(reasoning, str)
        assert len(reasoning) > 0

    def test_given_resolver_with_history_when_getting_stats_then_returns_statistics(
        self, conflict_resolver, sample_pattern, another_pattern
    ):
        """Verify resolution statistics retrieval."""
        # Given
        patterns = [sample_pattern, another_pattern]
        conflict_resolver.resolve_patterns(patterns)

        # When
        stats = conflict_resolver.get_resolution_stats()

        # Then
        assert isinstance(stats, dict)
        assert "total_resolutions" in stats or len(stats) >= 0

    def test_given_resolver_with_history_when_clearing_history_then_history_is_empty(
        self, conflict_resolver, sample_pattern, another_pattern
    ):
        """Verify history clearing."""
        # Given
        patterns = [sample_pattern, another_pattern]
        conflict_resolver.resolve_patterns(patterns)

        # When
        conflict_resolver.clear_history()

        # Then
        stats = conflict_resolver.get_resolution_stats()
        assert stats.get("total_resolutions", 0) == 0 or len(stats) == 0


# AgentTask Tests
class TestAgentTask:
    """Test AgentTask dataclass."""

    def test_given_task_data_when_creating_agent_task_then_initializes_correctly(self):
        """Verify AgentTask initialization."""
        # Given
        task_id = "task_1"
        agent_id = "agent_1"
        task_type = "code_review"
        priority = 5
        data = {"file": "test.py"}

        # When
