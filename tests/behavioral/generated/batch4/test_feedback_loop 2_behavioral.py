"""Behavioral tests for feedback_loop 2.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

from __future__ import annotations

import json
from datetime import datetime, timedelta
from typing import Any
from unittest.mock import MagicMock, Mock, mock_open, patch

import pytest

from empathy_os.telemetry.feedback_loop_2 import (
    FeedbackEntry,
    FeedbackLoop,
    ModelTier,
    QualityStats,
    TierRecommendation,
)


# Fixtures


@pytest.fixture
def sample_feedback_data() -> dict[str, Any]:
    """Given a sample feedback entry data dictionary."""
    return {
        "feedback_id": "test-123",
        "workflow_name": "code-review",
        "stage_name": "analysis",
        "tier": ModelTier.CHEAP,
        "quality_score": 0.8,
        "timestamp": datetime(2025, 1, 15, 12, 0, 0),
        "metadata": {"response_length": 500, "tokens": 150},
    }


@pytest.fixture
def feedback_entry(sample_feedback_data: dict[str, Any]) -> FeedbackEntry:
    """Given a sample FeedbackEntry instance."""
    return FeedbackEntry(**sample_feedback_data)


@pytest.fixture
def feedback_loop() -> FeedbackLoop:
    """Given a FeedbackLoop instance."""
    return FeedbackLoop()


@pytest.fixture
def feedback_loop_with_data(feedback_loop: FeedbackLoop) -> FeedbackLoop:
    """Given a FeedbackLoop with pre-populated feedback data."""
    # Add multiple feedback entries
    feedback_loop.record_feedback(
        workflow_name="code-review",
        stage_name="analysis",
        tier=ModelTier.CHEAP,
        quality_score=0.6,
        metadata={"tokens": 100},
    )
    feedback_loop.record_feedback(
        workflow_name="code-review",
        stage_name="analysis",
        tier=ModelTier.CHEAP,
        quality_score=0.7,
        metadata={"tokens": 120},
    )
    feedback_loop.record_feedback(
        workflow_name="code-review",
        stage_name="analysis",
        tier=ModelTier.CAPABLE,
        quality_score=0.9,
        metadata={"tokens": 200},
    )
    feedback_loop.record_feedback(
        workflow_name="code-review",
        stage_name="generation",
        tier=ModelTier.CHEAP,
        quality_score=0.5,
        metadata={"tokens": 80},
    )
    return feedback_loop


# ModelTier Tests


class TestModelTier:
    """Tests for ModelTier enum."""

    def test_given_model_tier_enum_when_accessing_values_then_returns_correct_strings(self):
        """Given ModelTier enum, when accessing values, then returns correct string values."""
        # When/Then
        assert ModelTier.CHEAP == "cheap"
        assert ModelTier.CAPABLE == "capable"
        assert ModelTier.PREMIUM == "premium"

    def test_given_model_tier_when_comparing_values_then_equality_works(self):
        """Given ModelTier values, when comparing, then equality works correctly."""
        # When/Then
        assert ModelTier.CHEAP == ModelTier.CHEAP
        assert ModelTier.CHEAP != ModelTier.CAPABLE
        assert ModelTier.CHEAP == "cheap"


# FeedbackEntry Tests


class TestFeedbackEntry:
    """Tests for FeedbackEntry dataclass."""

    def test_given_feedback_data_when_creating_entry_then_initializes_correctly(
        self, sample_feedback_data: dict[str, Any]
    ):
        """Given feedback data, when creating FeedbackEntry, then initializes with correct values."""
        # When
        entry = FeedbackEntry(**sample_feedback_data)

        # Then
        assert entry.feedback_id == "test-123"
        assert entry.workflow_name == "code-review"
        assert entry.stage_name == "analysis"
        assert entry.tier == ModelTier.CHEAP
        assert entry.quality_score == 0.8
        assert entry.timestamp == datetime(2025, 1, 15, 12, 0, 0)
        assert entry.metadata == {"response_length": 500, "tokens": 150}

    def test_given_feedback_entry_when_converting_to_dict_then_returns_serializable_dict(
        self, feedback_entry: FeedbackEntry
    ):
        """Given FeedbackEntry, when converting to dict, then returns properly serialized dictionary."""
        # When
        result = feedback_entry.to_dict()

        # Then
        assert result["feedback_id"] == "test-123"
        assert result["workflow_name"] == "code-review"
        assert result["stage_name"] == "analysis"
        assert result["tier"] == ModelTier.CHEAP
        assert result["quality_score"] == 0.8
        assert result["timestamp"] == "2025-01-15T12:00:00"
        assert result["metadata"] == {"response_length": 500, "tokens": 150}

    def test_given_dict_with_string_timestamp_when_creating_from_dict_then_parses_correctly(self):
        """Given dict with string timestamp, when creating FeedbackEntry, then parses ISO format."""
        # Given
        data = {
            "feedback_id": "test-456",
            "workflow_name": "testing",
            "stage_name": "validation",
            "tier": "capable",
            "quality_score": 0.9,
            "timestamp": "2025-01-15T14:30:00",
            "metadata": {},
        }

        # When
        entry = FeedbackEntry.from_dict(data)

        # Then
        assert entry.feedback_id == "test-456"
        assert entry.timestamp == datetime(2025, 1, 15, 14, 30, 0)
        assert entry.quality_score == 0.9

    def test_given_dict_with_datetime_timestamp_when_creating_from_dict_then_uses_datetime(self):
        """Given dict with datetime timestamp, when creating FeedbackEntry, then uses datetime directly."""
        # Given
        timestamp = datetime(2025, 1, 16, 10, 0, 0)
        data = {
            "feedback_id": "test-789",
            "workflow_name": "testing",
            "stage_name": "validation",
            "tier": "premium",
            "quality_score": 0.95,
            "timestamp": timestamp,
            "metadata": {},
        }

        # When
        entry = FeedbackEntry.from_dict(data)

        # Then
        assert entry.timestamp == timestamp

    def test_given_dict_with_invalid_timestamp_when_creating_from_dict_then_uses_current_time(self):
        """Given dict with invalid timestamp, when creating FeedbackEntry, then uses current UTC time."""
        # Given
        data = {
            "feedback_id": "test-invalid",
            "workflow_name": "testing",
            "stage_name": "validation",
            "tier": "cheap",
            "quality_score": 0.7,
            "timestamp": None,
            "metadata": {},
        }

        # When
        with patch("empathy_os.telemetry.feedback_loop_2.datetime") as mock_datetime:
            mock_now = datetime(2025, 1, 20, 15, 0, 0)
            mock_datetime.utcnow.return_value = mock_now
            mock_datetime.fromisoformat = datetime.fromisoformat
            entry = FeedbackEntry.from_dict(data)

        # Then
        assert entry.timestamp == mock_now

    def test_given_feedback_entry_without_metadata_when_created_then_has_empty_dict(self):
        """Given FeedbackEntry without metadata, when created, then has empty metadata dict."""
        # When
        entry = FeedbackEntry(
            feedback_id="test-no-meta",
            workflow_name="test",
            stage_name="test",
            tier=ModelTier.CHEAP,
            quality_score=0.5,
            timestamp=datetime.utcnow(),
        )

        # Then
        assert entry.metadata == {}


# QualityStats Tests


class TestQualityStats:
    """Tests for QualityStats dataclass."""

    def test_given_quality_stats_data_when_creating_then_initializes_correctly(self):
        """Given quality stats data, when creating QualityStats, then initializes with correct values."""
        # When
        stats = QualityStats(
            workflow_name="code-review",
            stage_name="analysis",
            tier=ModelTier.CHEAP,
            avg_quality=0.75,
            sample_count=10,
            min_quality=0.5,
            max_quality=0.95,
        )

        # Then
        assert stats.workflow_name == "code-review"
        assert stats.stage_name == "analysis"
        assert stats.tier == ModelTier.CHEAP
        assert stats.avg_quality == 0.75
        assert stats.sample_count == 10
        assert stats.min_quality == 0.5
        assert stats.max_quality == 0.95


# TierRecommendation Tests


class TestTierRecommendation:
    """Tests for TierRecommendation dataclass."""

    def test_given_tier_recommendation_data_when_creating_then_initializes_correctly(self):
        """Given tier recommendation data, when creating TierRecommendation, then initializes correctly."""
        # When
        recommendation = TierRecommendation(
            current_tier=ModelTier.CHEAP,
            recommended_tier=ModelTier.CAPABLE,
            confidence=0.85,
            reason="Quality below threshold",
        )

        # Then
        assert recommendation.current_tier == ModelTier.CHEAP
        assert recommendation.recommended_tier == ModelTier.CAPABLE
        assert recommendation.confidence == 0.85
        assert recommendation.reason == "Quality below threshold"


# FeedbackLoop Tests


class TestFeedbackLoopInitialization:
    """Tests for FeedbackLoop initialization."""

    def test_given_default_parameters_when_creating_feedback_loop_then_initializes_with_defaults(self):
        """Given default parameters, when creating FeedbackLoop, then initializes with default values."""
        # When
        loop = FeedbackLoop()

        # Then
        assert loop.quality_threshold == 0.7
        assert loop.upgrade_threshold == 0.85
        assert loop.downgrade_threshold == 0.6
        assert loop.min_samples == 5
        assert loop.time_window_hours == 24
        assert loop._feedback_store == []

    def test_given_custom_parameters_when_creating_feedback_loop_then_initializes_with_custom_values(self):
        """Given custom parameters, when creating FeedbackLoop, then initializes with custom values."""
        # When
        loop = FeedbackLoop(
            quality_threshold=0.8,
            upgrade_threshold=0.9,
            downgrade_threshold=0.5,
            min_samples=10,
            time_window_hours=48,
        )

        # Then
        assert loop.quality_threshold == 0.8
        assert loop.upgrade_threshold == 0.9
        assert loop.downgrade_threshold == 0.5
        assert loop.min_samples == 10
        assert loop.time_window_hours == 48


class TestFeedbackLoopRecordFeedback:
    """Tests for FeedbackLoop.record_feedback method."""

    def test_given_valid_feedback_when_recording_then_stores_entry(self, feedback_loop: FeedbackLoop):
        """Given valid feedback data, when recording feedback, then stores entry successfully."""
        # When
        feedback_id = feedback_loop.record_feedback(
            workflow_name="code-review",
            stage_name="analysis",
            tier=ModelTier.CHEAP,
            quality_score=0.8,
            metadata={"tokens": 150},
        )

        # Then
        assert feedback_id is not None
        assert len(feedback_loop._feedback_store) == 1
        entry = feedback_loop._feedback_store[0]
        assert entry.workflow_name == "code-review"
        assert entry.stage_name == "analysis"
        assert entry.tier == ModelTier.CHEAP
        assert entry.quality_score == 0.8
        assert entry.metadata == {"tokens": 150}

    def test_given_feedback_without_metadata_when_recording_then_stores_with_empty_metadata(
        self, feedback_loop: FeedbackLoop
    ):
        """Given feedback without metadata, when recording, then stores with empty metadata."""
        # When
        feedback_id = feedback_loop.record_feedback(
            workflow_name="test",
            stage_name="test",
            tier=ModelTier.CAPABLE,
            quality_score=0.9,
        )

        # Then
        entry = feedback_loop._feedback_store[0]
        assert entry.metadata == {}

    def test_given_multiple_feedback_entries_when_recording_then_stores_all(
        self, feedback_loop: FeedbackLoop
    ):
        """Given multiple feedback entries, when recording, then stores all entries."""
        # When
        id1 = feedback_loop.record_feedback("wf1", "stage1", ModelTier.CHEAP, 0.7)
        id2 = feedback_loop.record_feedback("wf2", "stage2", ModelTier.CAPABLE, 0.8)
        id3 = feedback_loop.record_feedback("wf3", "stage3", ModelTier.PREMIUM, 0.9)

        # Then
        assert len(feedback_loop._feedback_store) == 3
        assert id1 != id2 != id3

    @patch("empathy_os.telemetry.feedback_loop_2.uuid4")
    def test_given_uuid_generator_when_recording_feedback_then_uses_uuid_for_id(
        self, mock_uuid: Mock, feedback_loop: FeedbackLoop
    ):
        """Given UUID generator, when recording feedback, then uses UUID for feedback_id."""
        # Given
        mock_uuid.return_value = Mock(hex="abc123def456")

        # When
        feedback_id = feedback_loop.record_feedback(
            "test", "test", ModelTier.CHEAP, 0.5
        )

        # Then
        assert feedback_id == "abc123def456"


class TestFeedbackLoopGetQualityStats:
    """Tests for FeedbackLoop.get_quality_stats method."""

    def test_given_feedback_data_when_getting_stats_then_returns_correct_statistics(
        self, feedback_loop_with_data: FeedbackLoop
    ):
        """Given feedback data, when getting quality stats, then returns correct statistics."""
        # When
        stats = feedback_loop_with_data.get_quality_stats(
            workflow_name="code-review",
            stage_name="analysis",
            tier=ModelTier.CHEAP,
        )

        # Then
        assert stats is not None
        assert stats.workflow_name == "code-review"
        assert stats.stage_name == "analysis"
        assert stats.tier == ModelTier.CHEAP
        assert stats.sample_count == 2
        assert stats.avg_quality == 0.65  # (0.6 + 0.7) / 2
        assert stats.min_quality == 0.6
        assert stats.max_quality == 0.7

    def test_given_no_matching_feedback_when_getting_stats_then_returns_none(
        self, feedback_loop: FeedbackLoop
    ):
        """Given no matching feedback, when getting quality