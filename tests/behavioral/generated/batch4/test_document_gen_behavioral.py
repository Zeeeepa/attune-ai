"""Behavioral tests for document_gen.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import logging
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock, Mock, patch

import pytest

from empathy_os.workflows.document_gen import (
    DOC_GEN_STEPS,
    TOKEN_COSTS,
    DocumentGenerationWorkflow,
    ModelTier,
)


@pytest.fixture
def mock_executor():
    """Fixture providing a mock executor for workflow execution."""
    executor = AsyncMock()
    executor.execute_step = AsyncMock(return_value={"content": "test result"})
    return executor


@pytest.fixture
def workflow_basic():
    """Fixture providing a basic DocumentGenerationWorkflow instance."""
    return DocumentGenerationWorkflow()


@pytest.fixture
def workflow_custom():
    """Fixture providing a customized DocumentGenerationWorkflow instance."""
    return DocumentGenerationWorkflow(
        skip_polish_threshold=2000,
        max_sections=5,
        max_write_tokens=5000,
        section_focus=["Overview", "API"],
        chunked_generation=False,
        sections_per_chunk=2,
        max_cost=10.0,
        cost_warning_threshold=0.9,
        graceful_degradation=False,
        export_path="docs/test",
        max_display_length=200,
    )


@pytest.fixture
def sample_source_code():
    """Fixture providing sample source code for testing."""
    return """
def hello_world():
    '''Print hello world.'''
    print("Hello, World!")

class Example:
    '''Example class.'''
    def __init__(self):
        self.value = 42
"""


@pytest.fixture
def mock_outline_result():
    """Fixture providing a mock outline result."""
    return {
        "outline": "# API Documentation\n## Section 1\n## Section 2",
        "sections": ["Section 1", "Section 2"],
    }


@pytest.fixture
def mock_write_result():
    """Fixture providing a mock write result."""
    return {"content": "Detailed documentation content for section"}


@pytest.fixture
def mock_polish_result():
    """Fixture providing a mock polish result."""
    return {"polished": "Final polished documentation"}


class TestDocumentGenerationWorkflowInitialization:
    """Test suite for DocumentGenerationWorkflow initialization."""

    def test_given_no_params_when_initialized_then_uses_defaults(self):
        """Given no parameters, when workflow is initialized, then it uses default values."""
        # When
        workflow = DocumentGenerationWorkflow()

        # Then
        assert workflow.name == "doc-gen"
        assert workflow.description == "Cost-optimized documentation generation pipeline"
        assert workflow.stages == ["outline", "write", "polish"]
        assert workflow.skip_polish_threshold == 1000
        assert workflow.max_sections == 10
        assert workflow.max_write_tokens is None
        assert workflow.section_focus is None
        assert workflow.chunked_generation is True
        assert workflow.sections_per_chunk == 3
        assert workflow.max_cost == 5.0
        assert workflow.cost_warning_threshold == 0.8
        assert workflow.graceful_degradation is True
        assert workflow.export_path is None
        assert workflow.max_display_length == 500

    def test_given_custom_params_when_initialized_then_uses_custom_values(
        self, workflow_custom
    ):
        """Given custom parameters, when workflow is initialized, then it uses custom values."""
        # Then
        assert workflow_custom.skip_polish_threshold == 2000
        assert workflow_custom.max_sections == 5
        assert workflow_custom.max_write_tokens == 5000
        assert workflow_custom.section_focus == ["Overview", "API"]
        assert workflow_custom.chunked_generation is False
        assert workflow_custom.sections_per_chunk == 2
        assert workflow_custom.max_cost == 10.0
        assert workflow_custom.cost_warning_threshold == 0.9
        assert workflow_custom.graceful_degradation is False
        assert workflow_custom.export_path == "docs/test"
        assert workflow_custom.max_display_length == 200

    def test_given_tier_map_when_accessed_then_returns_correct_tiers(
        self, workflow_basic
    ):
        """Given tier_map, when accessed, then it returns correct model tiers for each stage."""
        # Then
        assert workflow_basic.tier_map["outline"] == ModelTier.CHEAP
        assert workflow_basic.tier_map["write"] == ModelTier.CAPABLE
        assert workflow_basic.tier_map["polish"] == ModelTier.PREMIUM


class TestDocumentGenerationWorkflowEstimateCost:
    """Test suite for cost estimation functionality."""

    def test_given_small_input_when_estimate_cost_then_returns_reasonable_cost(
        self, workflow_basic
    ):
        """Given small input, when estimating cost, then returns reasonable cost estimate."""
        # Given
        input_text = "Short documentation request"
        expected_tokens = len(input_text.split()) * 2  # Rough estimate

        # When
        cost = workflow_basic._estimate_cost(input_text)

        # Then
        assert cost > 0
        assert cost < 1.0  # Should be under $1 for small input

    def test_given_large_input_when_estimate_cost_then_returns_higher_cost(
        self, workflow_basic
    ):
        """Given large input, when estimating cost, then returns higher cost estimate."""
        # Given
        small_input = "Short text"
        large_input = "Long text " * 1000

        # When
        small_cost = workflow_basic._estimate_cost(small_input)
        large_cost = workflow_basic._estimate_cost(large_input)

        # Then
        assert large_cost > small_cost

    def test_given_empty_input_when_estimate_cost_then_returns_minimal_cost(
        self, workflow_basic
    ):
        """Given empty input, when estimating cost, then returns minimal cost."""
        # Given
        input_text = ""

        # When
        cost = workflow_basic._estimate_cost(input_text)

        # Then
        assert cost >= 0
        assert cost < 0.1  # Should be very small


class TestDocumentGenerationWorkflowGenerateOutline:
    """Test suite for outline generation stage."""

    @pytest.mark.asyncio
    async def test_given_source_code_when_generate_outline_then_creates_outline(
        self, workflow_basic, mock_executor, sample_source_code
    ):
        """Given source code, when generating outline, then creates structured outline."""
        # Given
        mock_executor.execute_step.return_value = {
            "outline": "# Documentation\n## Introduction\n## API Reference"
        }

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic._generate_outline(
                source_code=sample_source_code,
                doc_type="api_reference",
                audience="developers",
            )

        # Then
        assert "outline" in result
        assert "#" in result["outline"]
        mock_executor.execute_step.assert_called_once()

    @pytest.mark.asyncio
    async def test_given_requirements_when_generate_outline_then_includes_requirements(
        self, workflow_basic, mock_executor
    ):
        """Given requirements, when generating outline, then includes them in prompt."""
        # Given
        requirements = "Must include examples and best practices"
        mock_executor.execute_step.return_value = {"outline": "# Docs"}

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            await workflow_basic._generate_outline(
                source_code="code",
                doc_type="guide",
                audience="developers",
                requirements=requirements,
            )

        # Then
        call_args = mock_executor.execute_step.call_args
        prompt = call_args[1]["prompt"]
        assert requirements in prompt

    @pytest.mark.asyncio
    async def test_given_executor_error_when_generate_outline_then_raises_exception(
        self, workflow_basic, mock_executor
    ):
        """Given executor error, when generating outline, then raises exception."""
        # Given
        mock_executor.execute_step.side_effect = Exception("Executor failed")

        # When/Then
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            with pytest.raises(Exception, match="Executor failed"):
                await workflow_basic._generate_outline(
                    source_code="code", doc_type="guide", audience="developers"
                )


class TestDocumentGenerationWorkflowWriteSections:
    """Test suite for content writing stage."""

    @pytest.mark.asyncio
    async def test_given_sections_when_write_sections_then_generates_content(
        self, workflow_basic, mock_executor, sample_source_code
    ):
        """Given sections, when writing sections, then generates content for each."""
        # Given
        sections = ["Introduction", "API Reference"]
        mock_executor.execute_step.return_value = {"content": "Section content"}

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic._write_sections(
                outline="# Docs\n## Introduction\n## API Reference",
                sections=sections,
                source_code=sample_source_code,
                doc_type="api",
                audience="developers",
            )

        # Then
        assert len(result) == len(sections)
        assert all("content" in r for r in result)

    @pytest.mark.asyncio
    async def test_given_section_focus_when_write_sections_then_filters_sections(
        self, workflow_basic, mock_executor, sample_source_code
    ):
        """Given section_focus, when writing sections, then only writes focused sections."""
        # Given
        workflow_basic.section_focus = ["Introduction"]
        sections = ["Introduction", "API Reference", "Examples"]
        mock_executor.execute_step.return_value = {"content": "Content"}

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic._write_sections(
                outline="# Docs",
                sections=sections,
                source_code=sample_source_code,
                doc_type="api",
                audience="developers",
            )

        # Then
        assert len(result) == 1

    @pytest.mark.asyncio
    async def test_given_max_sections_when_write_sections_then_limits_sections(
        self, workflow_basic, mock_executor, sample_source_code
    ):
        """Given max_sections, when writing sections, then limits number of sections."""
        # Given
        workflow_basic.max_sections = 2
        sections = ["Intro", "API", "Examples", "Conclusion"]
        mock_executor.execute_step.return_value = {"content": "Content"}

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic._write_sections(
                outline="# Docs",
                sections=sections,
                source_code=sample_source_code,
                doc_type="api",
                audience="developers",
            )

        # Then
        assert len(result) <= workflow_basic.max_sections

    @pytest.mark.asyncio
    async def test_given_empty_sections_when_write_sections_then_returns_empty_list(
        self, workflow_basic, mock_executor, sample_source_code
    ):
        """Given empty sections, when writing sections, then returns empty list."""
        # Given
        sections = []

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic._write_sections(
                outline="# Docs",
                sections=sections,
                source_code=sample_source_code,
                doc_type="api",
                audience="developers",
            )

        # Then
        assert result == []
        mock_executor.execute_step.assert_not_called()


class TestDocumentGenerationWorkflowPolishDocument:
    """Test suite for document polishing stage."""

    @pytest.mark.asyncio
    async def test_given_document_when_polish_document_then_returns_polished_version(
        self, workflow_basic, mock_executor
    ):
        """Given document, when polishing, then returns polished version."""
        # Given
        document = "# Documentation\nContent here"
        mock_executor.execute_step.return_value = {"polished": "Polished content"}

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic._polish_document(
                document=document, doc_type="api", audience="developers"
            )

        # Then
        assert "polished" in result
        mock_executor.execute_step.assert_called_once()

    @pytest.mark.asyncio
    async def test_given_short_document_when_polish_document_then_skips_polish(
        self, workflow_basic, mock_executor
    ):
        """Given short document, when polishing, then skips polish if below threshold."""
        # Given
        workflow_basic.skip_polish_threshold = 1000
        document = "Short doc"

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic._polish_document(
                document=document, doc_type="api", audience="developers"
            )

        # Then
        assert result == {"polished": document}
        mock_executor.execute_step.assert_not_called()

    @pytest.mark.asyncio
    async def test_given_large_document_when_polish_document_then_chunks_processing(
        self, workflow_basic, mock_executor
    ):
        """Given large document, when polishing, then chunks processing if needed."""
        # Given
        large_document = "Content " * 10000  # Very large document
        mock_executor.execute_step.return_value = {"polished": "Polished chunk"}

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic._polish_document(
                document=large_document, doc_type="api", audience="developers"
            )

        # Then
        assert "polished" in result

    @pytest.mark.asyncio
    async def test_given_requirements_when_polish_document_then_includes_in_prompt(
        self, workflow_basic, mock_executor
    ):
        """Given requirements, when polishing, then includes them in prompt."""
        # Given
        document = "Long document " * 200
        requirements = "Must be concise"
        mock_executor.execute_step.return_value = {"polished": "Polished"}

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            await workflow_basic._polish_document(
                document=document,
                doc_type="api",
                audience="developers",
                requirements=requirements,
            )

        # Then
        call_args = mock_executor.execute_step.call_args
        prompt = call_args[1]["prompt"]
        assert requirements in prompt


class TestDocumentGenerationWorkflowCostGuardrails:
    """Test suite for cost guardrails functionality."""

    @pytest.mark.asyncio
    async def test_given_high_cost_when_execute_then_warns_about_cost(
        self, workflow_basic, mock_executor, sample_source_code, caplog
    ):
        """Given high estimated cost, when executing, then warns about cost."""
        # Given
        large_input = "Generate extensive documentation " * 1000
        mock_executor.execute_step.return_value = {
            "outline": "# Docs",
            "sections": ["Intro"],
            "content": "Content",
            "polished": "Polished",
        }

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            with caplog.at_level(logging.WARNING):
                with patch.object(
                    workflow_basic, "_estimate_cost", return_value=4.5
                ):  # 90% of max
                    try:
                        await workflow_basic.execute(
                            source_code=large_input,
                            doc_type="api",
                            audience="developers",
                        )
                    except Exception:
                        pass

        # Then - check if cost was considered
        assert workflow_basic.max_cost > 0

    @pytest.mark.asyncio
    async def test_given_cost_exceeds_max_when_execute_then_raises_error(
        self, workflow_basic, mock_executor, sample_source_code
    ):
        """Given cost exceeds max_cost, when executing, then raises error."""
        # Given
        workflow_basic.max_cost = 0.01  # Very low limit
        mock_executor.execute_step.return_value = {"outline": "# Docs"}

        # When/Then
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            with patch.object(workflow_basic, "_estimate_cost", return_value=10.0):
                with pytest.raises(ValueError, match="Estimated cost.*exceeds"):
                    await workflow_basic.execute(
                        source_code=sample_source_code,
                        doc_type="api",
                        audience="developers",
                    )


class TestDocumentGenerationWorkflowGracefulDegradation:
    """Test suite for graceful degradation functionality."""

    @pytest.mark.asyncio
    async def test_given_error_and_graceful_degradation_when_execute_then_returns_partial(
        self, workflow_basic, mock_executor, sample_source_code
    ):
        """Given error with graceful_degradation enabled, when executing, then returns partial results."""
        # Given
        workflow_basic.graceful_degradation = True
        mock_executor.execute_step.side_effect = [
            {"outline": "# Docs", "sections": ["Intro"]},
            Exception("Write failed"),
        ]

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic.execute(
                source_code=sample_source_code, doc_type="api", audience="developers"
            )

        # Then
        assert result["status"] in ["error", "partial_success"]
        assert "outline" in result or "error" in result

    @pytest.mark.asyncio
    async def test_given_error_and_no_graceful_degradation_when_execute_then_raises(
        self, workflow_basic, mock_executor, sample_source_code
    ):
        """Given error without graceful_degradation, when executing, then raises exception."""
        # Given
        workflow_basic.graceful_degradation = False
        mock_executor.execute_step.side_effect = Exception("Fatal error")

        # When/Then
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            with pytest.raises(Exception, match="Fatal error"):
                await workflow_basic.execute(
                    source_code=sample_source_code, doc_type="api", audience="developers"
                )


class TestDocumentGenerationWorkflowExport:
    """Test suite for document export functionality."""

    @pytest.mark.asyncio
    async def test_given_export_path_when_execute_then_exports_document(
        self, workflow_basic, mock_executor, sample_source_code, tmp_path
    ):
        """Given export_path, when executing successfully, then exports document to file."""
        # Given
        export_path = tmp_path / "docs"
        workflow_basic.export_path = str(export_path)
        mock_executor.execute_step.side_effect = [
            {"outline": "# Docs", "sections": ["Intro"]},
            {"content": "Section content"},
            {"polished": "Final doc"},
        ]

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            with patch("empathy_os.workflows.document_gen._validate_file_path"):
                with patch("builtins.open", create=True) as mock_open:
                    mock_file = MagicMock()
                    mock_open.return_value.__enter__.return_value = mock_file
                    result = await workflow_basic.execute(
                        source_code=sample_source_code,
                        doc_type="api",
                        audience="developers",
                    )

        # Then
        assert result["status"] == "success"

    @pytest.mark.asyncio
    async def test_given_invalid_export_path_when_execute_then_handles_error(
        self, workflow_basic, mock_executor, sample_source_code
    ):
        """Given invalid export_path, when executing, then handles export error gracefully."""
        # Given
        workflow_basic.export_path = "/invalid/path/docs"
        workflow_basic.graceful_degradation = True
        mock_executor.execute_step.side_effect = [
            {"outline": "# Docs", "sections": ["Intro"]},
            {"content": "Content"},
            {"polished": "Final"},
        ]

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            with patch(
                "empathy_os.workflows.document_gen._validate_file_path",
                side_effect=ValueError("Invalid path"),
            ):
                result = await workflow_basic.execute(
                    source_code=sample_source_code, doc_type="api", audience="developers"
                )

        # Then
        # Should still succeed even if export fails with graceful degradation
        assert "status" in result


class TestDocumentGenerationWorkflowExecute:
    """Test suite for main workflow execution."""

    @pytest.mark.asyncio
    async def test_given_valid_inputs_when_execute_then_returns_success(
        self, workflow_basic, mock_executor, sample_source_code
    ):
        """Given valid inputs, when executing workflow, then returns success result."""
        # Given
        mock_executor.execute_step.side_effect = [
            {"outline": "# API Docs\n## Intro", "sections": ["Intro"]},
            {"content": "Introduction content"},
            {"polished": "Final polished documentation"},
        ]

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic.execute(
                source_code=sample_source_code, doc_type="api", audience="developers"
            )

        # Then
        assert result["status"] == "success"
        assert "document" in result or "polished" in result
        assert "metadata" in result
        assert result["metadata"]["doc_type"] == "api"
        assert result["metadata"]["audience"] == "developers"

    @pytest.mark.asyncio
    async def test_given_all_optional_params_when_execute_then_uses_them(
        self, workflow_basic, mock_executor, sample_source_code
    ):
        """Given all optional parameters, when executing, then uses them appropriately."""
        # Given
        requirements = "Must include code examples"
        context = {"project": "TestProject"}
        mock_executor.execute_step.side_effect = [
            {"outline": "# Docs", "sections": ["Intro"]},
            {"content": "Content"},
            {"polished": "Final"},
        ]

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic.execute(
                source_code=sample_source_code,
                doc_type="guide",
                audience="beginners",
                requirements=requirements,
                context=context,
            )

        # Then
        assert result["status"] == "success"
        assert result["metadata"]["requirements"] == requirements
        assert result["metadata"]["context"] == context

    @pytest.mark.asyncio
    async def test_given_missing_source_code_when_execute_then_handles_error(
        self, workflow_basic, mock_executor
    ):
        """Given missing source_code, when executing, then handles error appropriately."""
        # Given
        workflow_basic.graceful_degradation = True

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic.execute(
                source_code="", doc_type="api", audience="developers"
            )

        # Then
        # Should handle empty source gracefully or return appropriate error
        assert "status" in result

    @pytest.mark.asyncio
    async def test_given_chunked_generation_when_execute_then_processes_in_chunks(
        self, workflow_basic, mock_executor, sample_source_code
    ):
        """Given chunked_generation enabled, when executing, then processes sections in chunks."""
        # Given
        workflow_basic.chunked_generation = True
        workflow_basic.sections_per_chunk = 2
        sections = ["Intro", "API", "Examples", "Conclusion"]
        mock_executor.execute_step.side_effect = [
            {"outline": "# Docs", "sections": sections},
            {"content": "Content 1"},
            {"content": "Content 2"},
            {"content": "Content 3"},
            {"content": "Content 4"},
            {"polished": "Final"},
        ]

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic.execute(
                source_code=sample_source_code, doc_type="api", audience="developers"
            )

        # Then
        assert result["status"] == "success"


class TestDocumentGenerationWorkflowTokenCosts:
    """Test suite for token cost constants."""

    def test_given_token_costs_when_accessed_then_has_all_tiers(self):
        """Given TOKEN_COSTS, when accessed, then has costs for all model tiers."""
        # Then
        assert ModelTier.CHEAP in TOKEN_COSTS
        assert ModelTier.CAPABLE in TOKEN_COSTS
        assert ModelTier.PREMIUM in TOKEN_COSTS

    def test_given_token_costs_when_accessed_then_has_input_output_prices(self):
        """Given TOKEN_COSTS, when accessed, then has input and output prices for each tier."""
        # Then
        for tier in [ModelTier.CHEAP, ModelTier.CAPABLE, ModelTier.PREMIUM]:
            assert "input" in TOKEN_COSTS[tier]
            assert "output" in TOKEN_COSTS[tier]
            assert TOKEN_COSTS[tier]["input"] > 0
            assert TOKEN_COSTS[tier]["output"] > 0

    def test_given_token_costs_when_compared_then_premium_costs_more_than_cheap(self):
        """Given TOKEN_COSTS, when compared, then premium costs more than cheap."""
        # Then
        assert TOKEN_COSTS[ModelTier.PREMIUM]["input"] > TOKEN_COSTS[ModelTier.CHEAP]["input"]
        assert TOKEN_COSTS[ModelTier.PREMIUM]["output"] > TOKEN_COSTS[ModelTier.CHEAP]["output"]


class TestDocGenStepsConfig:
    """Test suite for DOC_GEN_STEPS configuration."""

    def test_given_doc_gen_steps_when_accessed_then_has_polish_config(self):
        """Given DOC_GEN_STEPS, when accessed, then has polish step configuration."""
        # Then
        assert "polish" in DOC_GEN_STEPS
        assert DOC_GEN_STEPS["polish"].name == "polish"
        assert DOC_GEN_STEPS["polish"].task_type == "final_review"
        assert DOC_GEN_STEPS["polish"].tier_hint == "premium"

    def test_given_polish_config_when_accessed_then_has_reasonable_max_tokens(self):
        """Given polish config, when accessed, then has reasonable max_tokens."""
        # Then
        polish_config = DOC_GEN_STEPS["polish"]
        assert polish_config.max_tokens > 0
        assert polish_config.max_tokens <= 100000  # Reasonable upper bound


class TestDocumentGenerationWorkflowMetadata:
    """Test suite for workflow metadata and properties."""

    def test_given_workflow_when_accessed_then_has_correct_name(self, workflow_basic):
        """Given workflow, when accessed, then has correct name."""
        # Then
        assert workflow_basic.name == "doc-gen"

    def test_given_workflow_when_accessed_then_has_correct_description(
        self, workflow_basic
    ):
        """Given workflow, when accessed, then has correct description."""
        # Then
        assert "documentation" in workflow_basic.description.lower()
        assert "cost" in workflow_basic.description.lower()

    def test_given_workflow_when_accessed_then_has_correct_stages(self, workflow_basic):
        """Given workflow, when accessed, then has correct stages."""
        # Then
        assert workflow_basic.stages == ["outline", "write", "polish"]


class TestDocumentGenerationWorkflowEdgeCases:
    """Test suite for edge cases and boundary conditions."""

    @pytest.mark.asyncio
    async def test_given_very_short_code_when_execute_then_handles_gracefully(
        self, workflow_basic, mock_executor
    ):
        """Given very short code, when executing, then handles gracefully."""
        # Given
        short_code = "x = 1"
        mock_executor.execute_step.side_effect = [
            {"outline": "# Docs", "sections": ["Intro"]},
            {"content": "Content"},
            {"polished": "Final"},
        ]

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic.execute(
                source_code=short_code, doc_type="api", audience="developers"
            )

        # Then
        assert result["status"] == "success"

    @pytest.mark.asyncio
    async def test_given_no_sections_in_outline_when_write_sections_then_handles_gracefully(
        self, workflow_basic, mock_executor, sample_source_code
    ):
        """Given outline with no sections, when writing sections, then handles gracefully."""
        # Given
        mock_executor.execute_step.return_value = {"outline": "# Docs"}

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic._write_sections(
                outline="# Docs",
                sections=[],
                source_code=sample_source_code,
                doc_type="api",
                audience="developers",
            )

        # Then
        assert result == []

    def test_given_zero_max_sections_when_initialized_then_accepts_value(self):
        """Given zero max_sections, when initialized, then accepts value."""
        # When
        workflow = DocumentGenerationWorkflow(max_sections=0)

        # Then
        assert workflow.max_sections == 0

    def test_given_negative_cost_when_initialized_then_accepts_value(self):
        """Given negative max_cost (for testing), when initialized, then accepts value."""
        # When
        workflow = DocumentGenerationWorkflow(max_cost=-1.0)

        # Then
        assert workflow.max_cost == -1.0

    @pytest.mark.asyncio
    async def test_given_unicode_content_when_execute_then_handles_correctly(
        self, workflow_basic, mock_executor
    ):
        """Given unicode content, when executing, then handles correctly."""
        # Given
        unicode_code = "def test():\n    '''Unicode: ä½ å¥½ ðŸŽ‰'''\n    pass"
        mock_executor.execute_step.side_effect = [
            {"outline": "# Docs", "sections": ["Intro"]},
            {"content": "Content with unicode"},
            {"polished": "Final with unicode"},
        ]

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic.execute(
                source_code=unicode_code, doc_type="api", audience="developers"
            )

        # Then
        assert result["status"] == "success"


class TestDocumentGenerationWorkflowDisplayLength:
    """Test suite for max_display_length functionality."""

    def test_given_custom_display_length_when_initialized_then_uses_value(self):
        """Given custom max_display_length, when initialized, then uses that value."""
        # When
        workflow = DocumentGenerationWorkflow(max_display_length=100)

        # Then
        assert workflow.max_display_length == 100

    @pytest.mark.asyncio
    async def test_given_long_output_when_execute_then_truncates_display(
        self, workflow_basic, mock_executor, sample_source_code
    ):
        """Given long output, when executing, then may truncate for display purposes."""
        # Given
        workflow_basic.max_display_length = 50
        long_content = "x" * 1000
        mock_executor.execute_step.side_effect = [
            {"outline": "# Docs", "sections": ["Intro"]},
            {"content": long_content},
            {"polished": long_content},
        ]

        # When
        with patch.object(workflow_basic, "_get_executor", return_value=mock_executor):
            result = await workflow_basic.execute(
                source_code=sample_source_code, doc_type="api", audience="developers"
            )

        # Then
        assert result["status"] == "success"
        # The actual document should be preserved, only display might be truncated