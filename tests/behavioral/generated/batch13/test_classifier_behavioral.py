"""Behavioral tests for classifier.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import json
import os
from unittest.mock import AsyncMock, Mock, patch, MagicMock

import pytest

from empathy_os.routing.classifier import ClassificationResult, HaikuClassifier


# Fixtures


@pytest.fixture
def mock_api_key():
    """Given a valid API key for testing."""
    return "test-api-key-12345"


@pytest.fixture
def mock_anthropic_client():
    """Given a mocked Anthropic client."""
    mock_client = Mock()
    mock_message = Mock()
    mock_message.content = [
        Mock(
            text=json.dumps(
                {
                    "primary_workflow": "code_analysis",
                    "secondary_workflows": ["documentation"],
                    "confidence": 0.95,
                    "reasoning": "Request involves analyzing code structure",
                    "suggested_chain": ["code_analysis", "documentation"],
                    "extracted_context": {"language": "python"},
                }
            )
        )
    ]
    mock_client.messages.create = AsyncMock(return_value=mock_message)
    return mock_client


@pytest.fixture
def mock_workflow_registry():
    """Given a mocked workflow registry."""
    mock_registry = Mock()
    mock_registry.get_descriptions_for_classification.return_value = {
        "code_analysis": "Analyze code structure and patterns",
        "documentation": "Generate or update documentation",
        "refactoring": "Refactor and improve code quality",
    }
    return mock_registry


@pytest.fixture
def sample_request():
    """Given a sample developer request."""
    return "Analyze this Python function and document its behavior"


@pytest.fixture
def sample_context():
    """Given sample context information."""
    return {
        "current_file": "test.py",
        "project_type": "python",
        "file_count": 10,
    }


# ClassificationResult Tests


class TestClassificationResult:
    """Behavioral tests for ClassificationResult dataclass."""

    def test_classification_result_creation_with_defaults(self):
        """
        Given: No optional parameters
        When: Creating a ClassificationResult
        Then: Should initialize with default values
        """
        result = ClassificationResult(primary_workflow="test_workflow")

        assert result.primary_workflow == "test_workflow"
        assert result.secondary_workflows == []
        assert result.confidence == 0.0
        assert result.reasoning == ""
        assert result.suggested_chain == []
        assert result.extracted_context == {}

    def test_classification_result_creation_with_all_fields(self):
        """
        Given: All optional parameters provided
        When: Creating a ClassificationResult
        Then: Should initialize with provided values
        """
        result = ClassificationResult(
            primary_workflow="code_analysis",
            secondary_workflows=["documentation", "testing"],
            confidence=0.95,
            reasoning="High confidence match",
            suggested_chain=["code_analysis", "documentation"],
            extracted_context={"language": "python"},
        )

        assert result.primary_workflow == "code_analysis"
        assert result.secondary_workflows == ["documentation", "testing"]
        assert result.confidence == 0.95
        assert result.reasoning == "High confidence match"
        assert result.suggested_chain == ["code_analysis", "documentation"]
        assert result.extracted_context == {"language": "python"}

    def test_classification_result_mutable_defaults(self):
        """
        Given: Multiple ClassificationResult instances
        When: Creating instances with default values
        Then: Should not share mutable default instances
        """
        result1 = ClassificationResult(primary_workflow="workflow1")
        result2 = ClassificationResult(primary_workflow="workflow2")

        result1.secondary_workflows.append("test")

        assert len(result1.secondary_workflows) == 1
        assert len(result2.secondary_workflows) == 0


# HaikuClassifier Initialization Tests


class TestHaikuClassifierInitialization:
    """Behavioral tests for HaikuClassifier initialization."""

    def test_classifier_initialization_with_api_key(self, mock_api_key):
        """
        Given: An explicit API key
        When: Initializing HaikuClassifier
        Then: Should store the API key and initialize with None client
        """
        classifier = HaikuClassifier(api_key=mock_api_key)

        assert classifier._api_key == mock_api_key
        assert classifier._client is None
        assert classifier._registry is not None

    def test_classifier_initialization_without_api_key(self):
        """
        Given: No API key provided
        When: Initializing HaikuClassifier with no env var
        Then: Should initialize with None API key
        """
        with patch.dict(os.environ, {}, clear=True):
            classifier = HaikuClassifier()

            assert classifier._api_key is None
            assert classifier._client is None

    def test_classifier_initialization_with_env_var(self, mock_api_key):
        """
        Given: API key in environment variable
        When: Initializing HaikuClassifier without explicit key
        Then: Should use environment variable
        """
        with patch.dict(os.environ, {"ANTHROPIC_API_KEY": mock_api_key}):
            classifier = HaikuClassifier()

            assert classifier._api_key == mock_api_key

    def test_classifier_explicit_key_overrides_env_var(self, mock_api_key):
        """
        Given: Both explicit API key and environment variable
        When: Initializing HaikuClassifier
        Then: Should prefer explicit API key
        """
        with patch.dict(os.environ, {"ANTHROPIC_API_KEY": "env-key"}):
            classifier = HaikuClassifier(api_key=mock_api_key)

            assert classifier._api_key == mock_api_key


# HaikuClassifier Client Loading Tests


class TestHaikuClassifierClientLoading:
    """Behavioral tests for lazy client loading."""

    @patch("empathy_os.routing.classifier.anthropic")
    def test_get_client_lazy_loads_anthropic(self, mock_anthropic, mock_api_key):
        """
        Given: A classifier with API key but no client
        When: Calling _get_client for the first time
        Then: Should lazy-load the Anthropic client
        """
        mock_anthropic.Anthropic.return_value = Mock()
        classifier = HaikuClassifier(api_key=mock_api_key)

        client = classifier._get_client()

        mock_anthropic.Anthropic.assert_called_once_with(api_key=mock_api_key)
        assert client is not None
        assert classifier._client is not None

    @patch("empathy_os.routing.classifier.anthropic")
    def test_get_client_caches_client_instance(self, mock_anthropic, mock_api_key):
        """
        Given: A classifier with loaded client
        When: Calling _get_client multiple times
        Then: Should return cached client without recreating
        """
        mock_client = Mock()
        mock_anthropic.Anthropic.return_value = mock_client
        classifier = HaikuClassifier(api_key=mock_api_key)

        client1 = classifier._get_client()
        client2 = classifier._get_client()

        assert client1 is client2
        mock_anthropic.Anthropic.assert_called_once()

    def test_get_client_returns_none_without_api_key(self):
        """
        Given: A classifier without API key
        When: Calling _get_client
        Then: Should return None
        """
        classifier = HaikuClassifier(api_key=None)

        client = classifier._get_client()

        assert client is None

    @patch("empathy_os.routing.classifier.anthropic", None)
    def test_get_client_handles_missing_anthropic_import(self, mock_api_key):
        """
        Given: Anthropic library not installed
        When: Calling _get_client
        Then: Should handle ImportError gracefully
        """
        with patch.dict("sys.modules", {"anthropic": None}):
            classifier = HaikuClassifier(api_key=mock_api_key)
            client = classifier._get_client()

            assert client is None


# HaikuClassifier Classification Tests


class TestHaikuClassifierClassification:
    """Behavioral tests for request classification."""

    @pytest.mark.asyncio
    @patch("empathy_os.routing.classifier.anthropic")
    async def test_classify_basic_request(
        self, mock_anthropic, mock_api_key, sample_request, mock_workflow_registry
    ):
        """
        Given: A simple developer request
        When: Classifying the request
        Then: Should return classification result with primary workflow
        """
        mock_client = Mock()
        mock_message = Mock()
        mock_message.content = [
            Mock(
                text=json.dumps(
                    {
                        "primary_workflow": "code_analysis",
                        "secondary_workflows": [],
                        "confidence": 0.9,
                        "reasoning": "Code analysis request",
                    }
                )
            )
        ]
        mock_client.messages.create = AsyncMock(return_value=mock_message)
        mock_anthropic.Anthropic.return_value = mock_client

        classifier = HaikuClassifier(api_key=mock_api_key)
        classifier._registry = mock_workflow_registry

        result = await classifier.classify(sample_request)

        assert isinstance(result, ClassificationResult)
        assert result.primary_workflow == "code_analysis"
        assert result.confidence == 0.9

    @pytest.mark.asyncio
    @patch("empathy_os.routing.classifier.anthropic")
    async def test_classify_with_context(
        self, mock_anthropic, mock_api_key, sample_request, sample_context, mock_workflow_registry
    ):
        """
        Given: A request with additional context
        When: Classifying the request
        Then: Should include context in the classification prompt
        """
        mock_client = Mock()
        mock_message = Mock()
        mock_message.content = [
            Mock(
                text=json.dumps(
                    {
                        "primary_workflow": "code_analysis",
                        "secondary_workflows": ["documentation"],
                        "confidence": 0.95,
                        "reasoning": "Context indicates Python project",
                        "extracted_context": {"language": "python"},
                    }
                )
            )
        ]
        mock_client.messages.create = AsyncMock(return_value=mock_message)
        mock_anthropic.Anthropic.return_value = mock_client

        classifier = HaikuClassifier(api_key=mock_api_key)
        classifier._registry = mock_workflow_registry

        result = await classifier.classify(sample_request, context=sample_context)

        assert result.primary_workflow == "code_analysis"
        assert result.extracted_context == {"language": "python"}
        
        # Verify context was included in API call
        call_args = mock_client.messages.create.call_args
        assert sample_context["current_file"] in str(call_args)

    @pytest.mark.asyncio
    @patch("empathy_os.routing.classifier.anthropic")
    async def test_classify_with_custom_workflows(
        self, mock_anthropic, mock_api_key, sample_request
    ):
        """
        Given: Custom available workflows
        When: Classifying a request
        Then: Should use provided workflows instead of registry
        """
        mock_client = Mock()
        mock_message = Mock()
        mock_message.content = [
            Mock(
                text=json.dumps(
                    {
                        "primary_workflow": "custom_workflow",
                        "secondary_workflows": [],
                        "confidence": 0.85,
                        "reasoning": "Matches custom workflow",
                    }
                )
            )
        ]
        mock_client.messages.create = AsyncMock(return_value=mock_message)
        mock_anthropic.Anthropic.return_value = mock_client

        custom_workflows = {
            "custom_workflow": "A custom workflow description",
            "another_workflow": "Another custom workflow",
        }

        classifier = HaikuClassifier(api_key=mock_api_key)
        result = await classifier.classify(
            sample_request, available_workflows=custom_workflows
        )

        assert result.primary_workflow == "custom_workflow"
        
        # Verify custom workflows were used in prompt
        call_args = mock_client.messages.create.call_args
        assert "custom_workflow" in str(call_args)

    @pytest.mark.asyncio
    @patch("empathy_os.routing.classifier.anthropic")
    async def test_classify_with_secondary_workflows(
        self, mock_anthropic, mock_api_key, sample_request, mock_workflow_registry
    ):
        """
        Given: A request that matches multiple workflows
        When: Classifying the request
        Then: Should return both primary and secondary workflows
        """
        mock_client = Mock()
        mock_message = Mock()
        mock_message.content = [
            Mock(
                text=json.dumps(
                    {
                        "primary_workflow": "code_analysis",
                        "secondary_workflows": ["documentation", "refactoring"],
                        "confidence": 0.92,
                        "reasoning": "Multiple relevant workflows",
                        "suggested_chain": ["code_analysis", "documentation", "refactoring"],
                    }
                )
            )
        ]
        mock_client.messages.create = AsyncMock(return_value=mock_message)
        mock_anthropic.Anthropic.return_value = mock_client

        classifier = HaikuClassifier(api_key=mock_api_key)
        classifier._registry = mock_workflow_registry

        result = await classifier.classify(sample_request)

        assert result.primary_workflow == "code_analysis"
        assert len(result.secondary_workflows) == 2
        assert "documentation" in result.secondary_workflows
        assert "refactoring" in result.secondary_workflows
        assert len(result.suggested_chain) == 3

    @pytest.mark.asyncio
    @patch("empathy_os.routing.classifier.anthropic")
    async def test_classify_uses_registry_by_default(
        self, mock_anthropic, mock_api_key, sample_request, mock_workflow_registry
    ):
        """
        Given: No custom workflows provided
        When: Classifying a request
        Then: Should use workflow registry for available workflows
        """
        mock_client = Mock()
        mock_message = Mock()
        mock_message.content = [
            Mock(
                text=json.dumps(
                    {
                        "primary_workflow": "code_analysis",
                        "secondary_workflows": [],
                        "confidence": 0.88,
                        "reasoning": "From registry",
                    }
                )
            )
        ]
        mock_client.messages.create = AsyncMock(return_value=mock_message)
        mock_anthropic.Anthropic.return_value = mock_client

        classifier = HaikuClassifier(api_key=mock_api_key)
        classifier._registry = mock_workflow_registry

        await classifier.classify(sample_request)

        mock_workflow_registry.get_descriptions_for_classification.assert_called_once()

    @pytest.mark.asyncio
    @patch("empathy_os.routing.classifier.anthropic")
    async def test_classify_handles_partial_json_response(
        self, mock_anthropic, mock_api_key, sample_request, mock_workflow_registry
    ):
        """
        Given: LLM returns partial/minimal JSON response
        When: Classifying a request
        Then: Should handle missing optional fields gracefully
        """