"""Behavioral tests for document_gen.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import asyncio
import logging
from datetime import datetime
from pathlib import Path
from unittest.mock import AsyncMock, Mock, patch, mock_open, MagicMock

import pytest

from empathy_os.workflows.document_gen import (
    DocumentGenerationWorkflow,
    TOKEN_COSTS,
    DOC_GEN_STEPS,
)
from empathy_os.workflows.base import ModelTier, WorkflowResult


@pytest.fixture
def mock_executor():
    """Fixture providing a mocked task executor."""
    executor = AsyncMock()
    executor.execute_task = AsyncMock()
    return executor


@pytest.fixture
def workflow_instance():
    """Fixture providing a DocumentGenerationWorkflow instance with defaults."""
    return DocumentGenerationWorkflow()


@pytest.fixture
def workflow_with_custom_config():
    """Fixture providing a workflow with custom configuration."""
    return DocumentGenerationWorkflow(
        skip_polish_threshold=2000,
        max_sections=5,
        max_write_tokens=8000,
        section_focus=["api", "examples"],
        chunked_generation=False,
        sections_per_chunk=2,
        max_cost=10.0,
        cost_warning_threshold=0.9,
        graceful_degradation=False,
        export_path="docs/test",
        max_display_chars=500,
    )


@pytest.fixture
def mock_config_loader():
    """Fixture providing mocked config loader."""
    with patch("empathy_os.workflows.document_gen._validate_file_path") as mock_validate:
        mock_validate.return_value = Path("/validated/path")
        yield mock_validate


class TestDocumentGenerationWorkflowInitialization:
    """Tests for DocumentGenerationWorkflow initialization."""

    def test_given_default_params_when_instantiated_then_sets_correct_defaults(self):
        """GIVEN default parameters
        WHEN workflow is instantiated
        THEN it should set correct default values
        """
        # When
        workflow = DocumentGenerationWorkflow()

        # Then
        assert workflow.skip_polish_threshold == 1000
        assert workflow.max_sections == 10
        assert workflow.max_write_tokens is None
        assert workflow.section_focus is None
        assert workflow.chunked_generation is True
        assert workflow.sections_per_chunk == 3
        assert workflow.max_cost == 5.0
        assert workflow.cost_warning_threshold == 0.8
        assert workflow.graceful_degradation is True
        assert workflow.export_path is None
        assert workflow.max_display_chars == 1000

    def test_given_custom_params_when_instantiated_then_sets_custom_values(self):
        """GIVEN custom parameters
        WHEN workflow is instantiated
        THEN it should set custom values correctly
        """
        # Given/When
        workflow = DocumentGenerationWorkflow(
            skip_polish_threshold=2000,
            max_sections=5,
            max_write_tokens=8000,
            section_focus=["api", "examples"],
            chunked_generation=False,
            sections_per_chunk=2,
            max_cost=10.0,
            cost_warning_threshold=0.9,
            graceful_degradation=False,
            export_path="docs/test",
            max_display_chars=500,
        )

        # Then
        assert workflow.skip_polish_threshold == 2000
        assert workflow.max_sections == 5
        assert workflow.max_write_tokens == 8000
        assert workflow.section_focus == ["api", "examples"]
        assert workflow.chunked_generation is False
        assert workflow.sections_per_chunk == 2
        assert workflow.max_cost == 10.0
        assert workflow.cost_warning_threshold == 0.9
        assert workflow.graceful_degradation is False
        assert workflow.export_path == "docs/test"
        assert workflow.max_display_chars == 500

    def test_given_workflow_when_check_class_attributes_then_has_correct_metadata(self):
        """GIVEN DocumentGenerationWorkflow class
        WHEN checking class attributes
        THEN it should have correct metadata
        """
        # Then
        assert DocumentGenerationWorkflow.name == "doc-gen"
        assert DocumentGenerationWorkflow.description == "Cost-optimized documentation generation pipeline"
        assert DocumentGenerationWorkflow.stages == ["outline", "write", "polish"]
        assert DocumentGenerationWorkflow.tier_map == {
            "outline": ModelTier.CHEAP,
            "write": ModelTier.CAPABLE,
            "polish": ModelTier.PREMIUM,
        }


class TestEstimateTokens:
    """Tests for _estimate_tokens method."""

    def test_given_simple_text_when_estimate_tokens_then_returns_approximate_count(self, workflow_instance):
        """GIVEN simple text
        WHEN estimating tokens
        THEN should return approximate token count
        """
        # Given
        text = "This is a simple test text with some words."

        # When
        tokens = workflow_instance._estimate_tokens(text)

        # Then
        assert isinstance(tokens, int)
        assert tokens > 0
        # Rough estimate: ~10 words, should be around 10-15 tokens
        assert 5 < tokens < 20

    def test_given_empty_text_when_estimate_tokens_then_returns_zero(self, workflow_instance):
        """GIVEN empty text
        WHEN estimating tokens
        THEN should return zero
        """
        # When
        tokens = workflow_instance._estimate_tokens("")

        # Then
        assert tokens == 0

    def test_given_long_text_when_estimate_tokens_then_returns_proportional_count(self, workflow_instance):
        """GIVEN long text
        WHEN estimating tokens
        THEN should return proportionally larger count
        """
        # Given
        short_text = "Hello world"
        long_text = "Hello world " * 100

        # When
        short_tokens = workflow_instance._estimate_tokens(short_text)
        long_tokens = workflow_instance._estimate_tokens(long_text)

        # Then
        assert long_tokens > short_tokens * 50  # Should be much larger


class TestEstimateCost:
    """Tests for _estimate_cost method."""

    def test_given_cheap_tier_when_estimate_cost_then_returns_low_cost(self, workflow_instance):
        """GIVEN cheap tier tokens
        WHEN estimating cost
        THEN should return low cost
        """
        # Given
        input_tokens = 1000
        output_tokens = 500

        # When
        cost = workflow_instance._estimate_cost(input_tokens, output_tokens, ModelTier.CHEAP)

        # Then
        expected = (input_tokens / 1000 * TOKEN_COSTS[ModelTier.CHEAP]["input"] +
                    output_tokens / 1000 * TOKEN_COSTS[ModelTier.CHEAP]["output"])
        assert cost == pytest.approx(expected, rel=0.01)

    def test_given_premium_tier_when_estimate_cost_then_returns_high_cost(self, workflow_instance):
        """GIVEN premium tier tokens
        WHEN estimating cost
        THEN should return higher cost
        """
        # Given
        input_tokens = 1000
        output_tokens = 500

        # When
        cheap_cost = workflow_instance._estimate_cost(input_tokens, output_tokens, ModelTier.CHEAP)
        premium_cost = workflow_instance._estimate_cost(input_tokens, output_tokens, ModelTier.PREMIUM)

        # Then
        assert premium_cost > cheap_cost * 10  # Premium should be significantly more expensive

    def test_given_zero_tokens_when_estimate_cost_then_returns_zero(self, workflow_instance):
        """GIVEN zero tokens
        WHEN estimating cost
        THEN should return zero cost
        """
        # When
        cost = workflow_instance._estimate_cost(0, 0, ModelTier.CAPABLE)

        # Then
        assert cost == 0.0


class TestCheckCostLimit:
    """Tests for _check_cost_limit method."""

    def test_given_cost_below_limit_when_check_cost_limit_then_does_not_raise(self, workflow_instance):
        """GIVEN cost below limit
        WHEN checking cost limit
        THEN should not raise exception
        """
        # Given
        workflow_instance.estimated_cost = 2.0
        workflow_instance.max_cost = 5.0

        # When/Then (should not raise)
        workflow_instance._check_cost_limit()

    def test_given_cost_above_limit_when_check_cost_limit_then_raises_error(self, workflow_instance):
        """GIVEN cost above limit
        WHEN checking cost limit
        THEN should raise ValueError
        """
        # Given
        workflow_instance.estimated_cost = 6.0
        workflow_instance.max_cost = 5.0

        # When/Then
        with pytest.raises(ValueError, match="Estimated cost.*exceeds maximum"):
            workflow_instance._check_cost_limit()

    def test_given_cost_at_warning_threshold_when_check_cost_limit_then_logs_warning(
        self, workflow_instance, caplog
    ):
        """GIVEN cost at warning threshold
        WHEN checking cost limit
        THEN should log warning
        """
        # Given
        workflow_instance.estimated_cost = 4.0
        workflow_instance.max_cost = 5.0
        workflow_instance.cost_warning_threshold = 0.8

        # When
        with caplog.at_level(logging.WARNING):
            workflow_instance._check_cost_limit()

        # Then
        assert any("Cost warning" in record.message for record in caplog.records)


class TestTruncateOutput:
    """Tests for _truncate_output method."""

    def test_given_short_text_when_truncate_output_then_returns_full_text(self, workflow_instance):
        """GIVEN text shorter than limit
        WHEN truncating output
        THEN should return full text
        """
        # Given
        text = "Short text"

        # When
        result = workflow_instance._truncate_output(text)

        # Then
        assert result == text

    def test_given_long_text_when_truncate_output_then_truncates_with_ellipsis(self, workflow_instance):
        """GIVEN text longer than limit
        WHEN truncating output
        THEN should truncate with ellipsis
        """
        # Given
        workflow_instance.max_display_chars = 50
        text = "A" * 100

        # When
        result = workflow_instance._truncate_output(text)

        # Then
        assert len(result) <= 53  # 50 + "..."
        assert result.endswith("...")

    def test_given_none_when_truncate_output_then_returns_none(self, workflow_instance):
        """GIVEN None
        WHEN truncating output
        THEN should return None
        """
        # When
        result = workflow_instance._truncate_output(None)

        # Then
        assert result is None


class TestExportDocument:
    """Tests for _export_document method."""

    @pytest.mark.asyncio
    async def test_given_export_path_when_export_document_then_writes_file(
        self, workflow_instance, mock_config_loader
    ):
        """GIVEN export path is configured
        WHEN exporting document
        THEN should write file to path
        """
        # Given
        workflow_instance.export_path = "docs/test"
        content = "# Test Document\n\nThis is a test."

        # When
        with patch("builtins.open", mock_open()) as mock_file:
            with patch("empathy_os.workflows.document_gen.Path") as mock_path:
                mock_path_instance = Mock()
                mock_path_instance.exists.return_value = True
                mock_path_instance.__truediv__ = Mock(return_value=mock_path_instance)
                mock_path.return_value = mock_path_instance

                await workflow_instance._export_document(content, "api_reference")

                # Then
                mock_file.assert_called_once()

    @pytest.mark.asyncio
    async def test_given_no_export_path_when_export_document_then_does_nothing(self, workflow_instance):
        """GIVEN no export path configured
        WHEN exporting document
        THEN should do nothing
        """
        # Given
        workflow_instance.export_path = None
        content = "# Test Document"

        # When
        with patch("builtins.open", mock_open()) as mock_file:
            await workflow_instance._export_document(content, "api_reference")

            # Then
            mock_file.assert_not_called()

    @pytest.mark.asyncio
    async def test_given_export_fails_when_export_document_then_logs_error(
        self, workflow_instance, mock_config_loader, caplog
    ):
        """GIVEN export operation fails
        WHEN exporting document
        THEN should log error and not raise
        """
        # Given
        workflow_instance.export_path = "docs/test"
        content = "# Test Document"

        # When
        with patch("builtins.open", side_effect=IOError("Write error")):
            with patch("empathy_os.workflows.document_gen.Path") as mock_path:
                mock_path_instance = Mock()
                mock_path_instance.exists.return_value = True
                mock_path_instance.__truediv__ = Mock(return_value=mock_path_instance)
                mock_path.return_value = mock_path_instance

                with caplog.at_level(logging.ERROR):
                    await workflow_instance._export_document(content, "api_reference")

                # Then
                assert any("Failed to export" in record.message for record in caplog.records)


class TestGenerateOutline:
    """Tests for _generate_outline method."""

    @pytest.mark.asyncio
    async def test_given_valid_inputs_when_generate_outline_then_returns_outline(
        self, workflow_instance, mock_executor
    ):
        """GIVEN valid source code and parameters
        WHEN generating outline
        THEN should return structured outline
        """
        # Given
        source_code = "def hello(): pass"
        doc_type = "api_reference"
        audience = "developers"
        mock_executor.execute_task.return_value = {
            "sections": ["Introduction", "API Reference", "Examples"],
            "estimated_length": 500,
        }

        # When
        with patch.object(workflow_instance, "executor", mock_executor):
            result = await workflow_instance._generate_outline(source_code, doc_type, audience)

        # Then
        assert "sections" in result
        assert isinstance(result["sections"], list)
        assert len(result["sections"]) > 0
        mock_executor.execute_task.assert_called_once()

    @pytest.mark.asyncio
    async def test_given_max_sections_limit_when_generate_outline_then_respects_limit(
        self, workflow_instance, mock_executor
    ):
        """GIVEN max_sections limit
        WHEN generating outline with many sections
        THEN should respect the limit
        """
        # Given
        workflow_instance.max_sections = 3
        source_code = "def hello(): pass"
        mock_executor.execute_task.return_value = {
            "sections": ["S1", "S2", "S3", "S4", "S5"],
            "estimated_length": 500,
        }

        # When
        with patch.object(workflow_instance, "executor", mock_executor):
            result = await workflow_instance._generate_outline(