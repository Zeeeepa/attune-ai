"""Behavioral tests for research_synthesis.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import pytest
from unittest.mock import AsyncMock, MagicMock, Mock, patch
from typing import Any, Dict, List

from empathy_os.workflows.research_synthesis import (
    ResearchSynthesisWorkflow,
    SUMMARIZE_STEP,
    ANALYZE_STEP,
    SYNTHESIZE_STEP,
    SYNTHESIZE_STEP_CAPABLE,
)
from empathy_os.workflows.base import ModelTier
from empathy_os.workflows.step_config import WorkflowStepConfig


# Fixtures

@pytest.fixture
def mock_executor():
    """Given a mock LLM executor."""
    executor = AsyncMock()
    executor.execute_task = AsyncMock()
    return executor


@pytest.fixture
def workflow_without_executor():
    """Given a workflow without an executor (legacy mode)."""
    return ResearchSynthesisWorkflow()


@pytest.fixture
def workflow_with_executor(mock_executor):
    """Given a workflow with an executor."""
    return ResearchSynthesisWorkflow(executor=mock_executor)


@pytest.fixture
def sample_sources():
    """Given sample source documents."""
    return [
        "Document 1: The history of AI research shows rapid progress.",
        "Document 2: Machine learning has transformed many industries.",
        "Document 3: Neural networks are inspired by biological systems.",
    ]


@pytest.fixture
def sample_question():
    """Given a sample research question."""
    return "What are the key themes in AI development?"


# Step Configuration Tests


class TestStepConfigurations:
    """Tests for workflow step configuration constants."""

    def test_summarize_step_configuration(self):
        """
        Given: The SUMMARIZE_STEP configuration
        When: Examining its properties
        Then: It should have correct task type and settings for summarization.
        """
        assert SUMMARIZE_STEP.name == "summarize"
        assert SUMMARIZE_STEP.task_type == "summarize"
        assert SUMMARIZE_STEP.description == "Summarize each source document"
        assert SUMMARIZE_STEP.max_tokens == 2048

    def test_analyze_step_configuration(self):
        """
        Given: The ANALYZE_STEP configuration
        When: Examining its properties
        Then: It should have correct task type and settings for pattern analysis.
        """
        assert ANALYZE_STEP.name == "analyze"
        assert ANALYZE_STEP.task_type == "analyze_patterns"
        assert ANALYZE_STEP.description == "Identify patterns across summaries"
        assert ANALYZE_STEP.max_tokens == 2048

    def test_synthesize_step_configuration(self):
        """
        Given: The SYNTHESIZE_STEP configuration
        When: Examining its properties
        Then: It should have correct task type for complex reasoning.
        """
        assert SYNTHESIZE_STEP.name == "synthesize"
        assert SYNTHESIZE_STEP.task_type == "complex_reasoning"
        assert SYNTHESIZE_STEP.description == "Synthesize final insights"
        assert SYNTHESIZE_STEP.max_tokens == 4096

    def test_synthesize_step_capable_configuration(self):
        """
        Given: The SYNTHESIZE_STEP_CAPABLE configuration
        When: Examining its properties
        Then: It should force capable tier with appropriate settings.
        """
        assert SYNTHESIZE_STEP_CAPABLE.name == "synthesize"
        assert SYNTHESIZE_STEP_CAPABLE.task_type == "generate_content"
        assert SYNTHESIZE_STEP_CAPABLE.tier_hint == "capable"
        assert SYNTHESIZE_STEP_CAPABLE.description == "Synthesize final insights (lower complexity)"
        assert SYNTHESIZE_STEP_CAPABLE.max_tokens == 4096


# Workflow Initialization Tests


class TestWorkflowInitialization:
    """Tests for workflow initialization."""

    def test_workflow_initialization_without_executor(self):
        """
        Given: No executor is provided
        When: Creating a ResearchSynthesisWorkflow
        Then: It should initialize successfully in legacy mode.
        """
        workflow = ResearchSynthesisWorkflow()
        assert workflow is not None
        assert workflow.executor is None

    def test_workflow_initialization_with_executor(self, mock_executor):
        """
        Given: An executor is provided
        When: Creating a ResearchSynthesisWorkflow
        Then: It should initialize with the executor attached.
        """
        workflow = ResearchSynthesisWorkflow(executor=mock_executor)
        assert workflow is not None
        assert workflow.executor == mock_executor

    def test_workflow_inherits_from_base(self):
        """
        Given: The ResearchSynthesisWorkflow class
        When: Checking its inheritance
        Then: It should inherit from BaseWorkflow.
        """
        from empathy_os.workflows.base import BaseWorkflow
        workflow = ResearchSynthesisWorkflow()
        assert isinstance(workflow, BaseWorkflow)


# Input Validation Tests


class TestInputValidation:
    """Tests for input validation in the workflow."""

    @pytest.mark.asyncio
    async def test_execute_with_insufficient_sources(self, workflow_without_executor):
        """
        Given: A workflow without executor
        When: Executing with fewer than 2 sources
        Then: It should raise ValueError.
        """
        with pytest.raises(ValueError, match="at least 2 source"):
            await workflow_without_executor.execute(
                sources=["Only one source"],
                question="What is this about?"
            )

    @pytest.mark.asyncio
    async def test_execute_with_empty_sources(self, workflow_without_executor):
        """
        Given: A workflow without executor
        When: Executing with empty sources list
        Then: It should raise ValueError.
        """
        with pytest.raises(ValueError, match="at least 2 source"):
            await workflow_without_executor.execute(
                sources=[],
                question="What is this about?"
            )

    @pytest.mark.asyncio
    async def test_execute_with_single_source(self, workflow_without_executor):
        """
        Given: A workflow without executor
        When: Executing with exactly one source
        Then: It should raise ValueError.
        """
        with pytest.raises(ValueError, match="at least 2 source"):
            await workflow_without_executor.execute(
                sources=["Single document"],
                question="What is this about?"
            )

    @pytest.mark.asyncio
    async def test_execute_with_executor_insufficient_sources(self, workflow_with_executor):
        """
        Given: A workflow with executor
        When: Executing with fewer than 2 sources
        Then: It should raise ValueError.
        """
        with pytest.raises(ValueError, match="at least 2 source"):
            await workflow_with_executor.execute(
                sources=["Only one source"],
                question="What is this about?"
            )

    @pytest.mark.asyncio
    async def test_execute_with_none_sources(self, workflow_without_executor):
        """
        Given: A workflow without executor
        When: Executing with None as sources
        Then: It should raise appropriate error.
        """
        with pytest.raises((ValueError, TypeError)):
            await workflow_without_executor.execute(
                sources=None,
                question="What is this about?"
            )


# Legacy Mode Execution Tests (without executor)


class TestLegacyModeExecution:
    """Tests for workflow execution without executor (legacy API calls)."""

    @pytest.mark.asyncio
    async def test_execute_legacy_mode_with_valid_inputs(
        self, workflow_without_executor, sample_sources, sample_question
    ):
        """
        Given: A workflow in legacy mode with valid inputs
        When: Executing the workflow
        Then: It should call cheap tier for summaries, capable for analysis, and return result.
        """
        with patch.object(workflow_without_executor, '_call_model', new_callable=AsyncMock) as mock_call:
            # Mock responses for each tier
            mock_call.side_effect = [
                # Summaries (cheap tier, parallel)
                "Summary 1: AI has progressed rapidly",
                "Summary 2: ML transformed industries",
                "Summary 3: Neural nets mimic biology",
                # Analysis (capable tier)
                "Analysis: Strong pattern of technological advancement. Complexity: high",
                # Synthesis (premium tier based on high complexity)
                "Final synthesis: AI evolution shows consistent innovation",
            ]

            result = await workflow_without_executor.execute(
                sources=sample_sources,
                question=sample_question
            )

            assert result is not None
            assert "Final synthesis" in result
            # Verify model tier calls: 3 cheap + 1 capable + 1 premium
            assert mock_call.call_count >= 4

    @pytest.mark.asyncio
    async def test_execute_legacy_mode_low_complexity(
        self, workflow_without_executor, sample_sources, sample_question
    ):
        """
        Given: A workflow in legacy mode
        When: Analysis indicates low complexity
        Then: It should use capable tier for synthesis instead of premium.
        """
        with patch.object(workflow_without_executor, '_call_model', new_callable=AsyncMock) as mock_call:
            mock_call.side_effect = [
                "Summary 1",
                "Summary 2",
                "Summary 3",
                "Analysis: Simple pattern. Complexity: low",
                "Synthesis with capable tier",
            ]

            result = await workflow_without_executor.execute(
                sources=sample_sources,
                question=sample_question
            )

            assert result is not None
            # Verify premium tier was not used (only cheap + capable)
            calls = mock_call.call_args_list
            tier_calls = [call.kwargs.get('tier') or call.args[1] if len(call.args) > 1 else None 
                         for call in calls]
            assert ModelTier.CHEAP in tier_calls or "cheap" in str(tier_calls).lower()

    @pytest.mark.asyncio
    async def test_execute_legacy_mode_parallel_summarization(
        self, workflow_without_executor, sample_sources, sample_question
    ):
        """
        Given: A workflow in legacy mode with multiple sources
        When: Executing the workflow
        Then: It should process summaries in parallel.
        """
        with patch.object(workflow_without_executor, '_call_model', new_callable=AsyncMock) as mock_call:
            import asyncio
            call_times = []
            
            async def track_call(*args, **kwargs):
                call_times.append(asyncio.get_event_loop().time())
                return f"Response {len(call_times)}"
            
            mock_call.side_effect = track_call

            await workflow_without_executor.execute(
                sources=sample_sources,
                question=sample_question
            )

            # First 3 calls (summaries) should be roughly simultaneous
            if len(call_times) >= 3:
                time_diff = call_times[2] - call_times[0]
                # Parallel execution should be much faster than sequential
                assert time_diff < 1.0  # Generous threshold for parallel execution


# Executor Mode Execution Tests


class TestExecutorModeExecution:
    """Tests for workflow execution with executor."""

    @pytest.mark.asyncio
    async def test_execute_with_executor_valid_inputs(
        self, workflow_with_executor, mock_executor, sample_sources, sample_question
    ):
        """
        Given: A workflow with executor and valid inputs
        When: Executing the workflow
        Then: It should use executor.execute_task for all steps.
        """
        mock_executor.execute_task.side_effect = [
            "Summary 1",
            "Summary 2",
            "Summary 3",
            "Analysis: Pattern found. Complexity: medium",
            "Final synthesis",
        ]

        result = await workflow_with_executor.execute(
            sources=sample_sources,
            question=sample_question
        )

        assert result is not None
        assert "synthesis" in result.lower()
        # Verify executor was called for each step
        assert mock_executor.execute_task.call_count >= 4

    @pytest.mark.asyncio
    async def test_execute_with_executor_step_configs(
        self, workflow_with_executor, mock_executor, sample_sources, sample_question
    ):
        """
        Given: A workflow with executor
        When: Executing the workflow
        Then: It should pass correct WorkflowStepConfig to executor.
        """
        mock_executor.execute_task.side_effect = [
            "Summary 1", "Summary 2", "Summary 3",
            "Analysis: Complexity: high",
            "Synthesis",
        ]

        await workflow_with_executor.execute(
            sources=sample_sources,
            question=sample_question
        )

        # Check that step configs were used
        calls = mock_executor.execute_task.call_args_list
        assert len(calls) >= 4
        
        # Verify step config types in calls
        for call in calls[:3]:  # First 3 are summaries
            config = call.kwargs.get('step_config') or call.args[1] if len(call.args) > 1 else None
            if config:
                assert isinstance(config, WorkflowStepConfig)

    @pytest.mark.asyncio
    async def test_execute_with_executor_high_complexity_routing(
        self, workflow_with_executor, mock_executor, sample_sources, sample_question
    ):
        """
        Given: A workflow with executor
        When: Analysis indicates high complexity
        Then: It should use premium tier for synthesis.
        """
        mock_executor.execute_task.side_effect = [
            "Summary 1", "Summary 2", "Summary 3",
            "Analysis: Very complex patterns. Complexity: high",
            "Premium synthesis",
        ]

        result = await workflow_with_executor.execute(
            sources=sample_sources,
            question=sample_question
        )

        assert result is not None
        # Verify synthesis call used appropriate step config
        synthesis_call = mock_executor.execute_task.call_args_list[-1]
        config = synthesis_call.kwargs.get('step_config') or synthesis_call.args[1]
        # Should be SYNTHESIZE_STEP (premium) not SYNTHESIZE_STEP_CAPABLE
        assert config.task_type == "complex_reasoning" or config.task_type == "generate_content"

    @pytest.mark.asyncio
    async def test_execute_with_executor_low_complexity_routing(
        self, workflow_with_executor, mock_executor, sample_sources, sample_question
    ):
        """
        Given: A workflow with executor
        When: Analysis indicates low complexity
        Then: It should use capable tier for synthesis.
        """
        mock_executor.execute_task.side_effect = [
            "Summary 1", "Summary 2", "Summary 3",
            "Analysis: Simple patterns. Complexity: low",
            "Capable synthesis",
        ]

        result = await workflow_with_executor.execute(
            sources=sample_sources,
            question=sample_question
        )

        assert result is not None
        synthesis_call = mock_executor.execute_task.call_args_list[-1]
        config = synthesis_call.kwargs.get('step_config') or synthesis_call.args[1]
        # Should use capable tier hint
        assert config.tier_hint == "capable" or config.task_type == "generate_content"

    @pytest.mark.asyncio
    async def test_execute_with_executor_telemetry_emission(
        self, workflow_with_executor, mock_executor, sample_sources, sample_question
    ):
        """
        Given: A workflow with executor
        When: Executing the workflow
        Then: Telemetry should be emitted automatically.
        """