"""Behavioral tests for batch_processing.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import json
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock, Mock, patch

import pytest

from empathy_os.workflows.batch_processing import (
    BatchProcessingWorkflow,
    BatchRequest,
    BatchResult,
)


@pytest.fixture
def mock_anthropic_batch_provider():
    """Mock AnthropicBatchProvider for testing."""
    with patch(
        "empathy_os.workflows.batch_processing.AnthropicBatchProvider"
    ) as mock_provider_class:
        mock_provider = Mock()
        mock_provider_class.return_value = mock_provider
        yield mock_provider


@pytest.fixture
def mock_get_model():
    """Mock get_model function."""
    with patch("empathy_os.workflows.batch_processing.get_model") as mock:
        mock_model = Mock()
        mock_model.name = "claude-3-sonnet-20240229"
        mock.return_value = mock_model
        yield mock


@pytest.fixture
def sample_batch_requests():
    """Sample batch requests for testing."""
    return [
        BatchRequest(
            task_id="task_1",
            task_type="analyze_logs",
            input_data={"logs": "ERROR: Connection failed"},
            model_tier="capable",
        ),
        BatchRequest(
            task_id="task_2",
            task_type="generate_report",
            input_data={"data": {"key": "value"}},
            model_tier="cheap",
        ),
        BatchRequest(
            task_id="task_3",
            task_type="summarize",
            input_data={"text": "Long text to summarize"},
            model_tier="premium",
        ),
    ]


@pytest.fixture
def workflow(mock_anthropic_batch_provider):
    """Create a BatchProcessingWorkflow instance."""
    return BatchProcessingWorkflow(api_key="test_api_key")


class TestBatchRequest:
    """Tests for BatchRequest dataclass."""

    def test_given_valid_data_when_creating_batch_request_then_success(self):
        """Test creating a BatchRequest with valid data."""
        # Given
        task_id = "task_123"
        task_type = "analyze"
        input_data = {"key": "value"}
        model_tier = "capable"

        # When
        request = BatchRequest(
            task_id=task_id,
            task_type=task_type,
            input_data=input_data,
            model_tier=model_tier,
        )

        # Then
        assert request.task_id == task_id
        assert request.task_type == task_type
        assert request.input_data == input_data
        assert request.model_tier == model_tier

    def test_given_no_model_tier_when_creating_batch_request_then_defaults_to_capable(
        self,
    ):
        """Test BatchRequest defaults to 'capable' model tier."""
        # Given
        task_id = "task_123"
        task_type = "analyze"
        input_data = {"key": "value"}

        # When
        request = BatchRequest(
            task_id=task_id, task_type=task_type, input_data=input_data
        )

        # Then
        assert request.model_tier == "capable"

    def test_given_empty_input_data_when_creating_batch_request_then_success(self):
        """Test BatchRequest with empty input data."""
        # Given
        task_id = "task_123"
        task_type = "analyze"
        input_data = {}

        # When
        request = BatchRequest(
            task_id=task_id, task_type=task_type, input_data=input_data
        )

        # Then
        assert request.input_data == {}


class TestBatchResult:
    """Tests for BatchResult dataclass."""

    def test_given_successful_result_when_creating_batch_result_then_success(self):
        """Test creating a successful BatchResult."""
        # Given
        task_id = "task_123"
        success = True
        output = {"result": "completed"}

        # When
        result = BatchResult(task_id=task_id, success=success, output=output)

        # Then
        assert result.task_id == task_id
        assert result.success is True
        assert result.output == output
        assert result.error is None

    def test_given_failed_result_when_creating_batch_result_then_success(self):
        """Test creating a failed BatchResult."""
        # Given
        task_id = "task_123"
        success = False
        error = "Processing failed"

        # When
        result = BatchResult(task_id=task_id, success=success, error=error)

        # Then
        assert result.task_id == task_id
        assert result.success is False
        assert result.output is None
        assert result.error == error

    def test_given_minimal_data_when_creating_batch_result_then_defaults_applied(self):
        """Test BatchResult with minimal data uses defaults."""
        # Given
        task_id = "task_123"
        success = True

        # When
        result = BatchResult(task_id=task_id, success=success)

        # Then
        assert result.output is None
        assert result.error is None


class TestBatchProcessingWorkflowInitialization:
    """Tests for BatchProcessingWorkflow initialization."""

    def test_given_api_key_when_initializing_workflow_then_provider_created(
        self, mock_anthropic_batch_provider
    ):
        """Test workflow initialization with API key."""
        # Given
        api_key = "test_api_key_123"

        # When
        workflow = BatchProcessingWorkflow(api_key=api_key)

        # Then
        assert workflow.batch_provider is not None
        assert workflow.batch_provider == mock_anthropic_batch_provider

    def test_given_no_api_key_when_initializing_workflow_then_provider_created(
        self, mock_anthropic_batch_provider
    ):
        """Test workflow initialization without API key."""
        # Given/When
        workflow = BatchProcessingWorkflow()

        # Then
        assert workflow.batch_provider is not None
        assert workflow.batch_provider == mock_anthropic_batch_provider


class TestExecuteBatch:
    """Tests for execute_batch method."""

    @pytest.mark.asyncio
    async def test_given_valid_requests_when_execute_batch_then_returns_results(
        self, workflow, sample_batch_requests, mock_anthropic_batch_provider
    ):
        """Test executing batch with valid requests."""
        # Given
        mock_response = {
            "task_1": {"success": True, "output": {"result": "analysis complete"}},
            "task_2": {"success": True, "output": {"result": "report generated"}},
            "task_3": {"success": True, "output": {"result": "summary created"}},
        }
        mock_anthropic_batch_provider.process_batch = AsyncMock(
            return_value=mock_response
        )

        # When
        results = await workflow.execute_batch(sample_batch_requests)

        # Then
        assert len(results) == 3
        assert all(isinstance(r, BatchResult) for r in results)
        assert all(r.success for r in results)

    @pytest.mark.asyncio
    async def test_given_empty_requests_when_execute_batch_then_raises_value_error(
        self, workflow
    ):
        """Test executing batch with empty requests list."""
        # Given
        requests = []

        # When/Then
        with pytest.raises(ValueError):
            await workflow.execute_batch(requests)

    @pytest.mark.asyncio
    async def test_given_custom_poll_interval_when_execute_batch_then_uses_interval(
        self, workflow, sample_batch_requests, mock_anthropic_batch_provider
    ):
        """Test executing batch with custom poll interval."""
        # Given
        poll_interval = 60
        mock_response = {
            "task_1": {"success": True, "output": {"result": "done"}},
            "task_2": {"success": True, "output": {"result": "done"}},
            "task_3": {"success": True, "output": {"result": "done"}},
        }
        mock_anthropic_batch_provider.process_batch = AsyncMock(
            return_value=mock_response
        )

        # When
        results = await workflow.execute_batch(
            sample_batch_requests, poll_interval=poll_interval
        )

        # Then
        assert len(results) == 3
        mock_anthropic_batch_provider.process_batch.assert_called_once()

    @pytest.mark.asyncio
    async def test_given_custom_timeout_when_execute_batch_then_uses_timeout(
        self, workflow, sample_batch_requests, mock_anthropic_batch_provider
    ):
        """Test executing batch with custom timeout."""
        # Given
        timeout = 3600
        mock_response = {
            "task_1": {"success": True, "output": {"result": "done"}},
            "task_2": {"success": True, "output": {"result": "done"}},
            "task_3": {"success": True, "output": {"result": "done"}},
        }
        mock_anthropic_batch_provider.process_batch = AsyncMock(
            return_value=mock_response
        )

        # When
        results = await workflow.execute_batch(sample_batch_requests, timeout=timeout)

        # Then
        assert len(results) == 3
        mock_anthropic_batch_provider.process_batch.assert_called_once()

    @pytest.mark.asyncio
    async def test_given_mixed_results_when_execute_batch_then_returns_all_results(
        self, workflow, sample_batch_requests, mock_anthropic_batch_provider
    ):
        """Test executing batch with mixed success and failure results."""
        # Given
        mock_response = {
            "task_1": {"success": True, "output": {"result": "done"}},
            "task_2": {"success": False, "error": "Processing failed"},
            "task_3": {"success": True, "output": {"result": "done"}},
        }
        mock_anthropic_batch_provider.process_batch = AsyncMock(
            return_value=mock_response
        )

        # When
        results = await workflow.execute_batch(sample_batch_requests)

        # Then
        assert len(results) == 3
        assert results[0].success is True
        assert results[1].success is False
        assert results[1].error == "Processing failed"
        assert results[2].success is True

    @pytest.mark.asyncio
    async def test_given_timeout_exceeded_when_execute_batch_then_raises_timeout_error(
        self, workflow, sample_batch_requests, mock_anthropic_batch_provider
    ):
        """Test executing batch that exceeds timeout."""
        # Given
        mock_anthropic_batch_provider.process_batch = AsyncMock(
            side_effect=TimeoutError("Batch processing timeout")
        )

        # When/Then
        with pytest.raises(TimeoutError):
            await workflow.execute_batch(sample_batch_requests, timeout=1)

    @pytest.mark.asyncio
    async def test_given_batch_failure_when_execute_batch_then_raises_runtime_error(
        self, workflow, sample_batch_requests, mock_anthropic_batch_provider
    ):
        """Test executing batch that fails with runtime error."""
        # Given
        mock_anthropic_batch_provider.process_batch = AsyncMock(
            side_effect=RuntimeError("Batch processing failed")
        )

        # When/Then
        with pytest.raises(RuntimeError):
            await workflow.execute_batch(sample_batch_requests)

    @pytest.mark.asyncio
    async def test_given_single_request_when_execute_batch_then_returns_single_result(
        self, workflow, mock_anthropic_batch_provider
    ):
        """Test executing batch with single request."""
        # Given
        requests = [
            BatchRequest(
                task_id="task_1",
                task_type="analyze",
                input_data={"data": "test"},
            )
        ]
        mock_response = {"task_1": {"success": True, "output": {"result": "done"}}}
        mock_anthropic_batch_provider.process_batch = AsyncMock(
            return_value=mock_response
        )

        # When
        results = await workflow.execute_batch(requests)

        # Then
        assert len(results) == 1
        assert results[0].task_id == "task_1"
        assert results[0].success is True

    @pytest.mark.asyncio
    async def test_given_large_batch_when_execute_batch_then_handles_all_requests(
        self, workflow, mock_anthropic_batch_provider
    ):
        """Test executing batch with large number of requests."""
        # Given
        requests = [
            BatchRequest(
                task_id=f"task_{i}",
                task_type="analyze",
                input_data={"data": f"test_{i}"},
            )
            for i in range(100)
        ]
        mock_response = {
            f"task_{i}": {"success": True, "output": {"result": "done"}}
            for i in range(100)
        }
        mock_anthropic_batch_provider.process_batch = AsyncMock(
            return_value=mock_response
        )

        # When
        results = await workflow.execute_batch(requests)

        # Then
        assert len(results) == 100
        assert all(r.success for r in results)

    @pytest.mark.asyncio
    async def test_given_different_model_tiers_when_execute_batch_then_processes_all(
        self, workflow, mock_anthropic_batch_provider
    ):
        """Test executing batch with different model tiers."""
        # Given
        requests = [
            BatchRequest(
                task_id="task_1",
                task_type="analyze",
                input_data={"data": "test"},
                model_tier="cheap",
            ),
            BatchRequest(
                task_id="task_2",
                task_type="analyze",
                input_data={"data": "test"},
                model_tier="capable",
            ),
            BatchRequest(
                task_id="task_3",
                task_type="analyze",
                input_data={"data": "test"},
                model_tier="premium",
            ),
        ]
        mock_response = {
            "task_1": {"success": True, "output": {"result": "done"}},
            "task_2": {"success": True, "output": {"result": "done"}},
            "task_3": {"success": True, "output": {"result": "done"}},
        }
        mock_anthropic_batch_provider.process_batch = AsyncMock(
            return_value=mock_response
        )

        # When
        results = await workflow.execute_batch(requests)

        # Then
        assert len(results) == 3
        assert all(r.success for r in results)

    @pytest.mark.asyncio
    async def test_given_api_error_when_execute_batch_then_propagates_error(
        self, workflow, sample_batch_requests, mock_anthropic_batch_provider
    ):
        """Test executing batch when API returns error."""
        # Given
        mock_anthropic_batch_provider.process_batch = AsyncMock(
            side_effect=Exception("API error")
        )

        # When/Then
        with pytest.raises(Exception, match="API error"):
            await workflow.execute_batch(sample_batch_requests)

    @pytest.