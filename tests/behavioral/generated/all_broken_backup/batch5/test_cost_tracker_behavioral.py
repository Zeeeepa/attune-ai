"""Behavioral tests for cost_tracker.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import atexit
import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any
from unittest.mock import MagicMock, Mock, patch, mock_open, call

import pytest

from empathy_os.cost_tracker import (
    CostTracker,
    MODEL_PRICING,
    BASELINE_MODEL,
    _build_model_pricing,
)


@pytest.fixture
def temp_storage_dir(tmp_path):
    """Given a temporary directory for test storage."""
    storage_dir = tmp_path / "empathy_data"
    storage_dir.mkdir(parents=True, exist_ok=True)
    return storage_dir


@pytest.fixture
def tracker(temp_storage_dir):
    """Given a fresh CostTracker instance."""
    return CostTracker(storage_dir=temp_storage_dir)


@pytest.fixture
def tracker_with_data(temp_storage_dir):
    """Given a CostTracker with pre-existing data."""
    tracker = CostTracker(storage_dir=temp_storage_dir)
    
    # Add some test requests
    tracker.log_request("claude-3-haiku-20240307", 1000, 500, "summarize")
    tracker.log_request("claude-3-5-sonnet-20241022", 2000, 1000, "analyze")
    tracker.log_request("claude-opus-4-20250514", 500, 250, "generate")
    tracker.flush()
    
    return tracker


class TestModelPricingBuilder:
    """Behavioral tests for _build_model_pricing function."""

    def test_builds_pricing_from_registry(self):
        """Given model registry exists, when building pricing, then returns dict with pricing info."""
        # When
        pricing = _build_model_pricing()
        
        # Then
        assert isinstance(pricing, dict)
        assert len(pricing) > 0
        
        # Should contain tier pricing
        assert "haiku" in pricing
        assert "sonnet" in pricing
        assert "opus" in pricing
        
        # Each entry should have input and output costs
        for model_pricing in pricing.values():
            assert "input" in model_pricing
            assert "output" in model_pricing
            assert isinstance(model_pricing["input"], (int, float))
            assert isinstance(model_pricing["output"], (int, float))

    def test_includes_legacy_models(self):
        """Given legacy model names, when building pricing, then includes backward compatibility."""
        # When
        pricing = _build_model_pricing()
        
        # Then
        assert "claude-3-haiku-20240307" in pricing
        assert "claude-3-5-sonnet-20241022" in pricing
        assert "claude-opus-4-20250514" in pricing
        assert "gpt-4-turbo" in pricing


class TestCostTrackerInitialization:
    """Behavioral tests for CostTracker initialization."""

    def test_initializes_with_default_storage_dir(self):
        """Given no storage_dir, when creating tracker, then uses default location."""
        # When
        with patch("empathy_os.cost_tracker.Path") as mock_path:
            mock_path.home.return_value = Path("/home/user")
            tracker = CostTracker()
            
            # Then
            assert tracker.storage_dir is not None

    def test_creates_storage_directory(self, temp_storage_dir):
        """Given storage_dir doesn't exist, when creating tracker, then creates directory."""
        # Given
        new_dir = temp_storage_dir / "new_subdir"
        assert not new_dir.exists()
        
        # When
        tracker = CostTracker(storage_dir=new_dir)
        
        # Then
        assert new_dir.exists()

    def test_initializes_with_empty_data(self, temp_storage_dir):
        """Given no existing data, when creating tracker, then initializes empty structure."""
        # When
        tracker = CostTracker(storage_dir=temp_storage_dir)
        
        # Then
        assert tracker.data["total_cost"] == 0.0
        assert tracker.data["baseline_cost"] == 0.0
        assert tracker.data["total_requests"] == 0
        assert len(tracker.requests) == 0

    def test_loads_existing_json_data(self, temp_storage_dir):
        """Given existing JSON file, when creating tracker, then loads data."""
        # Given
        existing_data = {
            "total_cost": 10.0,
            "baseline_cost": 20.0,
            "total_requests": 5,
            "requests": [
                {
                    "model": "test-model",
                    "input_tokens": 100,
                    "output_tokens": 50,
                    "cost": 2.0,
                    "baseline_cost": 4.0,
                    "task_type": "test",
                    "timestamp": "2025-01-01T00:00:00",
                }
            ],
        }
        
        summary_file = temp_storage_dir / "cost_summary.json"
        with open(summary_file, "w") as f:
            json.dump(existing_data, f)
        
        # When
        tracker = CostTracker(storage_dir=temp_storage_dir)
        
        # Then
        assert tracker.data["total_cost"] == 10.0
        assert tracker.data["baseline_cost"] == 20.0
        assert tracker.data["total_requests"] == 5

    def test_loads_existing_jsonl_data(self, temp_storage_dir):
        """Given existing JSONL file, when creating tracker, then loads requests lazily."""
        # Given
        requests_file = temp_storage_dir / "cost_requests.jsonl"
        with open(requests_file, "w") as f:
            request = {
                "model": "test-model",
                "input_tokens": 100,
                "output_tokens": 50,
                "cost": 2.0,
                "baseline_cost": 4.0,
                "task_type": "test",
                "timestamp": "2025-01-01T00:00:00",
            }
            f.write(json.dumps(request) + "\n")
        
        # When
        tracker = CostTracker(storage_dir=temp_storage_dir)
        
        # Then - not loaded yet
        assert tracker._requests_loaded is False
        
        # When accessing requests
        requests = tracker.requests
        
        # Then - now loaded
        assert tracker._requests_loaded is True
        assert len(requests) == 1
        assert requests[0]["model"] == "test-model"

    def test_registers_atexit_handler(self, temp_storage_dir):
        """Given tracker creation, when initializing, then registers flush on exit."""
        # When
        with patch("empathy_os.cost_tracker.atexit.register") as mock_register:
            tracker = CostTracker(storage_dir=temp_storage_dir)
            
            # Then
            mock_register.assert_called_once_with(tracker.flush)

    def test_handles_corrupted_json_file(self, temp_storage_dir):
        """Given corrupted JSON file, when creating tracker, then initializes empty."""
        # Given
        summary_file = temp_storage_dir / "cost_summary.json"
        with open(summary_file, "w") as f:
            f.write("invalid json {")
        
        # When
        tracker = CostTracker(storage_dir=temp_storage_dir)
        
        # Then
        assert tracker.data["total_cost"] == 0.0
        assert tracker.data["total_requests"] == 0


class TestLazyLoading:
    """Behavioral tests for lazy loading of request history."""

    def test_requests_not_loaded_on_init(self, temp_storage_dir):
        """Given tracker initialization, when not accessing requests, then data not loaded."""
        # Given
        requests_file = temp_storage_dir / "cost_requests.jsonl"
        with open(requests_file, "w") as f:
            f.write(json.dumps({"model": "test"}) + "\n")
        
        # When
        tracker = CostTracker(storage_dir=temp_storage_dir)
        
        # Then
        assert tracker._requests_loaded is False

    def test_requests_loaded_on_first_access(self, temp_storage_dir):
        """Given tracker with data, when accessing requests, then loads lazily."""
        # Given
        requests_file = temp_storage_dir / "cost_requests.jsonl"
        with open(requests_file, "w") as f:
            f.write(json.dumps({"model": "test-model"}) + "\n")
        
        tracker = CostTracker(storage_dir=temp_storage_dir)
        
        # When
        requests = tracker.requests
        
        # Then
        assert tracker._requests_loaded is True
        assert len(requests) == 1
        assert requests[0]["model"] == "test-model"

    def test_subsequent_access_uses_cached_data(self, temp_storage_dir):
        """Given loaded requests, when accessing again, then uses cached data."""
        # Given
        requests_file = temp_storage_dir / "cost_requests.jsonl"
        with open(requests_file, "w") as f:
            f.write(json.dumps({"model": "test"}) + "\n")
        
        tracker = CostTracker(storage_dir=temp_storage_dir)
        first_access = tracker.requests
        
        # When
        with patch.object(tracker, "_load_requests") as mock_load:
            second_access = tracker.requests
            
            # Then
            mock_load.assert_not_called()
            assert first_access is second_access


class TestLogRequest:
    """Behavioral tests for logging API requests."""

    def test_logs_request_with_valid_model(self, tracker):
        """Given valid model and tokens, when logging request, then records correctly."""
        # When
        tracker.log_request("claude-3-haiku-20240307", 1000, 500, "summarize")
        
        # Then
        assert len(tracker.requests) == 1
        request = tracker.requests[0]
        assert request["model"] == "claude-3-haiku-20240307"
        assert request["input_tokens"] == 1000
        assert request["output_tokens"] == 500
        assert request["task_type"] == "summarize"
        assert "timestamp" in request
        assert "cost" in request
        assert "baseline_cost" in request

    def test_calculates_cost_correctly(self, tracker):
        """Given model pricing, when logging request, then calculates cost accurately."""
        # Given
        model = "claude-3-haiku-20240307"
        input_tokens = 1000
        output_tokens = 500
        
        expected_cost = (
            (input_tokens * MODEL_PRICING[model]["input"] / 1_000_000) +
            (output_tokens * MODEL_PRICING[model]["output"] / 1_000_000)
        )
        
        # When
        tracker.log_request(model, input_tokens, output_tokens, "test")
        
        # Then
        assert abs(tracker.requests[0]["cost"] - expected_cost) < 0.0001

    def test_calculates_baseline_cost(self, tracker):
        """Given baseline model, when logging request, then calculates baseline cost."""
        # Given
        input_tokens = 1000
        output_tokens = 500
        
        expected_baseline = (
            (input_tokens * MODEL_PRICING[BASELINE_MODEL]["input"] / 1_000_000) +
            (output_tokens * MODEL_PRICING[BASELINE_MODEL]["output"] / 1_000_000)
        )
        
        # When
        tracker.log_request("claude-3-haiku-20240307", input_tokens, output_tokens, "test")
        
        # Then
        assert abs(tracker.requests[0]["baseline_cost"] - expected_baseline) < 0.0001

    def test_updates_summary_totals(self, tracker):
        """Given logged requests, when tracking, then updates totals correctly."""
        # When
        tracker.log_request("claude-3-haiku-20240307", 1000, 500, "test1")
        tracker.log_request("claude-3-5-sonnet-20241022", 2000, 1000, "test2")
        
        # Then
        assert tracker.data["total_requests"] == 2
        assert tracker.data["total_cost"] > 0
        assert tracker.data["baseline_cost"] > tracker.data["total_cost"]

    def test_adds_request_to_buffer(self, tracker):
        """Given logged request, when not flushed, then stores in buffer."""
        # When
        tracker.log_request("claude-3-haiku-20240307", 1000, 500, "test")
        
        # Then
        assert len(tracker._buffer) == 1

    def test_handles_unknown_model_with_default_pricing(self, tracker):
        """Given unknown model, when logging, then uses baseline pricing."""
        # When
        tracker.log_request("unknown-model", 1000, 500, "test")
        
        # Then
        assert len(tracker.requests) == 1
        # Should calculate using baseline model
        request = tracker.requests[0]
        assert request["cost"] == request["baseline_cost"]

    def test_handles_zero_tokens(self, tracker):
        """Given zero tokens, when logging, then records with zero cost."""
        # When
        tracker.log_request("claude-3-haiku-20240307", 0, 0, "test")
        
        # Then
        assert tracker.requests[0]["cost"] == 0.0
        assert tracker.requests[0]["baseline_cost"] == 0.0

    def test_auto_flush_on_buffer_limit(self, tracker):
        """Given buffer limit reached, when logging, then auto-flushes."""
        # Given - set small buffer size for testing
        tracker.batch_size = 3
        
        # When
        with patch.object(tracker, "flush") as mock_flush:
            tracker.log_request("claude-3-haiku-20240307", 100, 50, "test1")
            tracker.log_request("claude-3-haiku-20240307", 100, 50, "test2")
            mock_flush.assert_not_called()
            
            tracker.log_request("claude-3-haiku-20240307", 100, 50, "test3")
            mock_flush.assert_called_once()


class TestFlush:
    """Behavioral tests for flushing data to disk."""

    def test_flushes_buffer_to_jsonl(self, tracker):
        """Given buffered requests, when flushing, then writes to JSONL file."""
        # Given
        tracker.log_request("claude-3-haiku-20240307", 1000, 500, "test")
        
        # When
        tracker.flush()
        
        # Then
        requests_file = tracker.storage_dir / "cost_requests.jsonl"
        assert requests_file.exists()
        
        with open(requests_file, "r") as f:
            lines = f.readlines()
            assert len(lines) == 1
            data = json.loads(lines[0])
            assert data["model"] == "claude-3-haiku-20240307"

    def test_writes_summary_to_json(self, tracker):
        """Given data to flush, when flushing, then writes summary file."""
        # Given
        tracker.log_request("claude-3-haiku-20240307", 1000, 500, "test")