"""Behavioral tests for test_gen 2.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import ast
import logging
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Any
from unittest.mock import MagicMock, Mock, PropertyMock, call, mock_open, patch

import pytest

from empathy_os.workflows.progressive.core import (
    EscalationConfig,
    FailureAnalysis,
    ProgressiveWorkflowResult,
    Tier,
    TierResult,
)
from empathy_os.workflows.progressive.test_gen_2 import (
    ProgressiveTestGenWorkflow,
)


# Fixtures


@pytest.fixture
def basic_escalation_config():
    """Provide a basic escalation configuration for testing."""
    return EscalationConfig(
        enabled=True,
        max_cost=10.00,
        cheap_tier_model="gpt-4o-mini",
        capable_tier_model="claude-3-5-sonnet",
        premium_tier_model="claude-opus-4",
    )


@pytest.fixture
def disabled_escalation_config():
    """Provide a disabled escalation configuration."""
    return EscalationConfig(enabled=False, max_cost=0.0)


@pytest.fixture
def workflow_with_config(basic_escalation_config):
    """Provide a workflow instance with basic configuration."""
    return ProgressiveTestGenWorkflow(config=basic_escalation_config)


@pytest.fixture
def workflow_without_config():
    """Provide a workflow instance without explicit configuration."""
    return ProgressiveTestGenWorkflow()


@pytest.fixture
def sample_python_file(tmp_path):
    """Create a temporary Python file with sample functions."""
    file_path = tmp_path / "sample.py"
    content = '''
def add(a, b):
    """Add two numbers."""
    return a + b

def multiply(x, y):
    """Multiply two numbers."""
    return x * y

class Calculator:
    """Simple calculator class."""
    
    def divide(self, a, b):
        """Divide two numbers."""
        if b == 0:
            raise ValueError("Cannot divide by zero")
        return a / b
'''
    file_path.write_text(content)
    return file_path


@pytest.fixture
def empty_python_file(tmp_path):
    """Create a temporary empty Python file."""
    file_path = tmp_path / "empty.py"
    file_path.write_text("# Empty file\n")
    return file_path


@pytest.fixture
def invalid_python_file(tmp_path):
    """Create a temporary file with invalid Python syntax."""
    file_path = tmp_path / "invalid.py"
    file_path.write_text("def broken(:\n    pass\n")
    return file_path


@pytest.fixture
def mock_tier_result():
    """Provide a mock TierResult."""
    return TierResult(
        tier=Tier.CHEAP,
        model="gpt-4o-mini",
        success=True,
        generated_items=["test_add", "test_multiply"],
        cost=0.01,
        quality_score=0.85,
        execution_time=1.5,
        metadata={"coverage": 75},
    )


@pytest.fixture
def mock_progressive_result(mock_tier_result):
    """Provide a mock ProgressiveWorkflowResult."""
    return ProgressiveWorkflowResult(
        task_type="test-gen",
        final_result=mock_tier_result,
        tier_progression=[Tier.CHEAP],
        total_cost=0.01,
        total_time=1.5,
        escalation_count=0,
        final_quality_score=0.85,
        metadata={"functions_tested": 2},
    )


# Tests for ProgressiveTestGenWorkflow.__init__


class TestProgressiveTestGenWorkflowInit:
    """Tests for ProgressiveTestGenWorkflow initialization."""

    def test_init_with_config(self, basic_escalation_config):
        """
        GIVEN a valid escalation configuration
        WHEN initializing ProgressiveTestGenWorkflow
        THEN the workflow should be created with the config and target_file as None
        """
        workflow = ProgressiveTestGenWorkflow(config=basic_escalation_config)

        assert workflow.config == basic_escalation_config
        assert workflow.target_file is None

    def test_init_without_config(self):
        """
        GIVEN no escalation configuration
        WHEN initializing ProgressiveTestGenWorkflow
        THEN the workflow should use default configuration
        """
        workflow = ProgressiveTestGenWorkflow()

        assert workflow.config is not None
        assert workflow.target_file is None

    def test_init_with_none_config(self):
        """
        GIVEN None as configuration
        WHEN initializing ProgressiveTestGenWorkflow
        THEN the workflow should handle None and use defaults
        """
        workflow = ProgressiveTestGenWorkflow(config=None)

        assert workflow.target_file is None


# Tests for ProgressiveTestGenWorkflow.execute


class TestProgressiveTestGenWorkflowExecute:
    """Tests for the execute method of ProgressiveTestGenWorkflow."""

    def test_execute_with_valid_file(
        self, workflow_with_config, sample_python_file, mock_progressive_result
    ):
        """
        GIVEN a valid Python file with functions
        WHEN executing the workflow
        THEN tests should be generated and results returned
        """
        with patch.object(
            workflow_with_config, "_parse_functions", return_value=["add", "multiply"]
        ) as mock_parse, patch.object(
            workflow_with_config,
            "_execute_progressive_generation",
            return_value=mock_progressive_result,
        ) as mock_execute:

            result = workflow_with_config.execute(target_file=str(sample_python_file))

            assert workflow_with_config.target_file == sample_python_file
            mock_parse.assert_called_once_with(sample_python_file)
            assert result == mock_progressive_result

    def test_execute_with_nonexistent_file(self, workflow_with_config):
        """
        GIVEN a path to a nonexistent file
        WHEN executing the workflow
        THEN FileNotFoundError should be raised
        """
        with pytest.raises(FileNotFoundError) as exc_info:
            workflow_with_config.execute(target_file="/nonexistent/file.py")

        assert "Target file not found" in str(exc_info.value)

    def test_execute_with_empty_file(
        self, workflow_with_config, empty_python_file, mock_progressive_result
    ):
        """
        GIVEN a Python file with no functions
        WHEN executing the workflow
        THEN an empty result should be returned
        """
        with patch.object(
            workflow_with_config, "_parse_functions", return_value=[]
        ) as mock_parse, patch.object(
            workflow_with_config, "_create_empty_result", return_value=mock_progressive_result
        ) as mock_empty:

            result = workflow_with_config.execute(target_file=str(empty_python_file))

            mock_parse.assert_called_once()
            mock_empty.assert_called_once_with("test-gen")
            assert result == mock_progressive_result

    def test_execute_logs_function_count(
        self, workflow_with_config, sample_python_file, mock_progressive_result, caplog
    ):
        """
        GIVEN a valid Python file with multiple functions
        WHEN executing the workflow
        THEN the number of functions found should be logged
        """
        with patch.object(
            workflow_with_config, "_parse_functions", return_value=["func1", "func2", "func3"]
        ), patch.object(
            workflow_with_config,
            "_execute_progressive_generation",
            return_value=mock_progressive_result,
        ):
            with caplog.at_level(logging.INFO):
                workflow_with_config.execute(target_file=str(sample_python_file))

            assert "Found 3 functions to test" in caplog.text

    def test_execute_with_additional_kwargs(
        self, workflow_with_config, sample_python_file, mock_progressive_result
    ):
        """
        GIVEN additional keyword arguments
        WHEN executing the workflow
        THEN the kwargs should be accepted without error
        """
        with patch.object(
            workflow_with_config, "_parse_functions", return_value=["add"]
        ), patch.object(
            workflow_with_config,
            "_execute_progressive_generation",
            return_value=mock_progressive_result,
        ):

            result = workflow_with_config.execute(
                target_file=str(sample_python_file),
                extra_param="value",
                another_param=123,
            )

            assert result == mock_progressive_result

    def test_execute_sets_target_file_path(self, workflow_with_config, sample_python_file):
        """
        GIVEN a valid target file path as string
        WHEN executing the workflow
        THEN target_file should be converted to Path object
        """
        with patch.object(
            workflow_with_config, "_parse_functions", return_value=["add"]
        ), patch.object(
            workflow_with_config,
            "_execute_progressive_generation",
            return_value=Mock(),
        ):

            workflow_with_config.execute(target_file=str(sample_python_file))

            assert isinstance(workflow_with_config.target_file, Path)
            assert workflow_with_config.target_file == sample_python_file

    def test_execute_with_budget_exceeded_error(
        self, workflow_with_config, sample_python_file
    ):
        """
        GIVEN a workflow execution that exceeds budget
        WHEN executing the workflow
        THEN BudgetExceededError should be propagated
        """
        from empathy_os.workflows.progressive.core import BudgetExceededError

        with patch.object(
            workflow_with_config, "_parse_functions", return_value=["add"]
        ), patch.object(
            workflow_with_config,
            "_execute_progressive_generation",
            side_effect=BudgetExceededError("Budget exceeded"),
        ):

            with pytest.raises(BudgetExceededError):
                workflow_with_config.execute(target_file=str(sample_python_file))

    def test_execute_with_user_cancelled_error(
        self, workflow_with_config, sample_python_file
    ):
        """
        GIVEN a workflow execution where user cancels approval
        WHEN executing the workflow
        THEN UserCancelledError should be propagated
        """
        from empathy_os.workflows.progressive.core import UserCancelledError

        with patch.object(
            workflow_with_config, "_parse_functions", return_value=["add"]
        ), patch.object(
            workflow_with_config,
            "_execute_progressive_generation",
            side_effect=UserCancelledError("User cancelled"),
        ):

            with pytest.raises(UserCancelledError):
                workflow_with_config.execute(target_file=str(sample_python_file))


# Tests for ProgressiveTestGenWorkflow._parse_functions (private method behavior)


class TestProgressiveTestGenWorkflowParseFunctions:
    """Tests for the _parse_functions private method behavior."""

    def test_parse_functions_from_valid_file(
        self, workflow_with_config, sample_python_file
    ):
        """
        GIVEN a valid Python file with function definitions
        WHEN _parse_functions is called
        THEN it should return a list of function names
        """
        # Since _parse_functions is private, we test through execute
        with patch.object(
            workflow_with_config, "_parse_functions", wraps=workflow_with_config._parse_functions
        ) as mock_parse, patch.object(
            workflow_with_config, "_execute_progressive_generation", return_value=Mock()
        ):

            workflow_with_config.execute(target_file=str(sample_python_file))

            mock_parse.assert_called_once()
            args = mock_parse.call_args[0]
            assert args[0] == sample_python_file

    def test_parse_functions_handles_syntax_errors(
        self, workflow_with_config, invalid_python_file
    ):
        """
        GIVEN a Python file with syntax errors
        WHEN _parse_functions attempts to parse it
        THEN it should handle the syntax error gracefully
        """
        # Testing through mocking since it's a private method
        with patch("ast.parse", side_effect=SyntaxError("Invalid syntax")):
            with patch.object(
                workflow_with_config, "_create_empty_result", return_value=Mock()
            ):
                # This should handle the syntax error internally
                result = workflow_with_config._parse_functions(invalid_python_file)
                # Depending on implementation, might return empty list or raise
                assert result is not None


# Tests for integration scenarios


class TestProgressiveTestGenWorkflowIntegration:
    """Integration tests for the complete workflow."""

    def test_full_workflow_execution(
        self, workflow_with_config, sample_python_file, mock_progressive_result
    ):
        """
        GIVEN a complete workflow setup
        WHEN executing end-to-end
        THEN all components should work together correctly
        """
        with patch.object(
            workflow_with_config, "_parse_functions", return_value=["add", "multiply"]
        ), patch.object(
            workflow_with_config,
            "_execute_progressive_generation",
            return_value=mock_progressive_result,
        ):

            result = workflow_with_config.execute(target_file=str(sample_python_file))

            assert result.task_type == "test-gen"
            assert result.final_quality_score == 0.85
            assert result.total_cost == 0.01

    def test_workflow_with_multiple_tiers(
        self, workflow_with_config, sample_python_file
    ):
        """
        GIVEN a workflow that escalates through multiple tiers
        WHEN executing
        THEN tier progression should be tracked correctly
        """
        escalated_result = ProgressiveWorkflowResult(
            task_type="test-gen",
            final_result=TierResult(
                tier=Tier.CAPABLE,
                model="claude-3-5-sonnet",
                success=True,
                generated_items=["test_add", "test_multiply"],
                cost=0.50,
                quality_score=0.95,
                execution_time=3.0,
                metadata={},
            ),
            tier_progression=[Tier.CHEAP, Tier.CAPABLE],
            total_cost=0.51,
            total_time=4.5,
            escalation_count=1,
            final_quality_score=0.95,
            metadata={},
        )

        with patch.object(
            workflow_with_config, "_parse_functions", return_value=["add"]
        ), patch.object(
            workflow_with_config,
            "_execute_progressive_generation",
            return_value=escalated_result,
        ):

            result = workflow_with_config.execute(target_file=str(sample_python_file))

            assert len(result.tier_progression) == 2
            assert result.escalation_count == 1
            assert Tier.CHEAP in result.tier_progression
            assert Tier.CAPABLE in result.tier_progression

    def test_workflow_respects_disabled_escalation(
        self, disabled_escalation_config, sample_python_file, mock_progressive_result
    ):
        """
        GIVEN a workflow with disabled escalation
        WHEN executing
        THEN only the cheap tier should be used
        """
        workflow = Progress