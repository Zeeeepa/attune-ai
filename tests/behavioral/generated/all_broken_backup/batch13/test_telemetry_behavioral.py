"""Behavioral tests for telemetry.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import logging
from datetime import datetime
from unittest.mock import MagicMock, Mock, patch

import pytest

from empathy_os.workflows.progressive.core import (
    ProgressiveWorkflowResult,
    Tier,
    TierResult,
)
from empathy_os.workflows.progressive.telemetry import ProgressiveTelemetry


@pytest.fixture
def mock_usage_tracker():
    """Provide a mock UsageTracker instance."""
    with patch("empathy_os.workflows.progressive.telemetry.UsageTracker") as mock_tracker_class:
        mock_instance = MagicMock()
        mock_tracker_class.get_instance.return_value = mock_instance
        yield mock_instance


@pytest.fixture
def sample_tier_result():
    """Provide a sample TierResult for testing."""
    tier_result = Mock(spec=TierResult)
    tier_result.tier = Tier.FAST
    tier_result.model = "gpt-4o-mini"
    tier_result.cost = 0.123
    tier_result.duration = 1.5
    tier_result.tokens_used = {
        "input": 100,
        "output": 200,
        "total": 300,
    }
    tier_result.success = True
    tier_result.output = {"result": "test"}
    tier_result.error = None
    return tier_result


@pytest.fixture
def sample_workflow_result():
    """Provide a sample ProgressiveWorkflowResult for testing."""
    result = Mock(spec=ProgressiveWorkflowResult)
    result.final_result = [{"test": "data1"}, {"test": "data2"}]
    result.final_tier = Tier.SMART
    result.total_cost = 0.456
    result.total_duration = 3.5
    result.escalations = 1
    result.tier_results = []
    return result


class TestProgressiveTelemetryInitialization:
    """Test suite for ProgressiveTelemetry initialization."""

    def test_given_workflow_name_when_initialized_then_sets_attributes(
        self, mock_usage_tracker
    ):
        """Given a workflow name, when initialized, then sets workflow name and tracker."""
        # Given
        workflow_name = "test-workflow"
        
        # When
        telemetry = ProgressiveTelemetry(workflow_name=workflow_name)
        
        # Then
        assert telemetry.workflow_name == workflow_name
        assert telemetry.user_id is None
        assert telemetry.tracker is not None

    def test_given_workflow_name_and_user_id_when_initialized_then_sets_both(
        self, mock_usage_tracker
    ):
        """Given workflow name and user ID, when initialized, then sets both attributes."""
        # Given
        workflow_name = "test-workflow"
        user_id = "user-123"
        
        # When
        telemetry = ProgressiveTelemetry(workflow_name=workflow_name, user_id=user_id)
        
        # Then
        assert telemetry.workflow_name == workflow_name
        assert telemetry.user_id == user_id

    def test_given_initialization_when_created_then_gets_tracker_instance(
        self, mock_usage_tracker
    ):
        """Given initialization, when created, then gets UsageTracker instance."""
        # Given / When
        with patch("empathy_os.workflows.progressive.telemetry.UsageTracker") as mock_tracker:
            mock_instance = MagicMock()
            mock_tracker.get_instance.return_value = mock_instance
            
            telemetry = ProgressiveTelemetry(workflow_name="test")
            
            # Then
            mock_tracker.get_instance.assert_called_once()
            assert telemetry.tracker == mock_instance


class TestTrackTierExecution:
    """Test suite for track_tier_execution method."""

    def test_given_tier_result_when_tracked_then_calls_tracker_with_correct_params(
        self, mock_usage_tracker, sample_tier_result
    ):
        """Given a tier result, when tracked, then calls tracker with correct parameters."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow", user_id="user-123")
        attempt = 1
        escalated = False
        
        # When
        telemetry.track_tier_execution(
            tier_result=sample_tier_result,
            attempt=attempt,
            escalated=escalated,
            escalation_reason=None,
        )
        
        # Then
        mock_usage_tracker.track_llm_call.assert_called_once()
        call_kwargs = mock_usage_tracker.track_llm_call.call_args[1]
        assert call_kwargs["workflow"] == "test-workflow"
        assert call_kwargs["stage"] == "tier-fast-attempt-1"
        assert call_kwargs["tier"] == "FAST"
        assert call_kwargs["model"] == "gpt-4o-mini"
        assert call_kwargs["cost"] == 0.123
        assert call_kwargs["user_id"] == "user-123"

    def test_given_tier_result_when_tracked_then_extracts_tokens_correctly(
        self, mock_usage_tracker, sample_tier_result
    ):
        """Given a tier result, when tracked, then extracts token counts correctly."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow")
        
        # When
        telemetry.track_tier_execution(
            tier_result=sample_tier_result,
            attempt=1,
            escalated=False,
        )
        
        # Then
        call_kwargs = mock_usage_tracker.track_llm_call.call_args[1]
        tokens = call_kwargs["tokens"]
        assert tokens["input_tokens"] == 100
        assert tokens["output_tokens"] == 200
        assert tokens["total_tokens"] == 300

    def test_given_tier_result_when_tracked_then_converts_duration_to_ms(
        self, mock_usage_tracker, sample_tier_result
    ):
        """Given a tier result, when tracked, then converts duration to milliseconds."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow")
        sample_tier_result.duration = 2.5  # 2.5 seconds
        
        # When
        telemetry.track_tier_execution(
            tier_result=sample_tier_result,
            attempt=1,
            escalated=False,
        )
        
        # Then
        call_kwargs = mock_usage_tracker.track_llm_call.call_args[1]
        assert call_kwargs["duration_ms"] == 2500

    def test_given_escalated_tier_when_tracked_then_includes_escalation_info(
        self, mock_usage_tracker, sample_tier_result
    ):
        """Given an escalated tier, when tracked, then includes escalation information."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow")
        escalation_reason = "Quality threshold not met"
        
        # When
        telemetry.track_tier_execution(
            tier_result=sample_tier_result,
            attempt=1,
            escalated=True,
            escalation_reason=escalation_reason,
        )
        
        # Then
        mock_usage_tracker.track_llm_call.assert_called_once()

    def test_given_smart_tier_when_tracked_then_uses_correct_tier_name(
        self, mock_usage_tracker, sample_tier_result
    ):
        """Given a smart tier result, when tracked, then uses correct tier name."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow")
        sample_tier_result.tier = Tier.SMART
        
        # When
        telemetry.track_tier_execution(
            tier_result=sample_tier_result,
            attempt=1,
            escalated=False,
        )
        
        # Then
        call_kwargs = mock_usage_tracker.track_llm_call.call_args[1]
        assert call_kwargs["tier"] == "SMART"
        assert call_kwargs["stage"] == "tier-smart-attempt-1"

    def test_given_genius_tier_when_tracked_then_uses_correct_tier_name(
        self, mock_usage_tracker, sample_tier_result
    ):
        """Given a genius tier result, when tracked, then uses correct tier name."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow")
        sample_tier_result.tier = Tier.GENIUS
        
        # When
        telemetry.track_tier_execution(
            tier_result=sample_tier_result,
            attempt=1,
            escalated=False,
        )
        
        # Then
        call_kwargs = mock_usage_tracker.track_llm_call.call_args[1]
        assert call_kwargs["tier"] == "GENIUS"
        assert call_kwargs["stage"] == "tier-genius-attempt-1"

    def test_given_multiple_attempts_when_tracked_then_includes_attempt_number(
        self, mock_usage_tracker, sample_tier_result
    ):
        """Given multiple attempts, when tracked, then includes attempt number in stage."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow")
        
        # When
        telemetry.track_tier_execution(
            tier_result=sample_tier_result,
            attempt=3,
            escalated=False,
        )
        
        # Then
        call_kwargs = mock_usage_tracker.track_llm_call.call_args[1]
        assert call_kwargs["stage"] == "tier-fast-attempt-3"

    def test_given_missing_token_fields_when_tracked_then_defaults_to_zero(
        self, mock_usage_tracker, sample_tier_result
    ):
        """Given missing token fields, when tracked, then defaults to zero."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow")
        sample_tier_result.tokens_used = {}  # Empty tokens
        
        # When
        telemetry.track_tier_execution(
            tier_result=sample_tier_result,
            attempt=1,
            escalated=False,
        )
        
        # Then
        call_kwargs = mock_usage_tracker.track_llm_call.call_args[1]
        tokens = call_kwargs["tokens"]
        assert tokens["input_tokens"] == 0
        assert tokens["output_tokens"] == 0
        assert tokens["total_tokens"] == 0

    def test_given_tracker_exception_when_tracked_then_logs_warning_and_continues(
        self, mock_usage_tracker, sample_tier_result, caplog
    ):
        """Given tracker exception, when tracked, then logs warning and continues."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow")
        mock_usage_tracker.track_llm_call.side_effect = Exception("Tracker error")
        
        # When
        with caplog.at_level(logging.WARNING):
            telemetry.track_tier_execution(
                tier_result=sample_tier_result,
                attempt=1,
                escalated=False,
            )
        
        # Then
        assert "Failed to track tier execution" in caplog.text
        assert "Tracker error" in caplog.text

    def test_given_tier_result_when_tracked_then_cache_hit_is_false(
        self, mock_usage_tracker, sample_tier_result
    ):
        """Given a tier result, when tracked, then cache_hit is always False."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow")
        
        # When
        telemetry.track_tier_execution(
            tier_result=sample_tier_result,
            attempt=1,
            escalated=False,
        )
        
        # Then
        call_kwargs = mock_usage_tracker.track_llm_call.call_args[1]
        assert call_kwargs["cache_hit"] is False
        assert call_kwargs["cache_type"] is None

    def test_given_no_user_id_when_tracked_then_user_id_is_none(
        self, mock_usage_tracker, sample_tier_result
    ):
        """Given no user ID, when tracked, then user_id is None in tracking call."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow")
        
        # When
        telemetry.track_tier_execution(
            tier_result=sample_tier_result,
            attempt=1,
            escalated=False,
        )
        
        # Then
        call_kwargs = mock_usage_tracker.track_llm_call.call_args[1]
        assert call_kwargs["user_id"] is None


class TestGetProvider:
    """Test suite for _get_provider helper method."""

    def test_given_gpt_model_when_getting_provider_then_returns_openai(
        self, mock_usage_tracker
    ):
        """Given a GPT model, when getting provider, then returns openai."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow")
        
        # When
        provider = telemetry._get_provider("gpt-4o-mini")
        
        # Then
        assert provider == "openai"

    def test_given_claude_model_when_getting_provider_then_returns_anthropic(
        self, mock_usage_tracker
    ):
        """Given a Claude model, when getting provider, then returns anthropic."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow")
        
        # When
        provider = telemetry._get_provider("claude-3-5-sonnet")
        
        # Then
        assert provider == "anthropic"

    def test_given_o1_model_when_getting_provider_then_returns_openai(
        self, mock_usage_tracker
    ):
        """Given an o1 model, when getting provider, then returns openai."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow")
        
        # When
        provider = telemetry._get_provider("o1-preview")
        
        # Then
        assert provider == "openai"

    def test_given_unknown_model_when_getting_provider_then_returns_unknown(
        self, mock_usage_tracker
    ):
        """Given an unknown model, when getting provider, then returns unknown."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow")
        
        # When
        provider = telemetry._get_provider("some-unknown-model")
        
        # Then
        assert provider == "unknown"


class TestTrackWorkflowCompletion:
    """Test suite for track_workflow_completion method."""

    def test_given_workflow_result_when_tracked_then_calls_tracker(
        self, mock_usage_tracker, sample_workflow_result
    ):
        """Given a workflow result, when tracked, then calls tracker with metrics."""
        # Given
        telemetry = ProgressiveTelemetry(workflow_name="test-workflow", user_id="user-123")
        
        # When
        telemetry.track_workflow_completion(result=sample_workflow_result)
        
        # Then
        # Verify tracking was