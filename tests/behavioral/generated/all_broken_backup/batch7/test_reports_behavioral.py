"""Behavioral tests for reports.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import pytest
from datetime import datetime
from unittest.mock import Mock, patch

from empathy_os.project_index.reports import ReportGenerator
from empathy_os.project_index.models import (
    FileRecord,
    ProjectSummary,
    TestRequirement,
    FileCategory,
)


# ===== Fixtures =====


@pytest.fixture
def sample_summary():
    """Given a basic project summary."""
    return ProjectSummary(
        total_files=10,
        total_source_files=7,
        total_test_files=3,
        total_lines_of_code=1000,
        files_needing_tests=5,
        test_coverage_estimate=0.4,
        high_impact_files=2,
        last_indexed=datetime(2025, 1, 1, 12, 0, 0),
    )


@pytest.fixture
def source_file_with_tests():
    """Given a source file that has tests."""
    return FileRecord(
        path="src/empathy_os/core/engine.py",
        name="engine.py",
        category=FileCategory.SOURCE,
        lines_of_code=150,
        test_requirement=TestRequirement.REQUIRED,
        tests_exist=True,
        impact_score=7.5,
        imported_by_count=10,
    )


@pytest.fixture
def source_file_without_tests():
    """Given a source file without tests."""
    return FileRecord(
        path="src/empathy_os/core/processor.py",
        name="processor.py",
        category=FileCategory.SOURCE,
        lines_of_code=200,
        test_requirement=TestRequirement.REQUIRED,
        tests_exist=False,
        impact_score=8.0,
        imported_by_count=15,
    )


@pytest.fixture
def low_impact_file_without_tests():
    """Given a low impact source file without tests."""
    return FileRecord(
        path="src/empathy_os/utils/helpers.py",
        name="helpers.py",
        category=FileCategory.SOURCE,
        lines_of_code=50,
        test_requirement=TestRequirement.REQUIRED,
        tests_exist=False,
        impact_score=2.0,
        imported_by_count=2,
    )


@pytest.fixture
def high_impact_file_without_tests():
    """Given a high impact source file without tests."""
    return FileRecord(
        path="src/empathy_os/core/critical.py",
        name="critical.py",
        category=FileCategory.SOURCE,
        lines_of_code=300,
        test_requirement=TestRequirement.REQUIRED,
        tests_exist=False,
        impact_score=9.5,
        imported_by_count=25,
    )


@pytest.fixture
def config_file():
    """Given a config file."""
    return FileRecord(
        path="config/settings.yaml",
        name="settings.yaml",
        category=FileCategory.CONFIG,
        lines_of_code=30,
        test_requirement=TestRequirement.OPTIONAL,
        tests_exist=False,
        impact_score=1.0,
        imported_by_count=0,
    )


@pytest.fixture
def sample_records(
    source_file_with_tests,
    source_file_without_tests,
    low_impact_file_without_tests,
    high_impact_file_without_tests,
    config_file,
):
    """Given a collection of sample file records."""
    return [
        source_file_with_tests,
        source_file_without_tests,
        low_impact_file_without_tests,
        high_impact_file_without_tests,
        config_file,
    ]


@pytest.fixture
def report_generator(sample_summary, sample_records):
    """Given a report generator instance."""
    return ReportGenerator(summary=sample_summary, records=sample_records)


# ===== ReportGenerator Initialization Tests =====


class TestReportGeneratorInit:
    """Tests for ReportGenerator initialization."""

    def test_initialization_with_valid_data(self, sample_summary, sample_records):
        """
        Given valid summary and records
        When ReportGenerator is initialized
        Then it should store the data and filter source records correctly
        """
        # When
        generator = ReportGenerator(summary=sample_summary, records=sample_records)

        # Then
        assert generator.summary == sample_summary
        assert generator.records == sample_records
        assert len(generator._source_records) == 4  # Excludes config file
        assert all(r.category == FileCategory.SOURCE for r in generator._source_records)

    def test_initialization_with_empty_records(self, sample_summary):
        """
        Given an empty records list
        When ReportGenerator is initialized
        Then it should handle empty list gracefully
        """
        # When
        generator = ReportGenerator(summary=sample_summary, records=[])

        # Then
        assert generator.summary == sample_summary
        assert generator.records == []
        assert generator._source_records == []

    def test_initialization_filters_only_source_files(self, sample_summary):
        """
        Given records with mixed categories
        When ReportGenerator is initialized
        Then _source_records should only contain SOURCE category files
        """
        # Given
        records = [
            FileRecord(
                path="src/test.py",
                name="test.py",
                category=FileCategory.SOURCE,
                lines_of_code=100,
                test_requirement=TestRequirement.REQUIRED,
                tests_exist=False,
                impact_score=5.0,
                imported_by_count=5,
            ),
            FileRecord(
                path="tests/test_test.py",
                name="test_test.py",
                category=FileCategory.TEST,
                lines_of_code=50,
                test_requirement=TestRequirement.NOT_NEEDED,
                tests_exist=False,
                impact_score=1.0,
                imported_by_count=0,
            ),
            FileRecord(
                path="README.md",
                name="README.md",
                category=FileCategory.DOCUMENTATION,
                lines_of_code=20,
                test_requirement=TestRequirement.NOT_NEEDED,
                tests_exist=False,
                impact_score=0.5,
                imported_by_count=0,
            ),
        ]

        # When
        generator = ReportGenerator(summary=sample_summary, records=records)

        # Then
        assert len(generator._source_records) == 1
        assert generator._source_records[0].category == FileCategory.SOURCE


# ===== Test Gap Report Tests =====


class TestTestGapReport:
    """Tests for test_gap_report method."""

    @patch("empathy_os.project_index.reports.datetime")
    def test_basic_test_gap_report_structure(
        self, mock_datetime, report_generator
    ):
        """
        Given a report generator with sample data
        When test_gap_report is called
        Then it should return a properly structured report
        """
        # Given
        fixed_time = datetime(2025, 1, 15, 10, 30, 0)
        mock_datetime.now.return_value = fixed_time

        # When
        report = report_generator.test_gap_report()

        # Then
        assert report["report_type"] == "test_gap"
        assert report["generated_at"] == fixed_time.isoformat()
        assert "summary" in report
        assert "priority_files" in report
        assert "by_directory" in report
        assert "recommendations" in report

    @patch("empathy_os.project_index.reports.datetime")
    def test_test_gap_report_summary_counts(
        self, mock_datetime, report_generator
    ):
        """
        Given files with various test states
        When test_gap_report is called
        Then summary should have correct counts
        """
        # Given
        mock_datetime.now.return_value = datetime(2025, 1, 15, 10, 30, 0)

        # When
        report = report_generator.test_gap_report()
        summary = report["summary"]

        # Then
        # 3 source files need tests (excluding the one with tests and config)
        assert summary["total_files_needing_tests"] == 3
        # 200 + 50 + 300 = 550 LOC untested
        assert summary["total_loc_untested"] == 550
        # Files with impact >= 5.0: processor.py (8.0) and critical.py (9.5)
        assert summary["high_impact_untested"] == 2

    @patch("empathy_os.project_index.reports.datetime")
    def test_priority_files_sorted_by_impact(
        self, mock_datetime, report_generator
    ):
        """
        Given files with different impact scores
        When test_gap_report is called
        Then priority_files should be sorted by impact score descending
        """
        # Given
        mock_datetime.now.return_value = datetime(2025, 1, 15, 10, 30, 0)

        # When
        report = report_generator.test_gap_report()
        priority_files = report["priority_files"]

        # Then
        assert len(priority_files) == 3
        # critical.py (9.5) > processor.py (8.0) > helpers.py (2.0)
        assert priority_files[0]["path"] == "src/empathy_os/core/critical.py"
        assert priority_files[0]["impact_score"] == 9.5
        assert priority_files[1]["path"] == "src/empathy_os/core/processor.py"
        assert priority_files[1]["impact_score"] == 8.0
        assert priority_files[2]["path"] == "src/empathy_os/utils/helpers.py"
        assert priority_files[2]["impact_score"] == 2.0

    @patch("empathy_os.project_index.reports.datetime")
    def test_priority_files_structure(self, mock_datetime, report_generator):
        """
        Given a file needing tests
        When test_gap_report is called
        Then each priority file should have required fields
        """
        # Given
        mock_datetime.now.return_value = datetime(2025, 1, 15, 10, 30, 0)

        # When
        report = report_generator.test_gap_report()
        first_file = report["priority_files"][0]

        # Then
        assert "path" in first_file
        assert "impact_score" in first_file
        assert "lines_of_code" in first_file
        assert "imported_by_count" in first_file
        assert "reason" in first_file
        assert "High impact" in first_file["reason"]
        assert "LOC" in first_file["reason"]

    @patch("empathy_os.project_index.reports.datetime")
    def test_priority_files_limited_to_20(self, mock_datetime, sample_summary):
        """
        Given more than 20 files needing tests
        When test_gap_report is called
        Then priority_files should be limited to top 20
        """
        # Given
        mock_datetime.now.return_value = datetime(2025, 1, 15, 10, 30, 0)
        records = [
            FileRecord(
                path=f"src/file_{i}.py",
                name=f"file_{i}.py",
                category=FileCategory.SOURCE,
                lines_of_code=100,
                test_requirement=TestRequirement.REQUIRED,
                tests_exist=False,
                impact_score=float(i),
                imported_by_count=i,
            )
            for i in range(30)
        ]
        generator = ReportGenerator(summary=sample_summary, records=records)

        # When
        report = generator.test_gap_report()

        # Then
        assert len(report["priority_files"]) == 20
        # Highest impact should be first
        assert report["priority_files"][0]["impact_score"] == 29.0

    @patch("empathy_os.project_index.reports.datetime")
    def test_no_files_needing_tests(self, mock_datetime, sample_summary):
        """
        Given all files either have tests or don't require them
        When test_gap_report is called
        Then report should show zero gaps
        """
        # Given
        mock_datetime.now.return_value = datetime(2025, 1, 15, 10, 30, 0)
        records = [
            FileRecord(
                path="src/tested.py",
                name="tested.py",
                category=FileCategory.SOURCE,
                lines_of_code=100,
                test_requirement=TestRequirement.REQUIRED,
                tests_exist=True,
                impact_score=5.0,
                imported_by_count=5,
            )
        ]
        generator = ReportGenerator(summary=sample_summary, records=records)

        # When
        report = generator.test_gap_report()

        # Then
        assert report["summary"]["total_files_needing_tests"] == 0
        assert report["summary"]["total_loc_untested"] == 0
        assert report["summary"]["high_impact_untested"] == 0
        assert report["priority_files"] == []

    @patch("empathy_os.project_index.reports.datetime")
    def test_optional_test_requirement_excluded(
        self, mock_datetime, sample_summary
    ):
        """
        Given a file with OPTIONAL test requirement
        When test_gap_report is called
        Then it should not be included in needing tests
        """
        # Given
        mock_datetime.now.return_value = datetime(2025, 1, 15, 10, 30, 0)
        records = [
            FileRecord(
                path="src/optional.py",
                name="optional.py",
                category=FileCategory.SOURCE,
                lines_of_code=100,
                test_requirement=TestRequirement.OPTIONAL,
                tests_exist=False,
                impact_score=5.0,
                imported_by_count=5,
            )
        ]
        generator = ReportGenerator(summary=sample_summary, records=records)

        # When
        report = generator.test_gap_report()

        # Then
        assert report["summary"]["total_files_needing_tests"] == 0

    @patch("empathy_os.project_index.reports.datetime")
    def test_not_needed_test_requirement_excluded(
        self, mock_datetime, sample_summary
    ):
        """
        Given a file with NOT_NEEDED test requirement
        When test_gap_report is called
        Then it should not be included in needing tests
        """
        # Given
        mock_datetime.now.return_value = datetime(2025, 1, 15, 10, 30, 0)
        records = [
            FileRecord(
                path="src/script.py",
                name="script.py",
                category=FileCategory.SOURCE,
                lines_of_code=50,
                test_requirement=TestRequirement.NOT_NEEDED,
                tests_exist=False,
                impact_score=1.0,
                imported_by_count=0,
            )
        ]
        generator = ReportGenerator(summary=sample_summary, records=records)

        # When
        report = generator.test_gap_report()

        # Then
        assert report["summary"]["total_files_needing_tests"] == 0


# ===== Test Recommendations Tests =====


class TestTestRecommendations:
    """Tests for _test_recommendations method."""

    def test_high_impact_recommendation(self, report_generator):
        """
        Given files with high impact scores
        When _test_