"""Behavioral tests for orchestrated_health_check.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import Any
from unittest.mock import AsyncMock, MagicMock, Mock, patch

import pytest

from empathy_os.workflows.orchestrated_health_check import (
    CategoryScore,
    HealthCheckReport,
    OrchestratedHealthCheckWorkflow,
    _calculate_grade,
    _calculate_overall_score,
    _extract_category_scores,
    _generate_recommendations,
    _load_historical_trends,
    _save_historical_trends,
)


# Fixtures


@pytest.fixture
def temp_project_root(tmp_path):
    """Given a temporary project root directory."""
    project_root = tmp_path / "test_project"
    project_root.mkdir()
    return project_root


@pytest.fixture
def temp_trends_file(tmp_path):
    """Given a temporary trends file."""
    trends_file = tmp_path / "health_trends.json"
    return trends_file


@pytest.fixture
def sample_strategy_result():
    """Given a sample strategy result with health check data."""
    return StrategyResult(
        success=True,
        outputs={
            "security_agent": {
                "critical_issues": 0,
                "vulnerability_count": 2,
                "security_score": 85,
            },
            "coverage_agent": {"coverage_percentage": 90, "uncovered_files": 5},
            "quality_agent": {"quality_score": 88, "code_smells": 3},
            "performance_agent": {
                "bottleneck_count": 1,
                "avg_response_time": 150,
            },
            "documentation_agent": {"completeness": 75, "missing_docs": 10},
        },
        metrics={
            "execution_time": 15.5,
            "agents_executed": 5,
            "parallel_execution": True,
        },
        metadata={"mode": "weekly", "timestamp": "2025-01-15T10:00:00"},
    )


@pytest.fixture
def sample_category_scores():
    """Given sample category scores."""
    return [
        CategoryScore(
            name="Security",
            score=85.0,
            weight=0.3,
            raw_metrics={"critical_issues": 0, "vulnerability_count": 2},
            issues=["2 medium vulnerabilities found"],
            passed=True,
        ),
        CategoryScore(
            name="Coverage",
            score=90.0,
            weight=0.25,
            raw_metrics={"coverage_percentage": 90},
            issues=[],
            passed=True,
        ),
        CategoryScore(
            name="Quality",
            score=88.0,
            weight=0.2,
            raw_metrics={"quality_score": 88},
            issues=["3 code smells detected"],
            passed=True,
        ),
        CategoryScore(
            name="Performance",
            score=75.0,
            weight=0.15,
            raw_metrics={"bottleneck_count": 1},
            issues=["1 performance bottleneck"],
            passed=True,
        ),
        CategoryScore(
            name="Documentation",
            score=75.0,
            weight=0.1,
            raw_metrics={"completeness": 75},
            issues=["25% documentation missing"],
            passed=True,
        ),
    ]


# CategoryScore Tests


class TestCategoryScore:
    """Tests for CategoryScore dataclass."""

    def test_given_valid_data_when_creating_category_score_then_initializes_correctly(
        self,
    ):
        """Given valid category data, when creating CategoryScore, then it initializes correctly."""
        # When
        score = CategoryScore(
            name="Security",
            score=85.5,
            weight=0.3,
            raw_metrics={"vulnerabilities": 2},
            issues=["Issue 1"],
            passed=True,
        )

        # Then
        assert score.name == "Security"
        assert score.score == 85.5
        assert score.weight == 0.3
        assert score.raw_metrics == {"vulnerabilities": 2}
        assert score.issues == ["Issue 1"]
        assert score.passed is True

    def test_given_minimal_data_when_creating_category_score_then_uses_defaults(self):
        """Given minimal data, when creating CategoryScore, then it uses default values."""
        # When
        score = CategoryScore(name="Quality", score=90.0, weight=0.2)

        # Then
        assert score.raw_metrics == {}
        assert score.issues == []
        assert score.passed is True


# HealthCheckReport Tests


class TestHealthCheckReport:
    """Tests for HealthCheckReport dataclass."""

    def test_given_valid_data_when_creating_report_then_initializes_correctly(
        self, sample_category_scores
    ):
        """Given valid report data, when creating HealthCheckReport, then it initializes correctly."""
        # Given
        timestamp = datetime.now()

        # When
        report = HealthCheckReport(
            overall_health_score=85.5,
            grade="B",
            category_scores=sample_category_scores,
            issues=["Issue 1", "Issue 2"],
            recommendations=["Recommendation 1"],
            trend="improving",
            execution_time=15.5,
            mode="weekly",
            timestamp=timestamp,
            agents_executed=5,
            success=True,
        )

        # Then
        assert report.overall_health_score == 85.5
        assert report.grade == "B"
        assert len(report.category_scores) == 5
        assert len(report.issues) == 2
        assert report.trend == "improving"
        assert report.success is True

    def test_given_minimal_data_when_creating_report_then_uses_defaults(self):
        """Given minimal data, when creating HealthCheckReport, then it uses default values."""
        # When
        report = HealthCheckReport(
            overall_health_score=75.0,
            grade="C",
            category_scores=[],
            execution_time=10.0,
            mode="daily",
        )

        # Then
        assert report.issues == []
        assert report.recommendations == []
        assert report.trend == "stable"
        assert report.agents_executed == 0
        assert report.success is True


# Helper Function Tests


class TestCalculateGrade:
    """Tests for _calculate_grade helper function."""

    def test_given_score_above_90_when_calculating_grade_then_returns_a(self):
        """Given a score above 90, when calculating grade, then it returns 'A'."""
        # When/Then
        assert _calculate_grade(95.0) == "A"
        assert _calculate_grade(90.0) == "A"

    def test_given_score_between_80_and_90_when_calculating_grade_then_returns_b(self):
        """Given a score between 80-90, when calculating grade, then it returns 'B'."""
        # When/Then
        assert _calculate_grade(85.0) == "B"
        assert _calculate_grade(80.0) == "B"

    def test_given_score_between_70_and_80_when_calculating_grade_then_returns_c(self):
        """Given a score between 70-80, when calculating grade, then it returns 'C'."""
        # When/Then
        assert _calculate_grade(75.0) == "C"
        assert _calculate_grade(70.0) == "C"

    def test_given_score_between_60_and_70_when_calculating_grade_then_returns_d(self):
        """Given a score between 60-70, when calculating grade, then it returns 'D'."""
        # When/Then
        assert _calculate_grade(65.0) == "D"
        assert _calculate_grade(60.0) == "D"

    def test_given_score_below_60_when_calculating_grade_then_returns_f(self):
        """Given a score below 60, when calculating grade, then it returns 'F'."""
        # When/Then
        assert _calculate_grade(50.0) == "F"
        assert _calculate_grade(0.0) == "F"


class TestCalculateOverallScore:
    """Tests for _calculate_overall_score helper function."""

    def test_given_category_scores_when_calculating_overall_then_returns_weighted_average(
        self, sample_category_scores
    ):
        """Given category scores, when calculating overall score, then it returns weighted average."""
        # When
        overall = _calculate_overall_score(sample_category_scores)

        # Then
        # Expected: 85*0.3 + 90*0.25 + 88*0.2 + 75*0.15 + 75*0.1 = 84.35
        assert abs(overall - 84.35) < 0.01

    def test_given_empty_scores_when_calculating_overall_then_returns_zero(self):
        """Given empty category scores, when calculating overall score, then it returns 0."""
        # When
        overall = _calculate_overall_score([])

        # Then
        assert overall == 0.0

    def test_given_single_category_when_calculating_overall_then_returns_that_score(
        self,
    ):
        """Given a single category, when calculating overall score, then it returns that score."""
        # Given
        scores = [CategoryScore(name="Test", score=80.0, weight=1.0)]

        # When
        overall = _calculate_overall_score(scores)

        # Then
        assert overall == 80.0


class TestExtractCategoryScores:
    """Tests for _extract_category_scores helper function."""

    def test_given_daily_mode_when_extracting_scores_then_includes_basic_categories(
        self, sample_strategy_result
    ):
        """Given daily mode, when extracting scores, then it includes basic categories."""
        # When
        scores = _extract_category_scores(sample_strategy_result, mode="daily")

        # Then
        score_names = [s.name for s in scores]
        assert "Security" in score_names
        assert "Coverage" in score_names
        assert "Quality" in score_names
        assert len(scores) == 3

    def test_given_weekly_mode_when_extracting_scores_then_includes_all_categories(
        self, sample_strategy_result
    ):
        """Given weekly mode, when extracting scores, then it includes all categories."""
        # When
        scores = _extract_category_scores(sample_strategy_result, mode="weekly")

        # Then
        score_names = [s.name for s in scores]
        assert "Security" in score_names
        assert "Coverage" in score_names
        assert "Quality" in score_names
        assert "Performance" in score_names
        assert "Documentation" in score_names
        assert len(scores) == 5

    def test_given_release_mode_when_extracting_scores_then_includes_all_categories(
        self, sample_strategy_result
    ):
        """Given release mode, when extracting scores, then it includes all categories."""
        # When
        scores = _extract_category_scores(sample_strategy_result, mode="release")

        # Then
        assert len(scores) == 5

    def test_given_security_critical_issues_when_extracting_then_marks_failed(self):
        """Given security critical issues, when extracting scores, then it marks as failed."""
        # Given
        result = StrategyResult(
            success=True,
            outputs={
                "security_agent": {"critical_issues": 3, "vulnerability_count": 5}
            },
            metrics={},
        )

        # When
        scores = _extract_category_scores(result, mode="daily")

        # Then
        security_score = next(s for s in scores if s.name == "Security")
        assert security_score.passed is False
        assert security_score.score < 70

    def test_given_low_coverage_when_extracting_then_reflects_in_score(self):
        """Given low coverage, when extracting scores, then it reflects in the score."""
        # Given
        result = StrategyResult(
            success=True,
            outputs={"coverage_agent": {"coverage_percentage": 45}},
            metrics={},
        )

        # When
        scores = _extract_category_scores(result, mode="daily")

        # Then
        coverage_score = next(s for s in scores if s.name == "Coverage")
        assert coverage_score.score == 45.0
        assert coverage_score.passed is False

    def test_given_missing_agent_output_when_extracting_then_handles_gracefully(self):
        """Given missing agent output, when extracting scores, then it handles gracefully."""
        # Given
        result = StrategyResult(
            success=True, outputs={"security_agent": {"critical_issues": 0}}, metrics={}
        )

        # When
        scores = _extract_category_scores(result, mode="weekly")

        # Then
        # Should still create scores for missing agents with default values
        assert len(scores) == 5


class TestGenerateRecommendations:
    """Tests for _generate_recommendations helper function."""

    def test_given_failing_categories_when_generating_recommendations_then_includes_improvements(
        self,
    ):
        """Given failing categories, when generating recommendations, then it includes improvements."""
        # Given
        scores = [
            CategoryScore(
                name="Security", score=50.0, weight=0.3, passed=False, issues=["Issue"]
            ),
            CategoryScore(
                name="Coverage", score=45.0, weight=0.25, passed=False, issues=[]
            ),
        ]

        # When
        recommendations = _generate_recommendations(scores)

        # Then
        assert len(recommendations) > 0
        assert any("Security" in r for r in recommendations)
        assert any("Coverage" in r or "test coverage" in r for r in recommendations)

    def test_given_all_passing_categories_when_generating_recommendations_then_includes_maintenance(
        self, sample_category_scores
    ):
        """Given all passing categories, when generating recommendations, then it includes maintenance."""
        # When
        recommendations = _generate_recommendations(sample_category_scores)

        # Then
        assert len(recommendations) > 0
        # Should still have some recommendations for continuous improvement

    def test_given_low_documentation_when_generating_recommendations_then_suggests_improvement(
        self,
    ):
        """Given low documentation score, when generating recommendations, then it suggests improvement."""
        # Given
        scores = [
            CategoryScore(
                name="Documentation",
                score=40.0,
                weight=0.1,
                passed=False,
                issues=["60% missing"],
            )
        ]

        # When
        recommendations = _generate_recommendations(scores)

        # Then
        assert any("documentation" in r.lower() for r in recommendations)


class TestHistoricalTrends:
    """Tests for historical trend functions."""

    def test_given_valid_trends_file_when_loading_then_returns_trends(
        self, temp_trends_file
    ):
        """Given a valid trends file, when loading, then it returns trends."""
        # Given
        trends_data = {
            "daily": [{"score": 85.0, "timestamp": "2025-01-15T10:00:00"}],
            "weekly": [],
        }
        temp_trends_file.write_text(json.dumps(trends_data))

        # When
        trends = _load_historical_trends(temp_trends_file)

        # Then
        assert "daily" in trends
        assert len(trends["daily"]) == 1
        assert trends["daily"][0]["score"] == 85.0