"""Behavioral tests for vscode_bridge 2.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import json
from datetime import datetime
from pathlib import Path
from unittest.mock import MagicMock, Mock, mock_open, patch

import pytest

from empathy_os.vscode_bridge_2 import (
    CodeReviewResult,
    ReviewFinding,
    get_empathy_dir,
    write_code_review_results,
)


class TestReviewFinding:
    """Behavioral tests for ReviewFinding dataclass."""

    def test_review_finding_creation_with_required_fields(self):
        """
        Given: Required fields for a ReviewFinding
        When: Creating a ReviewFinding instance
        Then: Instance is created with correct attributes
        """
        # Given
        finding_id = "FIND-001"
        file_path = "src/main.py"
        line_num = 42
        severity = "high"
        category = "security"
        message = "SQL injection vulnerability"

        # When
        finding = ReviewFinding(
            id=finding_id,
            file=file_path,
            line=line_num,
            severity=severity,
            category=category,
            message=message,
        )

        # Then
        assert finding.id == finding_id
        assert finding.file == file_path
        assert finding.line == line_num
        assert finding.severity == severity
        assert finding.category == category
        assert finding.message == message
        assert finding.column == 1  # Default value
        assert finding.details is None
        assert finding.recommendation is None

    def test_review_finding_creation_with_all_fields(self):
        """
        Given: All fields including optional ones for a ReviewFinding
        When: Creating a ReviewFinding instance
        Then: Instance is created with all attributes set correctly
        """
        # Given
        finding_data = {
            "id": "FIND-002",
            "file": "src/auth.py",
            "line": 15,
            "severity": "critical",
            "category": "security",
            "message": "Hardcoded credentials",
            "column": 10,
            "details": "Password found in source code",
            "recommendation": "Use environment variables",
        }

        # When
        finding = ReviewFinding(**finding_data)

        # Then
        assert finding.id == finding_data["id"]
        assert finding.column == 10
        assert finding.details == finding_data["details"]
        assert finding.recommendation == finding_data["recommendation"]

    def test_review_finding_supports_different_severities(self):
        """
        Given: Different severity levels
        When: Creating ReviewFinding instances
        Then: Each instance correctly stores its severity
        """
        # Given
        severities = ["critical", "high", "medium", "low", "info"]

        # When/Then
        for severity in severities:
            finding = ReviewFinding(
                id=f"ID-{severity}",
                file="test.py",
                line=1,
                severity=severity,
                category="correctness",
                message="Test",
            )
            assert finding.severity == severity

    def test_review_finding_supports_different_categories(self):
        """
        Given: Different category types
        When: Creating ReviewFinding instances
        Then: Each instance correctly stores its category
        """
        # Given
        categories = ["security", "performance", "maintainability", "style", "correctness"]

        # When/Then
        for category in categories:
            finding = ReviewFinding(
                id=f"ID-{category}",
                file="test.py",
                line=1,
                severity="medium",
                category=category,
                message="Test",
            )
            assert finding.category == category


class TestCodeReviewResult:
    """Behavioral tests for CodeReviewResult dataclass."""

    def test_code_review_result_creation_with_all_fields(self):
        """
        Given: All required fields for CodeReviewResult
        When: Creating a CodeReviewResult instance
        Then: Instance is created with correct attributes
        """
        # Given
        findings = [{"id": "F1", "message": "Issue"}]
        summary = {"total_findings": 1}
        verdict = "approve_with_suggestions"
        security_score = 85
        formatted_report = "# Report"
        model_tier = "capable"
        timestamp = "2026-01-01T12:00:00"

        # When
        result = CodeReviewResult(
            findings=findings,
            summary=summary,
            verdict=verdict,
            security_score=security_score,
            formatted_report=formatted_report,
            model_tier_used=model_tier,
            timestamp=timestamp,
        )

        # Then
        assert result.findings == findings
        assert result.summary == summary
        assert result.verdict == verdict
        assert result.security_score == security_score
        assert result.formatted_report == formatted_report
        assert result.model_tier_used == model_tier
        assert result.timestamp == timestamp

    def test_code_review_result_supports_different_verdicts(self):
        """
        Given: Different verdict types
        When: Creating CodeReviewResult instances
        Then: Each instance correctly stores its verdict
        """
        # Given
        verdicts = ["approve", "approve_with_suggestions", "request_changes", "reject"]

        # When/Then
        for verdict in verdicts:
            result = CodeReviewResult(
                findings=[],
                summary={},
                verdict=verdict,
                security_score=50,
                formatted_report="",
                model_tier_used="capable",
                timestamp="2026-01-01",
            )
            assert result.verdict == verdict

    def test_code_review_result_supports_security_score_range(self):
        """
        Given: Different security scores
        When: Creating CodeReviewResult instances
        Then: Each instance correctly stores its security score
        """
        # Given
        scores = [0, 25, 50, 75, 100]

        # When/Then
        for score in scores:
            result = CodeReviewResult(
                findings=[],
                summary={},
                verdict="approve",
                security_score=score,
                formatted_report="",
                model_tier_used="capable",
                timestamp="2026-01-01",
            )
            assert result.security_score == score


class TestGetEmpathyDir:
    """Behavioral tests for get_empathy_dir function."""

    @patch("empathy_os.vscode_bridge_2.Path")
    def test_get_empathy_dir_creates_directory_if_not_exists(self, mock_path):
        """
        Given: .empathy directory does not exist
        When: Calling get_empathy_dir
        Then: Directory is created and path is returned
        """
        # Given
        mock_dir = Mock(spec=Path)
        mock_path.return_value = mock_dir

        # When
        result = get_empathy_dir()

        # Then
        mock_path.assert_called_once_with(".empathy")
        mock_dir.mkdir.assert_called_once_with(exist_ok=True)
        assert result == mock_dir

    @patch("empathy_os.vscode_bridge_2.Path")
    def test_get_empathy_dir_returns_existing_directory(self, mock_path):
        """
        Given: .empathy directory already exists
        When: Calling get_empathy_dir
        Then: Existing directory path is returned without error
        """
        # Given
        mock_dir = Mock(spec=Path)
        mock_path.return_value = mock_dir

        # When
        result = get_empathy_dir()

        # Then
        mock_dir.mkdir.assert_called_once_with(exist_ok=True)
        assert result == mock_dir

    @patch("empathy_os.vscode_bridge_2.Path")
    def test_get_empathy_dir_multiple_calls_return_consistent_path(self, mock_path):
        """
        Given: Multiple calls to get_empathy_dir
        When: Function is called multiple times
        Then: Same path structure is returned each time
        """
        # Given
        mock_dir = Mock(spec=Path)
        mock_path.return_value = mock_dir

        # When
        result1 = get_empathy_dir()
        result2 = get_empathy_dir()

        # Then
        assert result1 == result2
        assert mock_path.call_count == 2


class TestWriteCodeReviewResults:
    """Behavioral tests for write_code_review_results function."""

    @patch("empathy_os.vscode_bridge_2.get_empathy_dir")
    @patch("empathy_os.vscode_bridge_2.Path")
    @patch("builtins.open", new_callable=mock_open)
    @patch("empathy_os.vscode_bridge_2.datetime")
    def test_write_code_review_results_with_minimal_parameters(
        self, mock_datetime, mock_file, mock_path_class, mock_get_empathy
    ):
        """
        Given: Minimal parameters for code review results
        When: Calling write_code_review_results
        Then: File is written with default values and structure
        """
        # Given
        mock_empathy_dir = Mock(spec=Path)
        mock_get_empathy.return_value = mock_empathy_dir
        
        mock_output_path = Mock(spec=Path)
        mock_empathy_dir.__truediv__.return_value = mock_output_path
        
        mock_datetime.now.return_value.isoformat.return_value = "2026-01-01T12:00:00"

        # When
        result_path = write_code_review_results()

        # Then
        mock_get_empathy.assert_called_once()
        mock_file.assert_called_once()
        assert result_path == mock_output_path

    @patch("empathy_os.vscode_bridge_2.get_empathy_dir")
    @patch("empathy_os.vscode_bridge_2.Path")
    @patch("builtins.open", new_callable=mock_open)
    @patch("empathy_os.vscode_bridge_2.datetime")
    def test_write_code_review_results_with_findings(
        self, mock_datetime, mock_file, mock_path_class, mock_get_empathy
    ):
        """
        Given: Code review findings to write
        When: Calling write_code_review_results with findings
        Then: Findings are included in the written file
        """
        # Given
        findings = [
            {
                "id": "F1",
                "file": "src/main.py",
                "line": 10,
                "severity": "high",
                "category": "security",
                "message": "SQL injection risk",
            }
        ]
        
        mock_empathy_dir = Mock(spec=Path)
        mock_get_empathy.return_value = mock_empathy_dir
        
        mock_output_path = Mock(spec=Path)
        mock_empathy_dir.__truediv__.return_value = mock_output_path
        
        mock_datetime.now.return_value.isoformat.return_value = "2026-01-01T12:00:00"

        # When
        result_path = write_code_review_results(findings=findings)

        # Then
        mock_file.assert_called_once()
        write_calls = mock_file().write.call_args_list
        assert len(write_calls) > 0
        
        # Verify JSON structure includes findings
        written_content = "".join(call[0][0] for call in write_calls)
        data = json.loads(written_content)
        assert len(data["findings"]) == 1
        assert data["findings"][0]["id"] == "F1"

    @patch("empathy_os.vscode_bridge_2.get_empathy_dir")
    @patch("empathy_os.vscode_bridge_2.Path")
    @patch("builtins.open", new_callable=mock_open)
    @patch("empathy_os.vscode_bridge_2.datetime")
    def test_write_code_review_results_generates_summary_when_not_provided(
        self, mock_datetime, mock_file, mock_path_class, mock_get_empathy
    ):
        """
        Given: Findings without explicit summary
        When: Calling write_code_review_results
        Then: Summary is automatically generated from findings
        """
        # Given
        findings = [
            {
                "id": "F1",
                "file": "src/main.py",
                "line": 10,
                "severity": "high",
                "category": "security",
                "message": "Issue 1",
            },
            {
                "id": "F2",
                "file": "src/auth.py",
                "line": 20,
                "severity": "medium",
                "category": "performance",
                "message": "Issue 2",
            },
        ]
        
        mock_empathy_dir = Mock(spec=Path)
        mock_get_empathy.return_value = mock_empathy_dir
        
        mock_output_path = Mock(spec=Path)
        mock_empathy_dir.__truediv__.return_value = mock_output_path
        
        mock_datetime.now.return_value.isoformat.return_value = "2026-01-01T12:00:00"

        # When
        result_path = write_code_review_results(findings=findings)

        # Then
        written_content = "".join(call[0][0] for call in mock_file().write.call_args_list)
        data = json.loads(written_content)
        
        assert data["summary"]["total_findings"] == 2
        assert data["summary"]["by_severity"]["high"] == 1
        assert data["summary"]["by_severity"]["medium"] == 1
        assert data["summary"]["by_category"]["security"] == 1
        assert data["summary"]["by_category"]["performance"] == 1
        assert len(data["summary"]["files_affected"]) == 2

    @patch("empathy_os.vscode_bridge_2.get_empathy_dir")
    @patch("empathy_os.vscode_bridge_2.Path")
    @patch("builtins.open", new_callable=mock_open)
    @patch("empathy_os.vscode_bridge_2.datetime")
    def test_write_code_review_results_with_custom_summary(
        self, mock_datetime, mock_file, mock_path_class, mock_get_empathy
    ):
        """
        Given: Custom summary provided
        When: Calling write_code_review_results with summary
        Then: Custom summary is used instead of auto-generated
        """
        # Given
        custom_summary = {
            "total_findings": 5,
            "by_severity": {"critical": 2},
            "by_category": {"security": 3},
            "files_affected": ["file1.py", "file2.py"],
        }
        
        mock_empathy_dir = Mock(spec=Path)
        mock_get_empathy.return_value = mock_empathy_dir
        
        mock_output_path = Mock(spec=Path)
        mock_empathy_dir.__truediv__.return_value = mock_output_path
        
        mock_datetime.now.return_value.isoformat.return_value = "2026-01-01T12:00:00"

        # When
        result_path = write_code_review_results(summary=custom_summary)

        # Then
        written_content = "".join(call[0][0] for call in mock_file().write.call_args_list)
        data = json.loads(written_content)
        
        assert data["