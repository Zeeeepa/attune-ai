"""Behavioral tests for hash_only.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import time
from unittest.mock import MagicMock, patch

import pytest

from empathy_os.cache.hash_only import HashOnlyCache
from empathy_os.cache.base import CacheEntry, CacheStats


@pytest.fixture
def cache():
    """Given a fresh HashOnlyCache instance."""
    return HashOnlyCache(max_size_mb=100, default_ttl=3600, max_memory_mb=10)


@pytest.fixture
def mock_time():
    """Given a controllable time source."""
    with patch("time.time") as mock:
        mock.return_value = 1000.0
        yield mock


@pytest.fixture
def sample_prompt():
    """Given a sample prompt text."""
    return "Analyze this code for security vulnerabilities:\ndef foo(): pass"


@pytest.fixture
def sample_response():
    """Given a sample cached response."""
    return {"analysis": "No vulnerabilities found", "confidence": 0.95}


class TestHashOnlyCacheInitialization:
    """Tests for HashOnlyCache initialization."""

    def test_init_with_defaults(self):
        """
        Given: Default initialization parameters
        When: Creating a new HashOnlyCache
        Then: It should initialize with correct default values
        """
        cache = HashOnlyCache()
        
        assert cache.max_size_mb == 500
        assert cache.default_ttl == 86400
        assert cache.max_memory_mb == 100
        assert cache._memory_cache == {}
        assert cache._access_times == {}
        assert isinstance(cache.stats, CacheStats)

    def test_init_with_custom_values(self):
        """
        Given: Custom initialization parameters
        When: Creating a new HashOnlyCache
        Then: It should use the provided values
        """
        cache = HashOnlyCache(max_size_mb=200, default_ttl=1800, max_memory_mb=50)
        
        assert cache.max_size_mb == 200
        assert cache.default_ttl == 1800
        assert cache.max_memory_mb == 50

    def test_init_logging(self, caplog):
        """
        Given: A new cache being initialized
        When: Creating the cache instance
        Then: It should log initialization details
        """
        with caplog.at_level("DEBUG"):
            cache = HashOnlyCache(max_size_mb=100, default_ttl=3600, max_memory_mb=10)
        
        assert "HashOnlyCache initialized" in caplog.text
        assert "max_memory: 10MB" in caplog.text
        assert "max_disk: 100MB" in caplog.text
        assert "ttl: 3600s" in caplog.text


class TestHashOnlyCacheGet:
    """Tests for get() method."""

    def test_get_cache_miss_empty_cache(self, cache, sample_prompt):
        """
        Given: An empty cache
        When: Getting a value that doesn't exist
        Then: It should return None and increment miss counter
        """
        result = cache.get("code-review", "scan", sample_prompt, "claude-3-5-sonnet")
        
        assert result is None
        assert cache.stats.misses == 1
        assert cache.stats.hits == 0

    def test_get_cache_hit(self, cache, sample_prompt, sample_response, mock_time):
        """
        Given: A cache with a stored entry
        When: Getting the same entry before expiration
        Then: It should return the cached value and increment hit counter
        """
        # Store entry
        cache_key = cache._create_cache_key("code-review", "scan", sample_prompt, "claude-3-5-sonnet")
        cache._memory_cache[cache_key] = CacheEntry(
            key=cache_key,
            value=sample_response,
            created_at=1000.0,
            ttl=3600
        )
        cache._access_times[cache_key] = 1000.0
        
        # Get entry
        result = cache.get("code-review", "scan", sample_prompt, "claude-3-5-sonnet")
        
        assert result == sample_response
        assert cache.stats.hits == 1
        assert cache.stats.misses == 0

    def test_get_expired_entry(self, cache, sample_prompt, sample_response, mock_time):
        """
        Given: A cache with an expired entry
        When: Getting the expired entry
        Then: It should return None, increment miss counter, and evict the entry
        """
        # Store entry with past creation time
        cache_key = cache._create_cache_key("code-review", "scan", sample_prompt, "claude-3-5-sonnet")
        cache._memory_cache[cache_key] = CacheEntry(
            key=cache_key,
            value=sample_response,
            created_at=100.0,  # Very old
            ttl=3600
        )
        cache._access_times[cache_key] = 100.0
        
        # Set current time to be well past expiration
        mock_time.return_value = 10000.0
        
        result = cache.get("code-review", "scan", sample_prompt, "claude-3-5-sonnet")
        
        assert result is None
        assert cache.stats.misses == 1
        assert cache.stats.hits == 0
        assert cache_key not in cache._memory_cache
        assert cache_key not in cache._access_times

    def test_get_updates_access_time(self, cache, sample_prompt, sample_response, mock_time):
        """
        Given: A cache with a stored entry
        When: Getting the entry successfully
        Then: It should update the access time for LRU tracking
        """
        cache_key = cache._create_cache_key("code-review", "scan", sample_prompt, "claude-3-5-sonnet")
        cache._memory_cache[cache_key] = CacheEntry(
            key=cache_key,
            value=sample_response,
            created_at=1000.0,
            ttl=3600
        )
        cache._access_times[cache_key] = 1000.0
        
        # Advance time
        mock_time.return_value = 1500.0
        
        cache.get("code-review", "scan", sample_prompt, "claude-3-5-sonnet")
        
        assert cache._access_times[cache_key] == 1500.0

    def test_get_different_workflows(self, cache, sample_prompt, sample_response, mock_time):
        """
        Given: Cache entries for different workflows
        When: Getting entries with different workflow parameters
        Then: Each should be independently cached
        """
        # Store entries for different workflows
        key1 = cache._create_cache_key("code-review", "scan", sample_prompt, "claude-3-5-sonnet")
        key2 = cache._create_cache_key("data-analysis", "scan", sample_prompt, "claude-3-5-sonnet")
        
        cache._memory_cache[key1] = CacheEntry(key1, {"result": "review"}, 1000.0, 3600)
        cache._memory_cache[key2] = CacheEntry(key2, {"result": "analysis"}, 1000.0, 3600)
        cache._access_times[key1] = 1000.0
        cache._access_times[key2] = 1000.0
        
        result1 = cache.get("code-review", "scan", sample_prompt, "claude-3-5-sonnet")
        result2 = cache.get("data-analysis", "scan", sample_prompt, "claude-3-5-sonnet")
        
        assert result1 == {"result": "review"}
        assert result2 == {"result": "analysis"}
        assert key1 != key2

    def test_get_expired_entry_logging(self, cache, sample_prompt, sample_response, mock_time, caplog):
        """
        Given: A cache with an expired entry
        When: Getting the expired entry
        Then: It should log the expiration
        """
        cache_key = cache._create_cache_key("code-review", "scan", sample_prompt, "claude-3-5-sonnet")
        cache._memory_cache[cache_key] = CacheEntry(
            key=cache_key,
            value=sample_response,
            created_at=100.0,
            ttl=3600
        )
        
        mock_time.return_value = 10000.0
        
        with caplog.at_level("DEBUG"):
            cache.get("code-review", "scan", sample_prompt, "claude-3-5-sonnet")
        
        assert "Cache entry expired" in caplog.text


class TestHashOnlyCachePut:
    """Tests for put() method."""

    def test_put_new_entry(self, cache, sample_prompt, sample_response, mock_time):
        """
        Given: An empty cache
        When: Putting a new entry
        Then: It should store the entry in memory with correct metadata
        """
        cache.put("code-review", "scan", sample_prompt, "claude-3-5-sonnet", sample_response)
        
        cache_key = cache._create_cache_key("code-review", "scan", sample_prompt, "claude-3-5-sonnet")
        
        assert cache_key in cache._memory_cache
        entry = cache._memory_cache[cache_key]
        assert entry.value == sample_response
        assert entry.created_at == 1000.0
        assert entry.ttl == 3600
        assert cache._access_times[cache_key] == 1000.0

    def test_put_with_custom_ttl(self, cache, sample_prompt, sample_response, mock_time):
        """
        Given: A cache with default TTL
        When: Putting an entry with custom TTL
        Then: It should use the custom TTL
        """
        cache.put("code-review", "scan", sample_prompt, "claude-3-5-sonnet", sample_response, ttl=7200)
        
        cache_key = cache._create_cache_key("code-review", "scan", sample_prompt, "claude-3-5-sonnet")
        entry = cache._memory_cache[cache_key]
        
        assert entry.ttl == 7200

    def test_put_overwrites_existing(self, cache, sample_prompt, mock_time):
        """
        Given: A cache with an existing entry
        When: Putting a new value with the same key
        Then: It should overwrite the old value
        """
        cache.put("code-review", "scan", sample_prompt, "claude-3-5-sonnet", {"old": "value"})
        cache.put("code-review", "scan", sample_prompt, "claude-3-5-sonnet", {"new": "value"})
        
        cache_key = cache._create_cache_key("code-review", "scan", sample_prompt, "claude-3-5-sonnet")
        entry = cache._memory_cache[cache_key]
        
        assert entry.value == {"new": "value"}

    def test_put_triggers_eviction_on_memory_limit(self, cache, mock_time):
        """
        Given: A cache near its memory limit
        When: Putting a new entry that exceeds the limit
        Then: It should evict old entries using LRU strategy
        """
        # Mock _estimate_size to control memory usage
        with patch.object(cache, "_estimate_size") as mock_size:
            # Each entry is 3MB
            mock_size.return_value = 3 * 1024 * 1024
            
            # Add 3 entries (9MB total, under 10MB limit)
            cache.put("workflow", "stage", "prompt1", "model", {"data": "1"})
            cache.put("workflow", "stage", "prompt2", "model", {"data": "2"})
            
            # Access entry 1 more recently
            mock_time.return_value = 1500.0
            key1 = cache._create_cache_key("workflow", "stage", "prompt1", "model")
            cache._access_times[key1] = 1500.0
            
            # Add 4th entry (would be 12MB, over limit)
            mock_time.return_value = 2000.0
            cache.put("workflow", "stage", "prompt4", "model", {"data": "4"})
            
            # Should evict prompt2 (least recently used)
            key2 = cache._create_cache_key("workflow", "stage", "prompt2", "model")
            assert key2 not in cache._memory_cache

    def test_put_multiple_entries(self, cache, mock_time):
        """
        Given: An empty cache
        When: Putting multiple different entries
        Then: All entries should be stored independently
        """
        cache.put("workflow1", "stage1", "prompt1", "model1", "response1")
        cache.put("workflow2", "stage2", "prompt2", "model2", "response2")
        cache.put("workflow3", "stage3", "prompt3", "model3", "response3")
        
        assert len(cache._memory_cache) == 3
        assert len(cache._access_times) == 3


class TestHashOnlyCacheClear:
    """Tests for clear() method."""

    def test_clear_empty_cache(self, cache):
        """
        Given: An empty cache
        When: Clearing the cache
        Then: It should not raise errors
        """
        cache.clear()
        
        assert len(cache._memory_cache) == 0
        assert len(cache._access_times) == 0

    def test_clear_populated_cache(self, cache, sample_prompt, sample_response, mock_time):
        """
        Given: A cache with multiple entries
        When: Clearing the cache
        Then: It should remove all entries and reset stats
        """
        # Add entries
        cache.put("workflow1", "stage1", sample_prompt, "model1", sample_response)
        cache.put("workflow2", "stage2", sample_prompt, "model2", sample_response)
        cache.stats.hits = 10
        cache.stats.misses = 5
        
        cache.clear()
        
        assert len(cache._memory_cache) == 0
        assert len(cache._access_times) == 0
        assert cache.stats.hits == 0
        assert cache.stats.misses == 0

    def test_clear_logging(self, cache, caplog):
        """
        Given: A cache being cleared
        When: Calling clear()
        Then: It should log the operation
        """
        with caplog.at_level("DEBUG"):
            cache.clear()
        
        assert "Cache cleared" in caplog.text


class TestHashOnlyCacheGetStats:
    """Tests for get_stats() method."""

    def test_get_stats_initial(self, cache):
        """
        Given: A new cache with no operations
        When: Getting stats
        Then: It should return zero values
        """
        stats = cache.get_stats()
        
        assert stats["hits"] == 0
        assert stats["misses"] == 0
        assert stats["total_requests"] == 0
        assert stats["hit_rate"] == 0.0
        assert stats["size_mb"] == 0.0

    def test_get_stats_after_operations(self, cache, sample_prompt, sample_response, mock_time):
        """
        Given: A cache with recorded hits and misses
        When: Getting stats
        Then: It should return accurate statistics
        """
        # Record some hits and misses
        cache.stats.hits = 7
        cache.stats.misses = 3
        
        # Add some entries
        cache.put("