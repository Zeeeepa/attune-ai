"""Behavioral tests for vscode_bridge.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import json
from datetime import datetime
from pathlib import Path
from unittest.mock import MagicMock, mock_open, patch

import pytest

from empathy_os.vscode_bridge import (
    CodeReviewResult,
    ReviewFinding,
    get_empathy_dir,
    write_code_review_results,
)


class TestReviewFinding:
    """Test suite for ReviewFinding dataclass."""

    def test_given_all_required_fields_when_creating_finding_then_instance_created(self):
        """
        Given all required fields for a ReviewFinding
        When creating a new ReviewFinding instance
        Then the instance should be created with correct values
        """
        # Given
        finding_data = {
            "id": "finding-1",
            "file": "src/test.py",
            "line": 42,
            "severity": "high",
            "category": "security",
            "message": "Potential SQL injection",
        }

        # When
        finding = ReviewFinding(**finding_data)

        # Then
        assert finding.id == "finding-1"
        assert finding.file == "src/test.py"
        assert finding.line == 42
        assert finding.severity == "high"
        assert finding.category == "security"
        assert finding.message == "Potential SQL injection"
        assert finding.column == 1  # Default value

    def test_given_optional_fields_when_creating_finding_then_all_fields_set(self):
        """
        Given all required and optional fields
        When creating a ReviewFinding
        Then all fields should be correctly set
        """
        # Given / When
        finding = ReviewFinding(
            id="finding-2",
            file="src/main.py",
            line=100,
            severity="medium",
            category="performance",
            message="Inefficient loop",
            column=5,
            details="This loop can be optimized",
            recommendation="Use list comprehension",
        )

        # Then
        assert finding.column == 5
        assert finding.details == "This loop can be optimized"
        assert finding.recommendation == "Use list comprehension"

    def test_given_finding_when_converting_to_dict_then_all_fields_included(self):
        """
        Given a ReviewFinding instance
        When converting it to a dictionary
        Then all fields should be included
        """
        # Given
        finding = ReviewFinding(
            id="test-1",
            file="test.py",
            line=1,
            severity="low",
            category="style",
            message="Test message",
        )

        # When
        from dataclasses import asdict

        result = asdict(finding)

        # Then
        assert result["id"] == "test-1"
        assert result["file"] == "test.py"
        assert result["line"] == 1
        assert "severity" in result
        assert "message" in result


class TestCodeReviewResult:
    """Test suite for CodeReviewResult dataclass."""

    def test_given_review_data_when_creating_result_then_instance_created(self):
        """
        Given code review data
        When creating a CodeReviewResult
        Then the instance should be created with correct values
        """
        # Given
        findings = [{"id": "1", "message": "test"}]
        summary = {"total_findings": 1}
        timestamp = datetime.now().isoformat()

        # When
        result = CodeReviewResult(
            findings=findings,
            summary=summary,
            verdict="approve",
            security_score=90,
            formatted_report="# Report",
            model_tier_used="capable",
            timestamp=timestamp,
        )

        # Then
        assert result.findings == findings
        assert result.summary == summary
        assert result.verdict == "approve"
        assert result.security_score == 90
        assert result.formatted_report == "# Report"
        assert result.model_tier_used == "capable"
        assert result.timestamp == timestamp

    def test_given_different_verdicts_when_creating_results_then_verdict_stored(self):
        """
        Given different verdict values
        When creating CodeReviewResult instances
        Then each verdict should be correctly stored
        """
        verdicts = ["approve", "approve_with_suggestions", "request_changes", "reject"]

        for verdict in verdicts:
            # When
            result = CodeReviewResult(
                findings=[],
                summary={},
                verdict=verdict,
                security_score=50,
                formatted_report="",
                model_tier_used="cheap",
                timestamp=datetime.now().isoformat(),
            )

            # Then
            assert result.verdict == verdict


class TestGetEmpathyDir:
    """Test suite for get_empathy_dir function."""

    @patch("empathy_os.vscode_bridge.Path")
    def test_given_no_empathy_dir_when_called_then_directory_created(self, mock_path):
        """
        Given no .empathy directory exists
        When get_empathy_dir is called
        Then the directory should be created
        """
        # Given
        mock_empathy_path = MagicMock()
        mock_path.return_value = mock_empathy_path

        # When
        result = get_empathy_dir()

        # Then
        mock_path.assert_called_once_with(".empathy")
        mock_empathy_path.mkdir.assert_called_once_with(exist_ok=True)
        assert result == mock_empathy_path

    @patch("empathy_os.vscode_bridge.Path")
    def test_given_existing_empathy_dir_when_called_then_no_error(self, mock_path):
        """
        Given .empathy directory already exists
        When get_empathy_dir is called
        Then it should not raise an error due to exist_ok=True
        """
        # Given
        mock_empathy_path = MagicMock()
        mock_path.return_value = mock_empathy_path

        # When
        result = get_empathy_dir()

        # Then
        mock_empathy_path.mkdir.assert_called_once_with(exist_ok=True)
        assert result == mock_empathy_path


class TestWriteCodeReviewResults:
    """Test suite for write_code_review_results function."""

    @patch("empathy_os.vscode_bridge.get_empathy_dir")
    @patch("builtins.open", new_callable=mock_open)
    @patch("empathy_os.vscode_bridge.datetime")
    def test_given_no_arguments_when_writing_results_then_defaults_used(
        self, mock_datetime, mock_file, mock_get_dir
    ):
        """
        Given no arguments to write_code_review_results
        When the function is called
        Then default values should be used
        """
        # Given
        mock_dir = MagicMock()
        mock_get_dir.return_value = mock_dir
        mock_datetime.now.return_value.isoformat.return_value = "2026-01-01T00:00:00"

        # When
        result_path = write_code_review_results()

        # Then
        mock_get_dir.assert_called_once()
        mock_file.assert_called_once()
        assert mock_file.call_args[0][1] == "w"

        # Verify JSON content
        written_content = "".join(
            call.args[0] for call in mock_file().write.call_args_list
        )
        data = json.loads(written_content)

        assert data["findings"] == []
        assert data["verdict"] == "approve_with_suggestions"
        assert data["security_score"] == 85
        assert data["model_tier_used"] == "capable"

    @patch("empathy_os.vscode_bridge.get_empathy_dir")
    @patch("builtins.open", new_callable=mock_open)
    @patch("empathy_os.vscode_bridge.datetime")
    def test_given_findings_when_writing_results_then_summary_calculated(
        self, mock_datetime, mock_file, mock_get_dir
    ):
        """
        Given a list of findings without summary
        When writing code review results
        Then summary should be automatically calculated
        """
        # Given
        mock_dir = MagicMock()
        mock_get_dir.return_value = mock_dir
        mock_datetime.now.return_value.isoformat.return_value = "2026-01-01T00:00:00"

        findings = [
            {
                "id": "1",
                "file": "test.py",
                "severity": "high",
                "category": "security",
                "message": "Issue 1",
            },
            {
                "id": "2",
                "file": "test.py",
                "severity": "high",
                "category": "performance",
                "message": "Issue 2",
            },
            {
                "id": "3",
                "file": "main.py",
                "severity": "low",
                "category": "style",
                "message": "Issue 3",
            },
        ]

        # When
        write_code_review_results(findings=findings)

        # Then
        written_content = "".join(
            call.args[0] for call in mock_file().write.call_args_list
        )
        data = json.loads(written_content)

        assert data["summary"]["total_findings"] == 3
        assert data["summary"]["by_severity"]["high"] == 2
        assert data["summary"]["by_severity"]["low"] == 1
        assert data["summary"]["by_category"]["security"] == 1
        assert data["summary"]["by_category"]["performance"] == 1
        assert data["summary"]["by_category"]["style"] == 1
        assert set(data["summary"]["files_affected"]) == {"test.py", "main.py"}

    @patch("empathy_os.vscode_bridge.get_empathy_dir")
    @patch("builtins.open", new_callable=mock_open)
    @patch("empathy_os.vscode_bridge.datetime")
    def test_given_custom_summary_when_writing_results_then_custom_summary_used(
        self, mock_datetime, mock_file, mock_get_dir
    ):
        """
        Given a custom summary is provided
        When writing code review results
        Then the custom summary should be used instead of auto-calculation
        """
        # Given
        mock_dir = MagicMock()
        mock_get_dir.return_value = mock_dir
        mock_datetime.now.return_value.isoformat.return_value = "2026-01-01T00:00:00"

        custom_summary = {
            "total_findings": 5,
            "by_severity": {"critical": 2},
            "by_category": {"security": 5},
            "files_affected": ["custom.py"],
        }

        # When
        write_code_review_results(summary=custom_summary)

        # Then
        written_content = "".join(
            call.args[0] for call in mock_file().write.call_args_list
        )
        data = json.loads(written_content)

        assert data["summary"] == custom_summary

    @patch("empathy_os.vscode_bridge.get_empathy_dir")
    @patch("builtins.open", new_callable=mock_open)
    @patch("empathy_os.vscode_bridge.datetime")
    def test_given_all_parameters_when_writing_results_then_all_included(
        self, mock_datetime, mock_file, mock_get_dir
    ):
        """
        Given all parameters are provided
        When writing code review results
        Then all parameters should be included in the output
        """
        # Given
        mock_dir = MagicMock()
        mock_get_dir.return_value = mock_dir
        mock_datetime.now.return_value.isoformat.return_value = "2026-01-01T12:34:56"

        findings = [{"id": "1", "message": "test"}]
        summary = {"total_findings": 1}
        verdict = "reject"
        security_score = 30
        formatted_report = "# Critical Issues Found"
        model_tier = "premium"

        # When
        write_code_review_results(
            findings=findings,
            summary=summary,
            verdict=verdict,
            security_score=security_score,
            formatted_report=formatted_report,
            model_tier_used=model_tier,
        )

        # Then
        written_content = "".join(
            call.args[0] for call in mock_file().write.call_args_list
        )
        data = json.loads(written_content)

        assert data["findings"] == findings
        assert data["summary"] == summary
        assert data["verdict"] == verdict
        assert data["security_score"] == security_score
        assert data["formatted_report"] == formatted_report
        assert data["model_tier_used"] == model_tier
        assert data["timestamp"] == "2026-01-01T12:34:56"

    @patch("empathy_os.vscode_bridge.get_empathy_dir")
    @patch("builtins.open", new_callable=mock_open)
    @patch("empathy_os.vscode_bridge.datetime")
    def test_given_findings_without_file_when_calculating_summary_then_handled(
        self, mock_datetime, mock_file, mock_get_dir
    ):
        """
        Given findings without file field
        When calculating summary
        Then it should handle missing file field gracefully
        """
        # Given
        mock_dir = MagicMock()
        mock_get_dir.return_value = mock_dir
        mock_datetime.now.return_value.isoformat.return_value = "2026-01-01T00:00:00"

        findings = [
            {"id": "1", "severity": "high", "category": "security", "message": "Test"},
            {"id": "2", "file": None, "severity": "low", "category": "style", "message": "Test2"},
        ]

        # When
        write_code_review_results(findings=findings)

        # Then
        written_content = "".join(
            call.args[0] for call in mock_file().write.call_args_list
        )
        data = json.loads(written_content)

        # Should only count findings with valid file fields
        assert len(data["summary"]["files_affected"]) == 0

    @patch("empathy_os.vscode_bridge.get_empathy_dir")
    @patch("builtins.open", new_callable=mock_open)
    @patch("empathy_os.vscode_bridge.datetime")
    def test_given_findings_without_severity_when_calculating_summary_then_defaults_to_info(
        self, mock_datetime, mock_file, mock_get_dir
    ):
        """
        Given findings without severity field
        When calculating summary
        Then it should default to 'info'
        """
        # Given
        mock_dir = MagicMock()
        mock_get_dir.return_value = mock_dir
        mock_datetime.now.return_value.isoformat.return_value = "2026-01-01T00:00:00"

        findings = [{"id": "1", "category": "style", "message": "Test"}]

        # When
        write_code_review_results(findings=findings)

        # Then
        written_content = "".join(
            call.args[0] for call in mock_file().write.call_args_list
        )
        data = json.loads(written_content)

        assert "info" in data["summary"]["by_severity