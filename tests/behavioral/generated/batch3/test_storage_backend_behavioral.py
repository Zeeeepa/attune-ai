"""Behavioral tests for storage_backend.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import json
from pathlib import Path
from unittest.mock import patch

import pytest

from attune.memory.storage_backend import MemDocsStorage


@pytest.fixture
def temp_storage_dir(tmp_path):
    """Create a temporary storage directory for testing.

    Args:
        tmp_path: pytest temporary directory fixture

    Returns:
        Path to temporary storage directory
    """
    storage_dir = tmp_path / "test_memdocs"
    storage_dir.mkdir(parents=True, exist_ok=True)
    return storage_dir


@pytest.fixture
def storage_backend(temp_storage_dir):
    """Create a MemDocsStorage instance with temporary directory.

    Args:
        temp_storage_dir: Temporary storage directory fixture

    Returns:
        Initialized MemDocsStorage instance
    """
    return MemDocsStorage(storage_dir=str(temp_storage_dir))


@pytest.fixture
def sample_pattern_data():
    """Provide sample pattern data for testing.

    Returns:
        Dictionary with pattern_id, content, and metadata
    """
    return {
        "pattern_id": "test_pattern_123",
        "content": "This is test pattern content",
        "metadata": {
            "classification": "emotional",
            "creator": "user_456",
            "timestamp": "2025-01-15T10:30:00Z",
            "tags": ["test", "sample"],
        },
    }


@pytest.fixture
def encrypted_pattern_data():
    """Provide encrypted pattern data for testing.

    Returns:
        Dictionary with encrypted content
    """
    return {
        "pattern_id": "encrypted_pattern_789",
        "content": "ENCRYPTED:a3f2b9c1d4e5f6g7h8i9j0k1l2m3n4o5",
        "metadata": {
            "classification": "sensitive",
            "creator": "user_789",
            "encrypted": True,
            "encryption_method": "AES-256",
        },
    }


class TestMemDocsStorageInitialization:
    """Test suite for MemDocsStorage initialization."""

    def test_init_creates_storage_directory(self, tmp_path):
        """Given a non-existent storage directory path
        When initializing MemDocsStorage
        Then the directory should be created.
        """
        # Given
        storage_path = tmp_path / "new_storage"
        assert not storage_path.exists()

        # When
        storage = MemDocsStorage(storage_dir=str(storage_path))

        # Then
        assert storage_path.exists()
        assert storage_path.is_dir()
        assert storage.storage_dir == storage_path

    def test_init_with_existing_directory(self, temp_storage_dir):
        """Given an existing storage directory
        When initializing MemDocsStorage
        Then it should use the existing directory without error.
        """
        # Given
        assert temp_storage_dir.exists()

        # When
        storage = MemDocsStorage(storage_dir=str(temp_storage_dir))

        # Then
        assert storage.storage_dir == temp_storage_dir
        assert temp_storage_dir.exists()

    def test_init_with_nested_directory_path(self, tmp_path):
        """Given a nested directory path that doesn't exist
        When initializing MemDocsStorage
        Then all parent directories should be created.
        """
        # Given
        nested_path = tmp_path / "level1" / "level2" / "storage"
        assert not nested_path.exists()

        # When
        storage = MemDocsStorage(storage_dir=str(nested_path))

        # Then
        assert nested_path.exists()
        assert storage.storage_dir == nested_path

    @patch("attune.memory.storage_backend.logger")
    def test_init_logs_initialization(self, mock_logger, temp_storage_dir):
        """Given a storage directory path
        When initializing MemDocsStorage
        Then it should log the initialization event.
        """
        # Given / When
        storage = MemDocsStorage(storage_dir=str(temp_storage_dir))

        # Then
        mock_logger.info.assert_called_once_with(
            "memdocs_storage_initialized", storage_dir=str(temp_storage_dir)
        )

    def test_init_with_default_directory(self):
        """Given no storage directory specified
        When initializing MemDocsStorage
        Then it should use the default directory.
        """
        # Given / When
        with patch("pathlib.Path.mkdir"):
            storage = MemDocsStorage()

        # Then
        assert storage.storage_dir == Path("./memdocs_storage")


class TestMemDocsStorageStore:
    """Test suite for MemDocsStorage.store method."""

    def test_store_pattern_successfully(
        self, storage_backend, sample_pattern_data, temp_storage_dir
    ):
        """Given valid pattern data
        When storing a pattern
        Then the pattern should be saved to a JSON file.
        """
        # Given
        pattern_id = sample_pattern_data["pattern_id"]
        content = sample_pattern_data["content"]
        metadata = sample_pattern_data["metadata"]

        # When
        result = storage_backend.store(pattern_id, content, metadata)

        # Then
        assert result is True
        pattern_file = temp_storage_dir / f"{pattern_id}.json"
        assert pattern_file.exists()

        with open(pattern_file, encoding="utf-8") as f:
            saved_data = json.load(f)
            assert saved_data["pattern_id"] == pattern_id
            assert saved_data["content"] == content
            assert saved_data["metadata"] == metadata

    def test_store_encrypted_pattern(
        self, storage_backend, encrypted_pattern_data, temp_storage_dir
    ):
        """Given encrypted pattern data
        When storing the pattern
        Then the encrypted content should be preserved.
        """
        # Given
        pattern_id = encrypted_pattern_data["pattern_id"]
        content = encrypted_pattern_data["content"]
        metadata = encrypted_pattern_data["metadata"]

        # When
        result = storage_backend.store(pattern_id, content, metadata)

        # Then
        assert result is True
        pattern_file = temp_storage_dir / f"{pattern_id}.json"

        with open(pattern_file, encoding="utf-8") as f:
            saved_data = json.load(f)
            assert saved_data["content"].startswith("ENCRYPTED:")
            assert saved_data["metadata"]["encrypted"] is True

    def test_store_pattern_with_special_characters(self, storage_backend, temp_storage_dir):
        """Given a pattern with special characters in content
        When storing the pattern
        Then it should handle special characters correctly.
        """
        # Given
        pattern_id = "special_chars_pattern"
        content = "Content with Ã¼Ã±Ã­Ã§Ã¶dÃ© and ç‰¹æ®Šå­—ç¬¦ and Ã©mojis ğŸ‰"
        metadata = {"type": "unicode_test"}

        # When
        result = storage_backend.store(pattern_id, content, metadata)

        # Then
        assert result is True
        pattern_file = temp_storage_dir / f"{pattern_id}.json"

        with open(pattern_file, encoding="utf-8") as f:
            saved_data = json.load(f)
            assert saved_data["content"] == content

    def test_store_pattern_overwrites_existing(self, storage_backend, temp_storage_dir):
        """Given an existing pattern file
        When storing a pattern with the same ID
        Then it should overwrite the existing file.
        """
        # Given
        pattern_id = "overwrite_test"
        original_content = "Original content"
        new_content = "Updated content"
        metadata = {"version": 1}

        storage_backend.store(pattern_id, original_content, metadata)

        # When
        metadata["version"] = 2
        result = storage_backend.store(pattern_id, new_content, metadata)

        # Then
        assert result is True
        pattern_file = temp_storage_dir / f"{pattern_id}.json"

        with open(pattern_file, encoding="utf-8") as f:
            saved_data = json.load(f)
            assert saved_data["content"] == new_content
            assert saved_data["metadata"]["version"] == 2

    def test_store_creates_parent_directory(self, temp_storage_dir):
        """Given a storage directory that doesn't exist yet
        When storing a pattern
        Then it should create the parent directory.
        """
        # Given
        non_existent_dir = temp_storage_dir / "subdir"
        storage = MemDocsStorage(storage_dir=str(non_existent_dir))
        pattern_id = "test_pattern"

        # When
        result = storage.store(pattern_id, "content", {"key": "value"})

        # Then
        assert result is True
        assert non_existent_dir.exists()

    @patch("attune.memory.storage_backend._validate_file_path")
    def test_store_validates_file_path(self, mock_validate, storage_backend):
        """Given a pattern to store
        When storing the pattern
        Then it should validate the file path for security.
        """
        # Given
        pattern_id = "validate_test"
        expected_path = storage_backend.storage_dir / f"{pattern_id}.json"
        mock_validate.return_value = str(expected_path)

        # When
        storage_backend.store(pattern_id, "content", {})

        # Then
        mock_validate.assert_called_once_with(str(expected_path))

    @patch("attune.memory.storage_backend.logger")
    def test_store_logs_success(self, mock_logger, storage_backend):
        """Given a successful pattern storage
        When storing a pattern
        Then it should log the success event.
        """
        # Given / When
        storage_backend.store("test_id", "content", {})

        # Then
        mock_logger.debug.assert_called_with("pattern_stored", pattern_id="test_id")

    @patch("builtins.open", side_effect=OSError("Disk full"))
    def test_store_raises_on_os_error(self, mock_file, storage_backend):
        """Given a file system error
        When attempting to store a pattern
        Then it should raise an IOError.
        """
        # Given / When / Then
        with pytest.raises(OSError, match="Disk full"):
            storage_backend.store("test_id", "content", {})

    @patch("builtins.open", side_effect=PermissionError("Access denied"))
    def test_store_raises_on_permission_error(self, mock_file, storage_backend):
        """Given insufficient permissions
        When attempting to store a pattern
        Then it should raise a PermissionError.
        """
        # Given / When / Then
        with pytest.raises(PermissionError, match="Access denied"):
            storage_backend.store("test_id", "content", {})

    @patch("attune.memory.storage_backend.logger")
    @patch("builtins.open", side_effect=OSError("Write failed"))
    def test_store_logs_error_on_failure(self, mock_file, mock_logger, storage_backend):
        """Given a storage failure
        When attempting to store a pattern
        Then it should log the error.
        """
        # Given / When
        with pytest.raises(OSError):
            storage_backend.store("test_id", "content", {})

        # Then
        mock_logger.error.assert_called_once()
        call_args = mock_logger.error.call_args
        assert call_args[1]["pattern_id"] == "test_id"
        assert "error" in call_args[1]

    def test_store_with_empty_metadata(self, storage_backend, temp_storage_dir):
        """Given empty metadata
        When storing a pattern
        Then it should store successfully with empty metadata dict.
        """
        # Given
        pattern_id = "empty_metadata"
        content = "Content with no metadata"
        metadata = {}

        # When
        result = storage_backend.store(pattern_id, content, metadata)

        # Then
        assert result is True
        pattern_file = temp_storage_dir / f"{pattern_id}.json"

        with open(pattern_file, encoding="utf-8") as f:
            saved_data = json.load(f)
            assert saved_data["metadata"] == {}

    def test_store_with_complex_metadata(self, storage_backend, temp_storage_dir):
        """Given complex nested metadata
        When storing a pattern
        Then it should handle nested structures correctly.
        """
        # Given
        pattern_id = "complex_metadata"
        content = "Content"
        metadata = {
            "nested": {"level1": {"level2": ["item1", "item2"]}},
            "list": [1, 2, 3],
            "boolean": True,
            "null": None,
        }

        # When
        result = storage_backend.store(pattern_id, content, metadata)

        # Then
        assert result is True
        pattern_file = temp_storage_dir / f"{pattern_id}.json"

        with open(pattern_file, encoding="utf-8") as f:
            saved_data = json.load(f)
            assert saved_data["metadata"]["nested"]["level1"]["level2"] == ["item1", "item2"]
            assert saved_data["metadata"]["null"] is None


class TestMemDocsStorageRetrieve:
    """Test suite for MemDocsStorage.retrieve method."""

    def test_retrieve_existing_pattern(self, storage_backend, sample_pattern_data):
        """Given a stored pattern
        When retrieving the pattern by ID
        Then it should return the complete pattern data.
        """
        # Given
        pattern_id = sample_pattern_data["pattern_id"]
        storage_backend.store(
            pattern_id, sample_pattern_data["content"], sample_pattern_data["metadata"]
        )

        # When
        result = storage_backend.retrieve(pattern_id)

        # Then
        assert result is not None
        assert result["pattern_id"] == pattern_id
        assert result["content"] == sample_pattern_data["content"]
        assert result["metadata"] == sample_pattern_data["metadata"]

    def test_retrieve_non_existent_pattern(self, storage_backend):
        """Given a pattern ID that doesn't exist
        When retrieving the pattern
        Then it should return None.
        """
        # Given
        non_existent_id = "does_not_exist_123"

        # When
        result = storage_backend.retrieve(non_existent_id)

        # Then
        assert result is None

    def test_retrieve_encrypted_pattern(self, storage_backend, encrypted_pattern_data):
        """Given an encrypted stored pattern
        When retrieving the pattern
        Then it should return the encrypted content as-is.
        """
        # Given
        pattern_id = encrypted_pattern_data["pattern_id"]
        storage_backend.store(
            pattern_id, encrypted_pattern_data["content"], encrypted_pattern_data["metadata"]
        )

        # When
        result = storage_backend.retrieve(pattern_id)

        # Then
        assert result is not None
        assert result["content"].startswith("ENCRYPTED:")
        assert result["metadata"]["encrypted"] is True

    @patch("attune.memory.storage_backend.logger")
    def test_retrieve_logs_warning_for_missing_pattern(self, mock_logger, storage_backend):
        """Given a non-existent pattern ID
        When retrieving the pattern
        Then it should log a warning.
        """
        # Given
        missing_id = "missing_pattern"

        # When
        result = storage_backend.retrieve(missing_id)

        # Then
        assert result is None
        mock_logger.warning.assert_called_once_with("pattern_not_found", pattern_id=missing_id)

    def test_retrieve_handles_special_characters(self, storage_backend):
        """Given a pattern with special characters
        When retrieving the pattern
        Then it should preserve special characters.
        """
        # Given
        pattern_id = "unicode_pattern"
        content = "Special: Ã¼Ã±Ã­Ã§Ã¶dÃ© ç‰¹æ®Š ğŸ‰"
        metadata = {"type": "unicode"}
        storage_backend.store(pattern_id, content, metadata)

        # When
        result = storage_backend.retrieve(pattern_id)

        # Then
        assert result is not None
        assert result["content"] == content

    @patch("builtins.open", side_effect=OSError("Read error"))
    @patch("attune.memory.storage_backend.logger")
    def test_retrieve_logs_error_on_read_failure(self, mock_logger, mock_file, storage_backend):
        """Given a file read error
        When retrieving a pattern
        Then it should log the error and return None.
        """
        # Given
        pattern_id = "error_pattern"
        # Create file to pass exists check
        pattern_file = storage_backend.storage_dir / f"{pattern_id}.json"
        pattern_file.touch()

        # When
        result = storage_backend.retrieve(pattern_id)

        # Then
        assert result is None
        mock_logger.error.assert_called_once()

    def test_retrieve_multiple_patterns_sequentially(self, storage_backend):
        """Given multiple stored patterns
        When retrieving them sequentially
        Then each should return correct data.
        """
        # Given
        patterns = [
            ("pattern1", "content1", {"key": "value1"}),
            ("pattern2", "content2", {"key": "value2"}),
            ("pattern3", "content3", {"key": "value3"}),
        ]

        for pid, content, metadata in patterns:
            storage_backend.store(pid, content, metadata)

        # When / Then
        for pid, content, metadata in patterns:
            result = storage_backend.retrieve(pid)
            assert result["pattern_id"] == pid
            assert result["content"] == content
            assert result["metadata"] == metadata

    @patch("builtins.open", side_effect=json.JSONDecodeError("Invalid JSON", "", 0))
    @patch("attune.memory.storage_backend.logger")
    def test_retrieve_handles_corrupted_json(self, mock_logger, mock_file, storage_backend):
        """Given a corrupted JSON file
        When retrieving the pattern
        Then it should log the error and return None.
        """
        # Given
        pattern_id = "corrupted_pattern"
        pattern_file = storage_backend.storage_dir / f"{pattern_id}.json"
        pattern_file.touch()

        # When
        result = storage_backend.retrieve(pattern_id)

        # Then
        assert result is None
        mock_logger.error.assert_called_once()

    def test_retrieve_with_empty_content(self, storage_backend):
        """Given a pattern with empty content
        When retrieving the pattern
        Then it should return the pattern with empty content.
        """
        # Given
        pattern_id = "empty_content"
        storage_backend.store(pattern_id, "", {"key": "value"})

        # When
        result = storage_backend.retrieve(pattern_id)

        # Then
        assert result is not None
        assert result["content"] == ""
        assert result["metadata"]["key"] == "value"


class TestMemDocsStorageIntegration:
    """Integration tests for MemDocsStorage."""

    def test_store_and_retrieve_cycle(self, storage_backend):
        """Given a complete store and retrieve cycle
        When storing then retrieving a pattern
        Then the retrieved data should match the stored data.
        """
        # Given
        pattern_id = "cycle_test"
        content = "Test content for cycle"
        metadata = {
            "classification": "test",
            "creator": "integration_test",
            "timestamp": "2025-01-15T12:00:00Z",
        }

        # When
        store_result = storage_backend.store(pattern_id, content, metadata)
        retrieve_result = storage_backend.retrieve(pattern_id)

        # Then
        assert store_result is True
        assert retrieve_result is not None
        assert retrieve_result["pattern_id"] == pattern_id
        assert retrieve_result["content"] == content
        assert retrieve_result["metadata"] == metadata

    def test_multiple_instances_share_storage(self, temp_storage_dir):
        """Given multiple storage backend instances
        When using the same storage directory
        Then they should share the same stored patterns.
        """
        # Given
        storage1 = MemDocsStorage(storage_dir=str(temp_storage_dir))
        storage2 = MemDocsStorage(storage_dir=str(temp_storage_dir))

        pattern_id = "shared_pattern"
        content = "Shared content"
        metadata = {"shared": True}

        # When
        storage1.store(pattern_id, content, metadata)
        result = storage2.retrieve(pattern_id)

        # Then
        assert result is not None
        assert result["content"] == content
        assert result["metadata"]["shared"] is True

    def test_storage_persistence_across_instances(self, temp_storage_dir):
        """Given a pattern stored by one instance
        When creating a new instance
        Then it should be able to retrieve the stored pattern.
        """
        # Given
        storage1 = MemDocsStorage(storage_dir=str(temp_storage_dir))
        pattern_id = "persistent_pattern"
        storage1.store(pattern_id, "persistent content", {"persistent": True})

        # When
        storage2 = MemDocsStorage(storage_dir=str(temp_storage_dir))
        result = storage2.retrieve(pattern_id)

        # Then
        assert result is not None
        assert result["content"] == "persistent content"

    def test_large_pattern_storage(self, storage_backend):
        """Given a large pattern with substantial content
        When storing and retrieving the pattern
        Then it should handle large data correctly.
        """
        # Given
        pattern_id = "large_pattern"
        large_content = "x" * 1000000  # 1MB of data
        metadata = {"size": "large", "bytes": len(large_content)}

        # When
        store_result = storage_backend.store(pattern_id, large_content, metadata)
        retrieve_result = storage_backend.retrieve(pattern_id)

        # Then
        assert store_result is True
        assert retrieve_result is not None
        assert len(retrieve_result["content"]) == 1000000

    def test_concurrent_pattern_ids(self, storage_backend):
        """Given patterns with similar IDs
        When storing multiple patterns
        Then each should be stored and retrieved independently.
        """
        # Given
        patterns = {
            "pattern_1": "content_1",
            "pattern_2": "content_2",
            "pattern_11": "content_11",
            "pattern_21": "content_21",
        }

        # When
        for pid, content in patterns.items():
            storage_backend.store(pid, content, {"id": pid})

        # Then
        for pid, expected_content in patterns.items():
            result = storage_backend.retrieve(pid)
            assert result is not None
            assert result["content"] == expected_content


class TestMemDocsStorageEdgeCases:
    """Test edge cases and boundary conditions."""

    def test_pattern_id_with_special_characters(self, storage_backend):
        """Given a pattern ID with special but valid filename characters
        When storing and retrieving
        Then it should handle the ID correctly.
        """
        # Given
        pattern_id = "pattern_with-dashes_and_underscores.123"
        content = "Special ID content"

        # When
        storage_backend.store(pattern_id, content, {})
        result = storage_backend.retrieve(pattern_id)

        # Then
        assert result is not None
        assert result["pattern_id"] == pattern_id

    def test_empty_pattern_id(self, storage_backend):
        """Given an empty pattern ID
        When storing a pattern
        Then it should handle or reject appropriately.
        """
        # Given
        pattern_id = ""
        content = "Content with empty ID"

        # When / Then
        # This should either work or raise an appropriate error
        # Testing current behavior
        result = storage_backend.store(pattern_id, content, {})
        assert isinstance(result, bool)

    def test_very_long_pattern_id(self, storage_backend):
        """Given a very long pattern ID
        When storing a pattern
        Then it should handle long IDs (within filesystem limits).
        """
        # Given
        pattern_id = "pattern_" + "x" * 200  # Long but reasonable ID
        content = "Content with long ID"

        # When
        store_result = storage_backend.store(pattern_id, content, {})
        retrieve_result = storage_backend.retrieve(pattern_id)

        # Then
        assert store_result is True
        assert retrieve_result is not None

    def test_metadata_with_non_serializable_values(self, storage_backend):
        """Given metadata containing values that aren't JSON serializable
        When storing a pattern
        Then it should raise an appropriate error.
        """
        # Given
        pattern_id = "non_serializable"
        content = "Content"
        metadata = {"function": lambda x: x}  # Not JSON serializable

        # When / Then
        with pytest.raises(TypeError):
            storage_backend.store(pattern_id, content, metadata)

    def test_retrieve_from_empty_storage(self, storage_backend):
        """Given a freshly initialized storage with no patterns
        When retrieving any pattern
        Then it should return None.
        """
        # Given / When
        result = storage_backend.retrieve("any_pattern_id")

        # Then
        assert result is None

    def test_storage_directory_as_relative_path(self, tmp_path):
        """Given a relative path for storage directory
        When initializing storage
        Then it should create the directory relative to current location.
        """
        # Given
        import os

        original_cwd = os.getcwd()
        os.chdir(tmp_path)

        try:
            # When
            storage = MemDocsStorage(storage_dir="./relative_storage")

            # Then
            assert storage.storage_dir.exists()
            assert storage.storage_dir.name == "relative_storage"
        finally:
            os.chdir(original_cwd)

    def test_pattern_overwrite_changes_file_size(self, storage_backend, temp_storage_dir):
        """Given an existing pattern
        When overwriting with different sized content
        Then the file size should change accordingly.
        """
        # Given
        pattern_id = "size_change"
        small_content = "small"
        large_content = "large" * 1000

        storage_backend.store(pattern_id, small_content, {})
        pattern_file = temp_storage_dir / f"{pattern_id}.json"
        small_size = pattern_file.stat().st_size

        # When
        storage_backend.store(pattern_id, large_content, {})
        large_size = pattern_file.stat().st_size

        # Then
        assert large_size > small_size

    def test_metadata_with_all_json_types(self, storage_backend):
        """Given metadata with all valid JSON types
        When storing and retrieving
        Then all types should be preserved correctly.
        """
        # Given
        pattern_id = "all_types"
        metadata = {
            "string": "text",
            "number": 42,
            "float": 3.14,
            "boolean": True,
            "null": None,
            "array": [1, 2, 3],
            "object": {"nested": "value"},
        }

        # When
        storage_backend.store(pattern_id, "content", metadata)
        result = storage_backend.retrieve(pattern_id)

        # Then
        assert result["metadata"]["string"] == "text"
        assert result["metadata"]["number"] == 42
        assert result["metadata"]["float"] == 3.14
        assert result["metadata"]["boolean"] is True
        assert result["metadata"]["null"] is None
        assert result["metadata"]["array"] == [1, 2, 3]
        assert result["metadata"]["object"]["nested"] == "value"
