"""Behavioral tests for new_sample_workflow1.

Generated by enhanced autonomous test generation system.

Copyright 2026 Smart-AI-Memory
Licensed under Apache 2.0
"""

import pytest
from unittest.mock import AsyncMock, Mock, patch
from typing import Any

from empathy_os.workflows.new_sample_workflow1 import NewSampleWorkflow1Workflow
from empathy_os.workflows.base import ModelTier


class MockExecutorResult:
    """Mock result from executor."""

    def __init__(self, content: Any, input_tokens: int = 100, output_tokens: int = 50):
        self.content = content
        self.input_tokens = input_tokens
        self.output_tokens = output_tokens


@pytest.fixture
def mock_executor():
    """Create a mock executor for testing."""
    executor = AsyncMock()
    executor.run = AsyncMock()
    return executor


@pytest.fixture
def workflow_instance():
    """Create a workflow instance for testing."""
    return NewSampleWorkflow1Workflow()


@pytest.fixture
def workflow_with_executor(mock_executor):
    """Create a workflow instance with mock executor."""
    workflow = NewSampleWorkflow1Workflow()
    workflow._executor = mock_executor
    return workflow


class TestNewSampleWorkflow1WorkflowInitialization:
    """Test workflow initialization and configuration."""

    def test_given_no_args_when_initialized_then_workflow_created_with_defaults(self):
        """Test that workflow can be initialized without arguments."""
        # Given: No arguments
        # When: Initializing workflow
        workflow = NewSampleWorkflow1Workflow()

        # Then: Workflow is created with correct attributes
        assert workflow.name == "new-sample-workflow1"
        assert workflow.description == "A team leader that has 10 years of experiance coding."
        assert workflow.stages == ["analyze", "process", "report"]

    def test_given_kwargs_when_initialized_then_kwargs_passed_to_base(self):
        """Test that additional kwargs are passed to BaseWorkflow."""
        # Given: Additional keyword arguments
        custom_arg = "test_value"

        # When: Initializing with kwargs
        workflow = NewSampleWorkflow1Workflow(custom_arg=custom_arg)

        # Then: Workflow is created successfully
        assert workflow is not None
        assert isinstance(workflow, NewSampleWorkflow1Workflow)

    def test_given_workflow_when_checking_tier_map_then_correct_tiers_assigned(self):
        """Test that tier map assigns correct model tiers to stages."""
        # Given: A workflow instance
        workflow = NewSampleWorkflow1Workflow()

        # When: Checking tier map
        tier_map = workflow.tier_map

        # Then: All stages have correct tier assignments
        assert tier_map["analyze"] == ModelTier.CHEAP
        assert tier_map["process"] == ModelTier.CAPABLE
        assert tier_map["report"] == ModelTier.PREMIUM


class TestRunStage:
    """Test run_stage routing functionality."""

    @pytest.mark.asyncio
    async def test_given_analyze_stage_when_run_stage_then_analyze_method_called(
        self, workflow_instance
    ):
        """Test that run_stage routes to _analyze for analyze stage."""
        # Given: An analyze stage name and input data
        stage_name = "analyze"
        tier = ModelTier.CHEAP
        input_data = {"test": "data"}

        # When: Running the stage
        with patch.object(
            workflow_instance, "_analyze", new_callable=AsyncMock
        ) as mock_analyze:
            mock_analyze.return_value = ("result", 10, 5)
            result, input_tokens, output_tokens = await workflow_instance.run_stage(
                stage_name, tier, input_data
            )

            # Then: Analyze method is called with correct parameters
            mock_analyze.assert_called_once_with(input_data, tier)
            assert result == "result"
            assert input_tokens == 10
            assert output_tokens == 5

    @pytest.mark.asyncio
    async def test_given_process_stage_when_run_stage_then_process_method_called(
        self, workflow_instance
    ):
        """Test that run_stage routes to _process for process stage."""
        # Given: A process stage name and input data
        stage_name = "process"
        tier = ModelTier.CAPABLE
        input_data = {"test": "data"}

        # When: Running the stage
        with patch.object(
            workflow_instance, "_process", new_callable=AsyncMock
        ) as mock_process:
            mock_process.return_value = ("result", 20, 10)
            result, input_tokens, output_tokens = await workflow_instance.run_stage(
                stage_name, tier, input_data
            )

            # Then: Process method is called with correct parameters
            mock_process.assert_called_once_with(input_data, tier)
            assert result == "result"
            assert input_tokens == 20
            assert output_tokens == 10

    @pytest.mark.asyncio
    async def test_given_report_stage_when_run_stage_then_report_method_called(
        self, workflow_instance
    ):
        """Test that run_stage routes to _report for report stage."""
        # Given: A report stage name and input data
        stage_name = "report"
        tier = ModelTier.PREMIUM
        input_data = {"test": "data"}

        # When: Running the stage
        with patch.object(
            workflow_instance, "_report", new_callable=AsyncMock
        ) as mock_report:
            mock_report.return_value = ("result", 30, 15)
            result, input_tokens, output_tokens = await workflow_instance.run_stage(
                stage_name, tier, input_data
            )

            # Then: Report method is called with correct parameters
            mock_report.assert_called_once_with(input_data, tier)
            assert result == "result"
            assert input_tokens == 30
            assert output_tokens == 15

    @pytest.mark.asyncio
    async def test_given_invalid_stage_when_run_stage_then_value_error_raised(
        self, workflow_instance
    ):
        """Test that run_stage raises ValueError for unknown stage."""
        # Given: An invalid stage name
        stage_name = "invalid_stage"
        tier = ModelTier.CHEAP
        input_data = {"test": "data"}

        # When/Then: Running the stage raises ValueError
        with pytest.raises(ValueError, match="Unknown stage: invalid_stage"):
            await workflow_instance.run_stage(stage_name, tier, input_data)


class TestAnalyzeStage:
    """Test _analyze stage implementation."""

    @pytest.mark.asyncio
    async def test_given_input_data_when_analyze_without_executor_then_default_result_returned(
        self, workflow_instance
    ):
        """Test analyze stage without executor returns default result."""
        # Given: Input data and no executor
        input_data = {"key": "value"}
        tier = ModelTier.CHEAP

        # When: Running analyze stage
        result, input_tokens, output_tokens = await workflow_instance._analyze(
            input_data, tier
        )

        # Then: Default result is returned with zero tokens
        assert result == {"stage": "analyze", "input": input_data}
        assert input_tokens == 0
        assert output_tokens == 0

    @pytest.mark.asyncio
    async def test_given_input_data_when_analyze_with_executor_then_executor_called(
        self, workflow_with_executor, mock_executor
    ):
        """Test analyze stage with executor calls executor.run."""
        # Given: Input data and mock executor
        input_data = {"key": "value"}
        tier = ModelTier.CHEAP
        expected_result = "analyzed data"
        mock_executor.run.return_value = MockExecutorResult(
            expected_result, 100, 50
        )

        # When: Running analyze stage
        result, input_tokens, output_tokens = await workflow_with_executor._analyze(
            input_data, tier
        )

        # Then: Executor is called with correct parameters
        mock_executor.run.assert_called_once()
        call_kwargs = mock_executor.run.call_args[1]
        assert call_kwargs["task_type"] == "workflow_stage"
        assert f"analyze stage: {input_data}" in call_kwargs["prompt"]
        assert result == expected_result
        assert input_tokens == 100
        assert output_tokens == 50

    @pytest.mark.asyncio
    async def test_given_tier_with_to_unified_when_analyze_then_tier_converted(
        self, workflow_with_executor, mock_executor
    ):
        """Test analyze stage converts tier using to_unified if available."""
        # Given: A tier with to_unified method
        tier = Mock(spec=ModelTier)
        tier.to_unified = Mock(return_value="unified_tier")
        input_data = {"key": "value"}
        mock_executor.run.return_value = MockExecutorResult("result", 10, 5)

        # When: Running analyze stage
        await workflow_with_executor._analyze(input_data, tier)

        # Then: to_unified is called
        tier.to_unified.assert_called_once()
        call_kwargs = mock_executor.run.call_args[1]
        assert call_kwargs["tier"] == "unified_tier"

    @pytest.mark.asyncio
    async def test_given_complex_input_when_analyze_then_input_included_in_prompt(
        self, workflow_with_executor, mock_executor
    ):
        """Test analyze stage includes complex input in prompt."""
        # Given: Complex input data
        input_data = {
            "nested": {"data": [1, 2, 3]},
            "text": "test string",
            "number": 42,
        }
        tier = ModelTier.CHEAP
        mock_executor.run.return_value = MockExecutorResult("result", 10, 5)

        # When: Running analyze stage
        await workflow_with_executor._analyze(input_data, tier)

        # Then: Prompt includes input data
        call_kwargs = mock_executor.run.call_args[1]
        assert str(input_data) in call_kwargs["prompt"]


class TestProcessStage:
    """Test _process stage implementation."""

    @pytest.mark.asyncio
    async def test_given_input_data_when_process_without_executor_then_default_result_returned(
        self, workflow_instance
    ):
        """Test process stage without executor returns default result."""
        # Given: Input data and no executor
        input_data = {"key": "value"}
        tier = ModelTier.CAPABLE

        # When: Running process stage
        result, input_tokens, output_tokens = await workflow_instance._process(
            input_data, tier
        )

        # Then: Default result is returned with zero tokens
        assert result == {"stage": "process", "input": input_data}
        assert input_tokens == 0
        assert output_tokens == 0

    @pytest.mark.asyncio
    async def test_given_input_data_when_process_with_executor_then_executor_called(
        self, workflow_with_executor, mock_executor
    ):
        """Test process stage with executor calls executor.run."""
        # Given: Input data and mock executor
        input_data = {"analyzed": "data"}
        tier = ModelTier.CAPABLE
        expected_result = "processed data"
        mock_executor.run.return_value = MockExecutorResult(
            expected_result, 200, 100
        )

        # When: Running process stage
        result, input_tokens, output_tokens = await workflow_with_executor._process(
            input_data, tier
        )

        # Then: Executor is called with correct parameters
        mock_executor.run.assert_called_once()
        call_kwargs = mock_executor.run.call_args[1]
        assert call_kwargs["task_type"] == "workflow_stage"
        assert f"process stage: {input_data}" in call_kwargs["prompt"]
        assert result == expected_result
        assert input_tokens == 200
        assert output_tokens == 100

    @pytest.mark.asyncio
    async def test_given_empty_input_when_process_then_handles_gracefully(
        self, workflow_instance
    ):
        """Test process stage handles empty input."""
        # Given: Empty input data
        input_data = {}
        tier = ModelTier.CAPABLE

        # When: Running process stage
        result, input_tokens, output_tokens = await workflow_instance._process(
            input_data, tier
        )

        # Then: Returns valid result
        assert result == {"stage": "process", "input": input_data}
        assert input_tokens == 0
        assert output_tokens == 0

    @pytest.mark.asyncio
    async def test_given_none_input_when_process_then_handles_gracefully(
        self, workflow_instance
    ):
        """Test process stage handles None input."""
        # Given: None as input data
        input_data = None
        tier = ModelTier.CAPABLE

        # When: Running process stage
        result, input_tokens, output_tokens = await workflow_instance._process(
            input_data, tier
        )

        # Then: Returns valid result
        assert result == {"stage": "process", "input": None}
        assert input_tokens == 0
        assert output_tokens == 0


class TestReportStage:
    """Test _report stage implementation."""

    @pytest.mark.asyncio
    async def test_given_input_data_when_report_without_executor_then_default_result_returned(
        self, workflow_instance
    ):
        """Test report stage without executor returns default result."""
        # Given: Input data and no executor
        input_data = {"key": "value"}
        tier = ModelTier.PREMIUM

        # When: Running report stage
        result, input_tokens, output_tokens = await workflow_instance._report(
            input_data, tier
        )

        # Then: Default result is returned with zero tokens
        assert result == {"stage": "report", "input": input_data}
        assert input_tokens == 0
        assert output_tokens == 0

    @pytest.mark.asyncio
    async def test_given_input_data_when_report_with_executor_then_executor_called(
        self, workflow_with_executor, mock_executor
    ):
        """Test report stage with executor calls executor.run."""
        # Given: Input data and mock executor
        input_data = {"processed": "data"}
        tier = ModelTier.PREMIUM
        expected_result = "final report"
        mock_executor.run.return_value = MockExecutorResult(
            expected_result, 300, 150
        )

        # When: Running report stage
        result, input_tokens, output_tokens = await workflow_with_executor._report(
            input_data, tier
        )

        # Then: Executor is called with correct parameters
        mock_executor.run.assert_called_once()
        call_kwargs = mock_executor.run.call_args[1]
        assert call_kwargs["task_type"] == "workflow_stage"
        assert f"report stage: {input_data}" in call_kwargs["prompt"]
        assert result == expected_result
        assert input_tokens == 300
        assert output_tokens == 150

    @pytest.mark.asyncio
    async def test_given_string_input_when_report_then_handles_correctly(
        self, workflow_instance
    ):
        """Test report stage handles string input."""
        # Given: String input data
        input_data = "string data"
        tier = ModelTier.PREMIUM

        # When: Running report stage
        result, input_tokens, output_tokens = await workflow_instance._report(
            input_data, tier
        )

        # Then: Returns valid result
        assert result == {"stage": "report", "input": input_data}